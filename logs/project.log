2024-11-04 11:24:17,210 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-04 11:24:17,213 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_models/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-04 11:24:17,213 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-04 11:24:17,213 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-04 11:24:17,213 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-04 11:24:17,214 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-04 11:24:17,234 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-04 11:24:17,366 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-04 11:24:22,667 - root - INFO - Feature extraction started at: 2024-11-04 11:24:22 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:94]
2024-11-04 11:24:22,668 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-04 11:24:22,668 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-04 11:27:29,625 - root - INFO - Patient TCGA-02-0003: final extracted features shape torch.Size([64, 1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:150]
2024-11-04 11:27:29,667 - root - INFO - Patient TCGA-02-2466: final extracted features shape torch.Size([20, 1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:150]
2024-11-04 11:27:29,672 - root - INFO - 
Feature extraction completed. Processed: 2, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:153]
2024-11-04 11:27:29,678 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-04 11:40:20,036 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-04 11:40:20,040 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-04 11:40:20,040 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-04 11:40:20,040 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-04 11:40:20,042 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-04 11:40:20,042 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:77]
2024-11-04 11:40:20,063 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-04 11:40:20,483 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-04 11:40:25,359 - root - INFO - Feature extraction started at: 2024-11-04 11:40:25 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-04 11:40:25,359 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-04 11:40:25,359 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-04 11:43:54,591 - root - INFO - Patient TCGA-02-0003: final extracted features shape torch.Size([64, 1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:151]
2024-11-04 11:43:54,644 - root - INFO - Patient TCGA-02-2466: final extracted features shape torch.Size([20, 1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:151]
2024-11-04 11:43:54,651 - root - INFO - 
Feature extraction completed. Processed: 2, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:154]
2024-11-04 11:43:54,655 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:93]
2024-11-04 13:57:22,165 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-04 13:57:22,175 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-04 13:57:22,175 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-04 13:57:22,175 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-04 13:57:22,177 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-04 13:57:22,177 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-04 13:57:22,219 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-04 13:57:22,437 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-04 13:57:27,288 - root - INFO - Feature extraction started at: 2024-11-04 13:57:27 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-04 13:57:27,288 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-04 13:57:27,288 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-04 14:00:06,817 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-04 14:00:06,821 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-04 14:00:06,821 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-04 14:00:06,821 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-04 14:00:06,822 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-04 14:00:06,822 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-04 14:00:06,842 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-04 14:00:07,056 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-04 14:00:07,885 - root - INFO - Feature extraction started at: 2024-11-04 14:00:07 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-04 14:00:07,886 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-04 14:00:07,886 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-04 14:01:35,042 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([64, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:136]
2024-11-04 14:01:35,458 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([20, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:158]
2024-11-04 14:01:35,458 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:199]
2024-11-04 14:01:35,462 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-04 14:16:27,138 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-04 14:16:27,146 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-04 14:16:27,146 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-04 14:16:27,147 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-04 14:16:27,148 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-04 14:16:27,149 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-04 14:16:27,178 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-04 14:16:27,544 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-04 14:16:28,377 - root - INFO - Feature extraction started at: 2024-11-04 14:16:28 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-04 14:16:28,377 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-04 14:16:28,377 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-04 14:17:48,635 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:128]
2024-11-04 14:17:48,639 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:128]
2024-11-04 14:17:48,658 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 2, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:202]
2024-11-04 14:17:48,661 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-04 15:23:11,094 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-04 15:23:11,099 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-04 15:23:11,099 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-04 15:23:11,099 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-04 15:23:11,099 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-04 15:23:11,099 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-04 15:23:11,126 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-04 15:23:11,521 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-04 15:23:16,388 - root - INFO - Feature extraction started at: 2024-11-04 15:23:16 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-04 15:23:16,388 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-04 15:23:16,388 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-04 15:26:00,343 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:129]
2024-11-04 15:26:00,352 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:129]
2024-11-04 15:26:00,372 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 2, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-04 15:26:00,376 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-04 15:32:50,142 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-04 15:32:50,148 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-04 15:32:50,148 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-04 15:32:50,148 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-04 15:32:50,148 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-04 15:32:50,148 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-04 15:32:50,385 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-04 15:32:50,545 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-04 15:32:55,605 - root - INFO - Feature extraction started at: 2024-11-04 15:32:55 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-04 15:32:55,606 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-04 15:32:55,606 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-04 15:35:45,312 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:128]
2024-11-04 15:35:45,313 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:128]
2024-11-04 15:35:45,333 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 2, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:202]
2024-11-04 15:35:45,336 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-04 15:40:31,662 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 64, 'num_workers': 1, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-04 15:40:31,666 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-04 15:40:31,666 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-04 15:40:31,666 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-04 15:40:31,666 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-04 15:40:31,666 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-04 15:40:31,705 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-04 15:40:32,055 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-04 15:40:36,627 - root - INFO - Feature extraction started at: 2024-11-04 15:40:36 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-04 15:40:36,627 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-04 15:40:36,627 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-04 15:43:13,670 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:128]
2024-11-04 15:43:13,670 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:128]
2024-11-04 15:43:13,685 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 2, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:202]
2024-11-04 15:43:13,688 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-05 08:25:53,621 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 64, 'num_workers': 1, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-05 08:25:53,623 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-05 08:25:53,623 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-05 08:25:53,623 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-05 08:25:53,623 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-05 08:25:53,623 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-05 08:25:53,649 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-05 08:25:54,033 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-05 08:25:54,608 - root - INFO - Feature extraction started at: 2024-11-05 08:25:54 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-05 08:25:54,608 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-05 08:25:54,608 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-05 08:27:04,143 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:128]
2024-11-05 08:27:04,143 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:128]
2024-11-05 08:27:04,162 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 2, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:202]
2024-11-05 08:27:04,180 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-05 09:39:42,390 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 64, 'num_workers': 1, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-05 09:39:42,392 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-05 09:39:42,392 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-05 09:39:42,392 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-05 09:39:42,392 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-05 09:39:42,392 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-05 09:39:42,418 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-05 09:39:42,776 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-05 09:39:43,267 - root - INFO - Feature extraction started at: 2024-11-05 09:39:43 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-05 09:39:43,267 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-05 09:39:43,268 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-05 09:40:48,064 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:227]
2024-11-05 09:40:48,079 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-05 10:03:26,546 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 64, 'num_workers': 1, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-05 10:03:26,548 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-05 10:03:26,548 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-05 10:03:26,548 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-05 10:03:26,549 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-05 10:03:26,549 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-05 10:03:26,572 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-05 10:03:26,721 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-05 10:03:27,281 - root - INFO - Feature extraction started at: 2024-11-05 10:03:27 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-05 10:03:27,282 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-05 10:03:27,282 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-05 10:04:33,337 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-05 10:15:50,524 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 64, 'num_workers': 1, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-05 10:15:50,526 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-05 10:15:50,526 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-05 10:15:50,526 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-05 10:15:50,526 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-05 10:15:50,526 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-05 10:15:50,550 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-05 10:15:50,716 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-05 10:15:51,257 - root - INFO - Feature extraction started at: 2024-11-05 10:15:51 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-05 10:15:51,257 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-05 10:15:51,257 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-05 10:16:54,666 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-05 10:33:41,647 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 1, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-05 10:33:41,649 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-05 10:33:41,649 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-05 10:33:41,649 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-05 10:33:41,649 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-05 10:33:41,650 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-05 10:33:41,675 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-05 10:33:41,838 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-05 10:33:42,385 - root - INFO - Feature extraction started at: 2024-11-05 10:33:42 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-05 10:33:42,385 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-05 10:33:42,385 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-05 10:34:49,136 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-05 10:54:19,604 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 1, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-05 10:54:19,606 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-05 10:54:19,606 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-05 10:54:19,606 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-05 10:54:19,606 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-05 10:54:19,606 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-05 10:54:19,636 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-05 10:54:19,792 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-05 10:54:20,352 - root - INFO - Feature extraction started at: 2024-11-05 10:54:20 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-05 10:54:20,352 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-05 10:54:20,352 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-05 10:55:27,316 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-05 11:26:25,195 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 1, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-05 11:26:25,197 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-05 11:26:25,197 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-05 11:26:25,197 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-05 11:26:25,197 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-05 11:26:25,198 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-05 11:26:25,222 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-05 11:26:25,380 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-05 11:26:25,926 - root - INFO - Feature extraction started at: 2024-11-05 11:26:25 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-05 11:26:25,926 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-05 11:26:25,926 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-05 11:27:10,772 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-05 11:27:10,774 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-05 11:27:10,774 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-05 11:27:10,774 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-05 11:27:10,774 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-05 11:27:10,774 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-05 11:27:10,794 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-05 11:27:11,140 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-05 11:27:11,564 - root - INFO - Feature extraction started at: 2024-11-05 11:27:11 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-05 11:27:11,564 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-05 11:27:11,564 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-05 11:28:13,571 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:154]
2024-11-05 11:28:13,572 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:154]
2024-11-05 11:28:13,670 - root - ERROR - Failed to extract features for patient TCGA-02-0033: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:179]
2024-11-05 11:28:13,894 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:164]
2024-11-05 11:28:13,906 - root - ERROR - Failed to extract features for patient TCGA-02-0047: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:179]
2024-11-05 11:28:13,914 - root - ERROR - Failed to extract features for patient TCGA-02-0047: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:179]
2024-11-05 11:28:13,925 - root - ERROR - Failed to extract features for patient TCGA-02-0055: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:179]
2024-11-05 11:28:13,933 - root - ERROR - Failed to extract features for patient TCGA-02-0055: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:179]
2024-11-05 11:28:13,933 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:154]
2024-11-05 11:28:13,934 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:154]
2024-11-05 11:28:13,963 - root - INFO - 
Feature extraction completed. Processed: 2, Skipped: 4, Errors: 5 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:228]
2024-11-05 11:28:13,964 - root - INFO - Errors encountered for the following patients: TCGA-02-0033, TCGA-02-0047, TCGA-02-0047, TCGA-02-0055, TCGA-02-0055 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:230]
2024-11-05 11:28:13,976 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-05 12:10:59,439 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-05 12:10:59,441 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-05 12:10:59,442 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-05 12:10:59,442 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-05 12:10:59,442 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-05 12:10:59,442 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-05 12:10:59,467 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-05 12:10:59,634 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-05 12:11:00,176 - root - INFO - Feature extraction started at: 2024-11-05 12:11:00 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-05 12:11:00,176 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-05 12:11:00,177 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-05 12:12:07,202 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:156]
2024-11-05 12:12:07,216 - root - ERROR - Failed to extract features for patient TCGA-02-0003: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:185]
2024-11-05 12:12:07,225 - root - ERROR - Failed to extract features for patient TCGA-02-0033: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:185]
2024-11-05 12:12:07,284 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:167]
2024-11-05 12:12:07,289 - root - ERROR - Failed to extract features for patient TCGA-02-0047: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:185]
2024-11-05 12:12:07,298 - root - ERROR - Failed to extract features for patient TCGA-02-0055: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:185]
2024-11-05 12:12:07,301 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:156]
2024-11-05 12:12:07,307 - root - ERROR - Failed to extract features for patient TCGA-02-2466: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:185]
2024-11-05 12:12:07,332 - root - INFO - 
Feature extraction completed. Processed: 2, Skipped: 2, Errors: 5 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:196]
2024-11-05 12:12:07,333 - root - INFO - Errors encountered for the following patients: TCGA-02-0003, TCGA-02-0033, TCGA-02-0047, TCGA-02-0055, TCGA-02-2466 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:198]
2024-11-05 12:12:07,351 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-05 13:18:54,281 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-05 13:18:54,283 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-05 13:18:54,283 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-05 13:18:54,283 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-05 13:18:54,283 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-05 13:18:54,283 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-05 13:18:54,306 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-05 13:18:54,455 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-05 13:18:54,945 - root - INFO - Feature extraction started at: 2024-11-05 13:18:54 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-05 13:18:54,945 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-05 13:18:54,945 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-05 13:20:01,348 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:156]
2024-11-05 13:20:01,356 - root - ERROR - Failed to extract features for patient TCGA-02-0003: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:184]
2024-11-05 13:20:01,363 - root - ERROR - Failed to extract features for patient TCGA-02-0033: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:184]
2024-11-05 13:20:01,426 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:167]
2024-11-05 13:20:01,431 - root - ERROR - Failed to extract features for patient TCGA-02-0047: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:184]
2024-11-05 13:20:01,440 - root - ERROR - Failed to extract features for patient TCGA-02-0055: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:184]
2024-11-05 13:20:01,443 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:156]
2024-11-05 13:20:01,449 - root - ERROR - Failed to extract features for patient TCGA-02-2466: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:184]
2024-11-05 13:20:01,472 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 2, Errors: 5 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:195]
2024-11-05 13:20:01,472 - root - INFO - Errors encountered for the following patients: TCGA-02-0003, TCGA-02-0033, TCGA-02-0047, TCGA-02-0055, TCGA-02-2466 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:197]
2024-11-05 13:20:01,490 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-05 13:34:35,779 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-05 13:34:35,781 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-05 13:34:35,782 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-05 13:34:35,782 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-05 13:34:35,782 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-05 13:34:35,782 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-05 13:34:35,806 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-05 13:34:36,187 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-05 13:34:36,815 - root - INFO - Feature extraction started at: 2024-11-05 13:34:36 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-05 13:34:36,815 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-05 13:34:36,815 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-05 13:35:44,266 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:156]
2024-11-05 13:35:44,286 - root - ERROR - Failed to extract features for patient TCGA-02-0033: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:184]
2024-11-05 13:35:44,350 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:167]
2024-11-05 13:35:44,355 - root - ERROR - Failed to extract features for patient TCGA-02-0047: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:184]
2024-11-05 13:35:44,364 - root - ERROR - Failed to extract features for patient TCGA-02-0055: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:184]
2024-11-05 13:35:44,367 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:156]
2024-11-05 13:35:44,387 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 2, Errors: 3 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:195]
2024-11-05 13:35:44,388 - root - INFO - Errors encountered for the following patients: TCGA-02-0033, TCGA-02-0047, TCGA-02-0055 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:197]
2024-11-05 13:35:44,398 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-05 14:40:46,277 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-05 14:40:46,279 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-05 14:40:46,279 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-05 14:40:46,279 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-05 14:40:46,279 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-05 14:40:46,279 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-05 14:40:46,304 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-05 14:40:46,540 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-05 14:40:47,038 - root - INFO - Feature extraction started at: 2024-11-05 14:40:47 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-05 14:40:47,038 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-05 14:40:47,038 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-05 14:41:53,878 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:156]
2024-11-05 14:41:53,881 - root - ERROR - Failed to extract features for patient TCGA-02-0033: 'DNABERT2BPE' object is not callable [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:188]
2024-11-05 14:41:53,881 - root - ERROR - Failed to extract features for patient TCGA-02-0047: 'DNABERT2BPE' object is not callable [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:188]
2024-11-05 14:41:53,881 - root - ERROR - Failed to extract features for patient TCGA-02-0055: 'DNABERT2BPE' object is not callable [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:188]
2024-11-05 14:41:53,881 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:156]
2024-11-05 14:41:53,903 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 2, Errors: 3 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:199]
2024-11-05 14:41:53,903 - root - INFO - Errors encountered for the following patients: TCGA-02-0033, TCGA-02-0047, TCGA-02-0055 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:201]
2024-11-05 14:41:53,912 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-05 14:45:57,258 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-05 14:45:57,260 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-05 14:45:57,260 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-05 14:45:57,260 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-05 14:45:57,260 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-05 14:45:57,260 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-05 14:45:57,284 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-05 14:45:57,656 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-05 14:45:58,227 - root - INFO - Feature extraction started at: 2024-11-05 14:45:58 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-05 14:45:58,227 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-05 14:45:58,227 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-05 14:47:07,287 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:156]
2024-11-05 14:47:07,305 - root - ERROR - Failed to extract features for patient TCGA-02-0033: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:188]
2024-11-05 14:47:07,362 - root - INFO - Features successfully extracted for patient TCGA-02-0033. Current features_list length: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:180]
2024-11-05 14:47:07,366 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:167]
2024-11-05 14:47:07,371 - root - ERROR - Failed to extract features for patient TCGA-02-0047: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:188]
2024-11-05 14:47:07,379 - root - ERROR - Failed to extract features for patient TCGA-02-0055: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:188]
2024-11-05 14:47:07,382 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:156]
2024-11-05 14:47:07,405 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 2, Errors: 3 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:199]
2024-11-05 14:47:07,405 - root - INFO - Errors encountered for the following patients: TCGA-02-0033, TCGA-02-0047, TCGA-02-0055 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:201]
2024-11-05 14:47:07,415 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-05 15:59:57,148 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-05 15:59:57,150 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-05 15:59:57,150 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-05 15:59:57,150 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-05 15:59:57,150 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-05 15:59:57,150 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-05 15:59:57,179 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-05 15:59:57,347 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-05 15:59:57,846 - root - INFO - Feature extraction started at: 2024-11-05 15:59:57 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-05 15:59:57,846 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-05 15:59:57,846 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-05 16:01:06,880 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:156]
2024-11-05 16:01:06,914 - root - ERROR - Failed to extract features for seq_chunk in patient TCGA-02-0033: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:178]
2024-11-05 16:01:06,973 - root - INFO - Features successfully extracted for patient TCGA-02-0033. Current features_list length: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:184]
2024-11-05 16:01:06,977 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:167]
2024-11-05 16:01:06,982 - root - ERROR - Failed to extract features for seq_chunk in patient TCGA-02-0047: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:178]
2024-11-05 16:01:06,985 - root - ERROR - Failed to extract features for seq_chunk in patient TCGA-02-0047: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:178]
2024-11-05 16:01:06,990 - root - ERROR - Failed to extract features for seq_chunk in patient TCGA-02-0055: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:178]
2024-11-05 16:01:06,993 - root - ERROR - Failed to extract features for seq_chunk in patient TCGA-02-0055: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:178]
2024-11-05 16:01:06,993 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:156]
2024-11-05 16:01:07,013 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 2, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:202]
2024-11-05 16:01:07,032 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-05 16:24:08,166 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-05 16:24:08,168 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-05 16:24:08,168 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-05 16:24:08,168 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-05 16:24:08,168 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-05 16:24:08,168 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-05 16:24:08,193 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-05 16:24:08,543 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-05 16:24:09,036 - root - INFO - Feature extraction started at: 2024-11-05 16:24:09 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-05 16:24:09,036 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-05 16:24:09,036 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-05 16:25:12,905 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:157]
2024-11-05 16:25:12,918 - root - ERROR - Failed to extract features for patient TCGA-02-0033: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:186]
2024-11-05 16:25:12,919 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:157]
2024-11-05 16:25:12,942 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 2, Errors: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:197]
2024-11-05 16:25:12,942 - root - INFO - Errors encountered for the following patients: TCGA-02-0033 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:199]
2024-11-05 16:25:12,951 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-05 16:44:29,070 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-05 16:44:29,072 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-05 16:44:29,072 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-05 16:44:29,072 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-05 16:44:29,072 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-05 16:44:29,072 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-05 16:44:29,095 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-05 16:44:29,271 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-05 16:44:29,818 - root - INFO - Feature extraction started at: 2024-11-05 16:44:29 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-05 16:44:29,818 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-05 16:44:29,818 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-05 16:45:39,285 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:161]
2024-11-05 16:45:39,306 - root - ERROR - Failed to extract features for patient TCGA-02-0033: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:192]
2024-11-05 16:45:39,307 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:161]
2024-11-05 16:45:39,329 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 2, Errors: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-05 16:45:39,330 - root - INFO - Errors encountered for the following patients: TCGA-02-0033 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-05 16:45:39,347 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-05 16:58:01,996 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-05 16:58:01,998 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-05 16:58:01,998 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-05 16:58:01,998 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-05 16:58:01,998 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-05 16:58:01,998 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-05 16:58:02,024 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-05 16:58:02,194 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-05 16:58:02,702 - root - INFO - Feature extraction started at: 2024-11-05 16:58:02 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-05 16:58:02,702 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-05 16:58:02,703 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-05 16:59:08,017 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:161]
2024-11-05 16:59:08,032 - root - ERROR - Failed to extract features for patient TCGA-02-0033: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:192]
2024-11-05 16:59:08,033 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:161]
2024-11-05 16:59:08,054 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 2, Errors: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:204]
2024-11-05 16:59:08,054 - root - INFO - Errors encountered for the following patients: TCGA-02-0033 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:206]
2024-11-05 16:59:08,064 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-05 17:01:32,587 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-05 17:01:32,589 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-05 17:01:32,589 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-05 17:01:32,589 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-05 17:01:32,589 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-05 17:01:32,589 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-05 17:01:32,612 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-05 17:01:32,805 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-05 17:01:33,281 - root - INFO - Feature extraction started at: 2024-11-05 17:01:33 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-05 17:01:33,281 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-05 17:01:33,281 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-05 17:02:39,230 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:161]
2024-11-05 17:02:39,248 - root - ERROR - Failed to extract features for patient TCGA-02-0033: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:192]
2024-11-05 17:02:39,689 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:161]
2024-11-05 17:02:39,842 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 2, Errors: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:204]
2024-11-05 17:02:39,842 - root - INFO - Errors encountered for the following patients: TCGA-02-0033 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:206]
2024-11-05 17:02:39,853 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-05 17:03:58,795 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-05 17:03:58,797 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-05 17:03:58,797 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-05 17:03:58,797 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-05 17:03:58,797 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-05 17:03:58,797 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-05 17:03:58,821 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-05 17:03:58,978 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-05 17:03:59,503 - root - INFO - Feature extraction started at: 2024-11-05 17:03:59 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-05 17:03:59,503 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-05 17:03:59,503 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-05 17:05:05,088 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:161]
2024-11-05 17:05:05,110 - root - ERROR - Failed to extract features for patient TCGA-02-0033: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:193]
2024-11-05 17:05:05,112 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:161]
2024-11-05 17:05:05,133 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 2, Errors: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-05 17:05:05,133 - root - INFO - Errors encountered for the following patients: TCGA-02-0033 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:207]
2024-11-05 17:05:05,148 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-06 09:50:46,759 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-06 09:50:46,785 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-06 09:50:46,785 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-06 09:50:46,785 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-06 09:50:46,785 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-06 09:50:46,786 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-06 09:50:46,832 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-06 09:50:47,011 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-06 09:50:49,143 - root - INFO - Feature extraction started at: 2024-11-06 09:50:49 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-06 09:50:49,144 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-06 09:50:49,144 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-06 09:52:01,898 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:161]
2024-11-06 09:52:01,984 - root - ERROR - Failed to extract features for patient TCGA-02-0033: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:193]
2024-11-06 09:52:01,985 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:161]
2024-11-06 09:52:02,011 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 2, Errors: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-06 09:52:02,011 - root - INFO - Errors encountered for the following patients: TCGA-02-0033 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:207]
2024-11-06 09:52:02,028 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-06 10:30:33,688 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-06 10:30:33,730 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-06 10:30:33,730 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-06 10:30:33,730 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-06 10:30:33,731 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-06 10:30:33,731 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-06 10:30:33,768 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-06 10:30:33,947 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-06 10:30:35,720 - root - INFO - Feature extraction started at: 2024-11-06 10:30:35 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-06 10:30:35,720 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-06 10:30:35,721 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-06 10:31:51,046 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:161]
2024-11-06 10:31:51,064 - root - ERROR - Failed to extract features for patient TCGA-02-0033: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:196]
2024-11-06 10:31:51,078 - root - ERROR - Failed to extract features for patient TCGA-02-0047: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:196]
2024-11-06 10:31:51,090 - root - ERROR - Failed to extract features for patient TCGA-02-0055: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:196]
2024-11-06 10:31:51,091 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:161]
2024-11-06 10:31:51,117 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 2, Errors: 3 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:212]
2024-11-06 10:31:51,117 - root - INFO - Errors encountered for the following patients: TCGA-02-0033, TCGA-02-0047, TCGA-02-0055 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:214]
2024-11-06 10:31:51,128 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-06 11:13:19,199 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-06 11:13:19,201 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-06 11:13:19,201 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-06 11:13:19,201 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-06 11:13:19,201 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-06 11:13:19,201 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-06 11:13:19,217 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-06 11:13:19,376 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-06 11:13:19,956 - root - INFO - Feature extraction started at: 2024-11-06 11:13:19 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-06 11:13:19,956 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-06 11:13:19,956 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-06 11:14:35,613 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:161]
2024-11-06 11:14:35,628 - root - ERROR - Failed to extract features for patient TCGA-02-0033: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:198]
2024-11-06 11:14:35,634 - root - ERROR - Failed to extract features for patient TCGA-02-0047: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:198]
2024-11-06 11:14:35,641 - root - ERROR - Failed to extract features for patient TCGA-02-0055: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:198]
2024-11-06 11:14:35,642 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:161]
2024-11-06 11:14:35,663 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 2, Errors: 3 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:214]
2024-11-06 11:14:35,664 - root - INFO - Errors encountered for the following patients: TCGA-02-0033, TCGA-02-0047, TCGA-02-0055 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:216]
2024-11-06 11:14:35,676 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-06 11:24:12,777 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-06 11:24:12,779 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-06 11:24:12,779 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-06 11:24:12,779 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-06 11:24:12,779 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-06 11:24:12,779 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-06 11:24:12,804 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-06 11:24:12,984 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-06 11:24:13,461 - root - INFO - Feature extraction started at: 2024-11-06 11:24:13 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-06 11:24:13,461 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-06 11:24:13,461 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-06 11:25:27,515 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:162]
2024-11-06 11:25:27,613 - root - ERROR - Failed to extract features for patient TCGA-02-0033: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:200]
2024-11-06 11:25:27,627 - root - ERROR - Failed to extract features for patient TCGA-02-0047: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:200]
2024-11-06 11:25:28,185 - root - ERROR - Failed to extract features for patient TCGA-02-0055: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:200]
2024-11-06 11:25:28,222 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:162]
2024-11-06 11:25:28,246 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 2, Errors: 3 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:216]
2024-11-06 11:25:28,246 - root - INFO - Errors encountered for the following patients: TCGA-02-0033, TCGA-02-0047, TCGA-02-0055 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:218]
2024-11-06 11:25:28,259 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-06 11:54:21,007 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-06 11:54:21,009 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-06 11:54:21,010 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-06 11:54:21,010 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-06 11:54:21,010 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-06 11:54:21,010 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-06 11:54:21,025 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-06 11:54:21,232 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-06 11:54:21,756 - root - INFO - Feature extraction started at: 2024-11-06 11:54:21 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-06 11:54:21,756 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-06 11:54:21,756 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-06 11:55:37,127 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:162]
2024-11-06 11:55:43,255 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([13, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:173]
2024-11-06 11:55:50,307 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([17, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:173]
2024-11-06 11:55:56,483 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:162]
2024-11-06 11:55:56,501 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([14, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:216]
2024-11-06 11:55:56,501 - root - INFO - 
Feature extraction completed. Processed: 3, Skipped: 2, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:219]
2024-11-06 11:55:56,510 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-06 12:03:56,843 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-06 12:03:56,845 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-06 12:03:56,845 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-06 12:03:56,845 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-06 12:03:56,845 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-06 12:03:56,846 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-06 12:03:56,868 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-06 12:03:57,042 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-06 12:03:57,539 - root - INFO - Feature extraction started at: 2024-11-06 12:03:57 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-06 12:03:57,539 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-06 12:03:57,539 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-06 12:05:22,735 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([16, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:173]
2024-11-06 12:05:28,149 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([13, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:173]
2024-11-06 12:05:35,188 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([17, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:173]
2024-11-06 12:05:41,326 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([14, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:173]
2024-11-06 12:05:51,279 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([24, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:216]
2024-11-06 12:05:51,280 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:219]
2024-11-06 12:05:51,289 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-06 16:20:15,160 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-06 16:22:49,552 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-06 16:22:49,555 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-06 16:22:49,555 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-06 16:22:49,555 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-06 16:22:49,555 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-06 16:22:49,555 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-06 16:22:49,597 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-06 16:22:49,774 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-06 16:22:51,730 - root - INFO - Feature extraction started at: 2024-11-06 16:22:51 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-06 16:22:51,730 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-06 16:22:51,730 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-06 16:24:14,186 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([16, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:173]
2024-11-06 16:24:19,378 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([13, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:173]
2024-11-06 16:24:26,233 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([17, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:173]
2024-11-06 16:24:32,020 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([14, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:173]
2024-11-06 16:24:41,499 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([24, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:216]
2024-11-06 16:24:41,499 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:219]
2024-11-06 16:24:41,508 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-06 17:29:47,755 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-06 17:29:47,757 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-06 17:29:47,757 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-06 17:29:47,757 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-06 17:29:47,758 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-06 17:29:47,758 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-06 17:29:47,773 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-06 17:29:47,951 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-06 17:29:48,444 - root - INFO - Feature extraction started at: 2024-11-06 17:29:48 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-06 17:29:48,444 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-06 17:29:48,444 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-06 17:31:01,362 - root - ERROR - Failed to extract features for patient TCGA-02-0003: 'DNABERT2BPE' object has no attribute 'convert_tokens_to_ids' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 17:31:01,721 - root - ERROR - Failed to extract features for patient TCGA-02-0033: 'DNABERT2BPE' object has no attribute 'convert_tokens_to_ids' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 17:31:02,058 - root - ERROR - Failed to extract features for patient TCGA-02-0047: 'DNABERT2BPE' object has no attribute 'convert_tokens_to_ids' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 17:31:02,416 - root - ERROR - Failed to extract features for patient TCGA-02-0055: 'DNABERT2BPE' object has no attribute 'convert_tokens_to_ids' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 17:31:02,758 - root - ERROR - Failed to extract features for patient TCGA-02-2466: 'DNABERT2BPE' object has no attribute 'convert_tokens_to_ids' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 17:31:02,774 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 0, Errors: 5 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:219]
2024-11-06 17:31:02,774 - root - INFO - Errors encountered for the following patients: TCGA-02-0003, TCGA-02-0033, TCGA-02-0047, TCGA-02-0055, TCGA-02-2466 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-06 17:31:02,781 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-06 19:25:36,665 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-06 19:25:36,670 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-06 19:25:36,670 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-06 19:25:36,670 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-06 19:25:36,670 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-06 19:25:36,670 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-06 19:25:36,698 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-06 19:25:36,902 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-06 19:25:43,288 - root - INFO - Feature extraction started at: 2024-11-06 19:25:43 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-06 19:25:43,288 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-06 19:25:43,288 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-06 19:28:21,885 - root - ERROR - Failed to extract features for patient TCGA-02-0003: 'DNABERT2BPE' object has no attribute 'convert_tokens_to_ids' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 19:28:21,921 - root - ERROR - Failed to extract features for patient TCGA-02-0033: 'DNABERT2BPE' object has no attribute 'convert_tokens_to_ids' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 19:28:21,949 - root - ERROR - Failed to extract features for patient TCGA-02-0047: 'DNABERT2BPE' object has no attribute 'convert_tokens_to_ids' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 19:28:21,974 - root - ERROR - Failed to extract features for patient TCGA-02-0055: 'DNABERT2BPE' object has no attribute 'convert_tokens_to_ids' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 19:28:21,996 - root - ERROR - Failed to extract features for patient TCGA-02-2466: 'DNABERT2BPE' object has no attribute 'convert_tokens_to_ids' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 19:28:22,028 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 0, Errors: 5 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:219]
2024-11-06 19:28:22,028 - root - INFO - Errors encountered for the following patients: TCGA-02-0003, TCGA-02-0033, TCGA-02-0047, TCGA-02-0055, TCGA-02-2466 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-06 19:28:22,032 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-06 19:58:44,696 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-06 19:58:44,702 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-06 19:58:44,702 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-06 19:58:44,702 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-06 19:58:44,703 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-06 19:58:44,704 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-06 19:58:44,728 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-06 19:58:44,991 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-06 19:58:49,702 - root - INFO - Feature extraction started at: 2024-11-06 19:58:49 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-06 19:58:49,702 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-06 19:58:49,702 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-06 20:03:12,805 - root - ERROR - Failed to extract features for patient TCGA-02-0003: 'DNABERT2BPE' object has no attribute 'convert_tokens_to_ids' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 20:03:12,837 - root - ERROR - Failed to extract features for patient TCGA-02-0033: 'DNABERT2BPE' object has no attribute 'convert_tokens_to_ids' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 20:03:12,862 - root - ERROR - Failed to extract features for patient TCGA-02-0047: 'DNABERT2BPE' object has no attribute 'convert_tokens_to_ids' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 20:03:12,885 - root - ERROR - Failed to extract features for patient TCGA-02-0055: 'DNABERT2BPE' object has no attribute 'convert_tokens_to_ids' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 20:03:12,906 - root - ERROR - Failed to extract features for patient TCGA-02-2466: 'DNABERT2BPE' object has no attribute 'convert_tokens_to_ids' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 20:03:12,931 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 0, Errors: 5 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:219]
2024-11-06 20:03:12,931 - root - INFO - Errors encountered for the following patients: TCGA-02-0003, TCGA-02-0033, TCGA-02-0047, TCGA-02-0055, TCGA-02-2466 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-06 20:03:12,935 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-06 20:37:16,752 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-06 20:37:16,756 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-06 20:37:16,756 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-06 20:37:16,756 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-06 20:37:16,756 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-06 20:37:16,757 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-06 20:37:16,776 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-06 20:37:16,987 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-06 20:37:22,036 - root - INFO - Feature extraction started at: 2024-11-06 20:37:22 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:95]
2024-11-06 20:37:22,036 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:96]
2024-11-06 20:37:22,036 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-06 20:41:13,386 - root - ERROR - Failed to extract features for patient TCGA-02-0003: DNABERT2.extract_feats() missing 1 required positional argument: 'sep_idxs' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 20:41:13,422 - root - ERROR - Failed to extract features for patient TCGA-02-0033: DNABERT2.extract_feats() missing 1 required positional argument: 'sep_idxs' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 20:41:13,450 - root - ERROR - Failed to extract features for patient TCGA-02-0047: DNABERT2.extract_feats() missing 1 required positional argument: 'sep_idxs' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 20:41:13,474 - root - ERROR - Failed to extract features for patient TCGA-02-0055: DNABERT2.extract_feats() missing 1 required positional argument: 'sep_idxs' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 20:41:13,496 - root - ERROR - Failed to extract features for patient TCGA-02-2466: DNABERT2.extract_feats() missing 1 required positional argument: 'sep_idxs' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:203]
2024-11-06 20:41:13,523 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 0, Errors: 5 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:219]
2024-11-06 20:41:13,524 - root - INFO - Errors encountered for the following patients: TCGA-02-0003, TCGA-02-0033, TCGA-02-0047, TCGA-02-0055, TCGA-02-2466 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-06 20:41:13,526 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-06 20:50:38,612 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-06 20:50:38,616 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-06 20:50:38,617 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-06 20:50:38,617 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-06 20:50:38,618 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-06 20:50:38,618 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-06 20:53:34,715 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-06 20:53:34,719 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-06 20:53:34,719 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-06 20:53:34,720 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-06 20:53:34,720 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-06 20:53:34,720 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-06 20:53:34,738 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-06 20:53:34,911 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-06 20:53:40,000 - root - INFO - Feature extraction started at: 2024-11-06 20:53:39 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-06 20:53:40,000 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-06 20:53:40,001 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-06 20:56:44,951 - root - ERROR - Failed to extract features for patient TCGA-02-0003: DNABERT2.extract_feats() missing 1 required positional argument: 'sep_idxs' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-06 20:56:45,049 - root - ERROR - Failed to extract features for patient TCGA-02-0033: DNABERT2.extract_feats() missing 1 required positional argument: 'sep_idxs' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-06 20:56:45,143 - root - ERROR - Failed to extract features for patient TCGA-02-0047: DNABERT2.extract_feats() missing 1 required positional argument: 'sep_idxs' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-06 20:56:45,227 - root - ERROR - Failed to extract features for patient TCGA-02-0055: DNABERT2.extract_feats() missing 1 required positional argument: 'sep_idxs' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-06 20:56:45,295 - root - ERROR - Failed to extract features for patient TCGA-02-2466: DNABERT2.extract_feats() missing 1 required positional argument: 'sep_idxs' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-06 20:56:45,361 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 0, Errors: 5 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-06 20:56:45,362 - root - INFO - Errors encountered for the following patients: TCGA-02-0003, TCGA-02-0033, TCGA-02-0047, TCGA-02-0055, TCGA-02-2466 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-06 20:56:45,370 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-06 21:08:42,836 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-06 21:08:42,839 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-06 21:08:42,839 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-06 21:08:42,839 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-06 21:08:42,839 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-06 21:08:42,840 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-06 21:11:47,244 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-06 21:11:47,248 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-06 21:11:47,248 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-06 21:11:47,248 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-06 21:11:47,248 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-06 21:11:47,248 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-06 21:24:19,868 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-06 21:24:19,872 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-06 21:24:19,872 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-06 21:24:19,872 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-06 21:24:19,873 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-06 21:24:19,873 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-06 21:30:34,209 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-06 21:30:34,212 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-06 21:30:34,213 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-06 21:30:34,213 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-06 21:30:34,214 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-06 21:30:34,214 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-06 21:41:48,411 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-06 21:41:48,419 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-06 21:41:48,419 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-06 21:41:48,419 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-06 21:41:48,420 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-06 21:41:48,420 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-06 21:41:48,458 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-06 21:41:48,644 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-06 21:41:53,988 - root - INFO - Feature extraction started at: 2024-11-06 21:41:53 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-06 21:41:53,988 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-06 21:41:53,988 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-06 21:44:34,728 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([821, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-06 21:44:35,762 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([631, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-06 21:44:36,749 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([849, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-06 21:44:37,572 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([717, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-06 21:44:38,994 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1232, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:218]
2024-11-06 21:44:38,994 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-06 21:44:38,998 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-07 07:21:01,744 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-07 07:21:01,770 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-07 07:21:01,770 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-07 07:21:01,770 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-07 07:21:01,772 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-07 07:21:01,772 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-07 07:21:01,856 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-07 07:21:02,034 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-07 07:21:07,300 - root - INFO - Feature extraction started at: 2024-11-07 07:21:07 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-07 07:21:07,300 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-07 07:21:07,300 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-07 07:23:40,760 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([821, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-07 07:23:41,216 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([631, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-07 07:23:41,587 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([849, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-07 07:23:41,902 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([717, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-07 07:23:42,451 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1232, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:218]
2024-11-07 07:23:42,451 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-07 07:23:42,458 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 09:46:01,084 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 09:46:01,089 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 09:46:01,089 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 09:46:01,089 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 09:46:01,089 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 09:46:01,090 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 09:46:01,134 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 09:46:01,296 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 09:46:06,897 - root - INFO - Feature extraction started at: 2024-11-11 09:46:06 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 09:46:06,897 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 09:46:06,898 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 09:48:40,203 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:164]
2024-11-11 09:48:40,204 - root - INFO - Skipping patient TCGA-02-0033 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:164]
2024-11-11 09:48:40,205 - root - INFO - Skipping patient TCGA-02-0047 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:164]
2024-11-11 09:48:40,206 - root - INFO - Skipping patient TCGA-02-0055 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:164]
2024-11-11 09:48:40,207 - root - INFO - Skipping patient TCGA-02-2466 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:164]
2024-11-11 09:48:40,223 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 5, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-11 09:48:40,229 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 09:49:19,152 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 09:49:19,156 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 09:49:19,156 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 09:49:19,156 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 09:49:19,157 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 09:49:19,157 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 09:49:19,188 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 09:49:19,346 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 09:49:24,043 - root - INFO - Feature extraction started at: 2024-11-11 09:49:24 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 09:49:24,043 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 09:49:24,043 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 09:51:57,734 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([821, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 09:51:58,054 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([631, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 09:51:58,446 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([849, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 09:51:58,833 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([717, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 09:51:59,398 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1232, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:218]
2024-11-11 09:51:59,398 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-11 09:51:59,402 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 10:09:55,926 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 10:09:55,930 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 10:09:55,930 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 10:09:55,930 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 10:09:55,930 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 10:09:55,930 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 10:09:55,964 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 10:09:56,115 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 10:11:43,644 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 10:11:43,648 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 10:11:43,648 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 10:11:43,648 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 10:11:43,648 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 10:11:43,648 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 10:11:43,902 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 10:11:44,046 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 10:13:53,219 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 10:13:53,223 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 10:13:53,223 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 10:13:53,223 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 10:13:53,223 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 10:13:53,224 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 10:13:53,375 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 10:13:53,541 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 11:17:10,653 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 11:17:10,658 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 11:17:10,659 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 11:17:10,659 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 11:17:10,659 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 11:17:10,659 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 11:17:10,703 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 11:17:10,852 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 11:17:15,963 - root - INFO - Feature extraction started at: 2024-11-11 11:17:15 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 11:17:15,963 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 11:17:15,963 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 11:19:57,684 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([821, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 11:19:58,463 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([631, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 11:19:59,492 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([849, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 11:20:00,341 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([717, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 11:20:01,815 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1232, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:218]
2024-11-11 11:20:01,815 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-11 11:20:01,818 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 11:27:51,681 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 11:27:51,686 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 11:27:51,686 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 11:27:51,686 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 11:27:51,686 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 11:27:51,687 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 11:27:51,752 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 11:27:51,916 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 11:27:56,731 - root - INFO - Feature extraction started at: 2024-11-11 11:27:56 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 11:27:56,731 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 11:27:56,731 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 11:30:38,385 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([805, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 11:30:39,158 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([618, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 11:30:40,165 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([832, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 11:30:41,003 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([703, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 11:30:42,447 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1208, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:218]
2024-11-11 11:30:42,447 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-11 11:30:42,452 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 11:49:12,805 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 11:49:12,811 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 11:49:12,811 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 11:49:12,811 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 11:49:12,812 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 11:49:12,814 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 11:49:12,889 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 11:49:13,064 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 11:49:18,335 - root - INFO - Feature extraction started at: 2024-11-11 11:49:18 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 11:49:18,335 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 11:49:18,335 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 11:52:15,732 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([805, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 11:52:16,506 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([618, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 11:52:17,511 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([832, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 11:52:18,355 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([703, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 11:52:19,807 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1208, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:218]
2024-11-11 11:52:19,807 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-11 11:52:19,810 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 12:03:36,458 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 12:03:36,463 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 12:03:36,463 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 12:03:36,463 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 12:03:36,463 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 12:03:36,464 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 12:03:36,533 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 12:03:36,688 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 12:03:41,789 - root - INFO - Feature extraction started at: 2024-11-11 12:03:41 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 12:03:41,789 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 12:03:41,790 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 12:06:22,117 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([805, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 12:06:22,894 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([618, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 12:06:23,903 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([832, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 12:06:24,747 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([703, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 12:06:26,211 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1208, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:218]
2024-11-11 12:06:26,211 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-11 12:06:26,215 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 12:16:23,350 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 12:16:23,355 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 12:16:23,355 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 12:16:23,355 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 12:16:23,355 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 12:16:23,355 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 12:16:23,426 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 12:16:23,599 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 12:16:28,759 - root - INFO - Feature extraction started at: 2024-11-11 12:16:28 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 12:16:28,760 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 12:16:28,760 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 12:19:01,904 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([805, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 12:19:02,681 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([618, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 12:19:03,685 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([832, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 12:19:04,521 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([703, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 12:19:05,968 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1208, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:218]
2024-11-11 12:19:05,968 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-11 12:19:05,974 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 12:20:50,098 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 12:20:50,103 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 12:20:50,103 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 12:20:50,103 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 12:20:50,103 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 12:20:50,104 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 12:20:50,163 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 12:20:50,336 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 12:20:55,437 - root - INFO - Feature extraction started at: 2024-11-11 12:20:55 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 12:20:55,437 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 12:20:55,437 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 12:23:49,445 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([805, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 12:23:57,515 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([618, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 12:24:08,377 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([832, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 12:24:14,928 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([703, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 12:24:30,637 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1208, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:218]
2024-11-11 12:24:30,637 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-11 12:24:30,642 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 12:32:21,208 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 12:32:21,214 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 12:32:21,214 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 12:32:21,215 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 12:32:21,216 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 12:32:21,216 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 12:32:21,268 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 12:32:21,426 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 12:32:26,550 - root - INFO - Feature extraction started at: 2024-11-11 12:32:26 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 12:32:26,550 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 12:32:26,550 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 12:35:07,588 - root - ERROR - Failed to extract features for patient TCGA-02-0003: 'tuple' object has no attribute 'shape' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 12:35:07,650 - root - ERROR - Failed to extract features for patient TCGA-02-0033: 'tuple' object has no attribute 'shape' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 12:35:07,711 - root - ERROR - Failed to extract features for patient TCGA-02-0047: 'tuple' object has no attribute 'shape' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 12:35:07,772 - root - ERROR - Failed to extract features for patient TCGA-02-0055: 'tuple' object has no attribute 'shape' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 12:35:07,831 - root - ERROR - Failed to extract features for patient TCGA-02-2466: 'tuple' object has no attribute 'shape' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 12:35:07,859 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 0, Errors: 5 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-11 12:35:07,859 - root - INFO - Errors encountered for the following patients: TCGA-02-0003, TCGA-02-0033, TCGA-02-0047, TCGA-02-0055, TCGA-02-2466 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-11 12:35:07,862 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 12:40:43,452 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 12:40:43,457 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 12:40:43,457 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 12:40:43,458 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 12:40:43,459 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 12:40:43,459 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 12:40:43,502 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 12:40:43,683 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 12:40:48,632 - root - INFO - Feature extraction started at: 2024-11-11 12:40:48 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 12:40:48,632 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 12:40:48,632 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 12:43:25,235 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([805, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 12:43:26,255 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([618, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 12:43:27,574 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([832, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 12:43:28,668 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([703, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 12:43:30,575 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1208, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:218]
2024-11-11 12:43:30,575 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-11 12:43:30,579 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 13:13:41,789 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 13:13:41,798 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 13:13:41,798 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 13:13:41,798 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 13:13:41,799 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 13:13:41,799 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 13:13:42,012 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 13:13:42,186 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 13:13:47,400 - root - INFO - Feature extraction started at: 2024-11-11 13:13:47 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 13:13:47,400 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 13:13:47,400 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 13:16:20,672 - root - ERROR - Failed to extract features for patient TCGA-02-0003: 'DNABERT2BPE' object has no attribute 'convert_ids_to_tokens' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:16:20,686 - root - ERROR - Failed to extract features for patient TCGA-02-0033: 'DNABERT2BPE' object has no attribute 'convert_ids_to_tokens' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:16:20,698 - root - ERROR - Failed to extract features for patient TCGA-02-0047: 'DNABERT2BPE' object has no attribute 'convert_ids_to_tokens' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:16:20,709 - root - ERROR - Failed to extract features for patient TCGA-02-0055: 'DNABERT2BPE' object has no attribute 'convert_ids_to_tokens' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:16:20,721 - root - ERROR - Failed to extract features for patient TCGA-02-2466: 'DNABERT2BPE' object has no attribute 'convert_ids_to_tokens' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:16:20,746 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 0, Errors: 5 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-11 13:16:20,746 - root - INFO - Errors encountered for the following patients: TCGA-02-0003, TCGA-02-0033, TCGA-02-0047, TCGA-02-0055, TCGA-02-2466 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-11 13:16:20,753 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 13:20:13,478 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 13:20:13,487 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 13:20:13,487 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 13:20:13,487 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 13:20:13,488 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 13:20:13,489 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 13:20:13,541 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 13:20:13,703 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 13:20:19,149 - root - INFO - Feature extraction started at: 2024-11-11 13:20:19 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 13:20:19,149 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 13:20:19,149 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 13:22:52,207 - root - ERROR - Failed to extract features for patient TCGA-02-0003: int() argument must be a string, a bytes-like object or a real number, not 'list' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:22:52,219 - root - ERROR - Failed to extract features for patient TCGA-02-0033: int() argument must be a string, a bytes-like object or a real number, not 'list' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:22:52,228 - root - ERROR - Failed to extract features for patient TCGA-02-0047: int() argument must be a string, a bytes-like object or a real number, not 'list' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:22:52,237 - root - ERROR - Failed to extract features for patient TCGA-02-0055: int() argument must be a string, a bytes-like object or a real number, not 'list' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:22:52,247 - root - ERROR - Failed to extract features for patient TCGA-02-2466: int() argument must be a string, a bytes-like object or a real number, not 'list' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:22:52,266 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 0, Errors: 5 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-11 13:22:52,266 - root - INFO - Errors encountered for the following patients: TCGA-02-0003, TCGA-02-0033, TCGA-02-0047, TCGA-02-0055, TCGA-02-2466 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-11 13:22:52,269 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 13:28:09,155 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 13:28:09,159 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 13:28:09,159 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 13:28:09,159 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 13:28:09,160 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 13:28:09,160 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 13:28:09,209 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 13:28:09,375 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 13:28:14,546 - root - INFO - Feature extraction started at: 2024-11-11 13:28:14 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 13:28:14,546 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 13:28:14,546 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 13:30:47,339 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([805, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 13:30:48,113 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([618, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 13:30:49,133 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([832, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 13:30:49,975 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([703, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 13:30:51,431 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1208, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:218]
2024-11-11 13:30:51,431 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-11 13:30:51,435 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 13:38:09,356 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 13:38:09,366 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 13:38:09,366 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 13:38:09,367 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 13:38:09,368 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 13:38:09,369 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 13:38:09,435 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 13:38:09,620 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 13:38:14,977 - root - INFO - Feature extraction started at: 2024-11-11 13:38:14 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 13:38:14,977 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 13:38:14,977 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 13:40:44,693 - root - ERROR - Failed to extract features for patient TCGA-02-0003: only one element tensors can be converted to Python scalars [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:40:44,717 - root - ERROR - Failed to extract features for patient TCGA-02-0033: only one element tensors can be converted to Python scalars [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:40:44,737 - root - ERROR - Failed to extract features for patient TCGA-02-0047: only one element tensors can be converted to Python scalars [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:40:44,757 - root - ERROR - Failed to extract features for patient TCGA-02-0055: only one element tensors can be converted to Python scalars [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:40:44,778 - root - ERROR - Failed to extract features for patient TCGA-02-2466: only one element tensors can be converted to Python scalars [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:40:44,813 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 0, Errors: 5 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-11 13:40:44,813 - root - INFO - Errors encountered for the following patients: TCGA-02-0003, TCGA-02-0033, TCGA-02-0047, TCGA-02-0055, TCGA-02-2466 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-11 13:40:44,818 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 13:52:35,409 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 13:52:35,418 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 13:52:35,418 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 13:52:35,418 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 13:52:35,419 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 13:52:35,420 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 13:52:35,524 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 13:52:35,690 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 13:52:41,079 - root - INFO - Feature extraction started at: 2024-11-11 13:52:41 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 13:52:41,079 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 13:52:41,079 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 13:55:10,561 - root - ERROR - Failed to extract features for patient TCGA-02-0003: only one element tensors can be converted to Python scalars [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:55:10,572 - root - ERROR - Failed to extract features for patient TCGA-02-0033: only one element tensors can be converted to Python scalars [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:55:10,582 - root - ERROR - Failed to extract features for patient TCGA-02-0047: only one element tensors can be converted to Python scalars [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:55:10,594 - root - ERROR - Failed to extract features for patient TCGA-02-0055: only one element tensors can be converted to Python scalars [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:55:10,605 - root - ERROR - Failed to extract features for patient TCGA-02-2466: only one element tensors can be converted to Python scalars [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:55:10,630 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 0, Errors: 5 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-11 13:55:10,630 - root - INFO - Errors encountered for the following patients: TCGA-02-0003, TCGA-02-0033, TCGA-02-0047, TCGA-02-0055, TCGA-02-2466 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-11 13:55:10,634 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 13:56:48,382 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 13:56:48,388 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 13:56:48,388 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 13:56:48,388 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 13:56:48,388 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 13:56:48,389 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 13:56:48,483 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 13:56:48,633 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 13:56:54,697 - root - INFO - Feature extraction started at: 2024-11-11 13:56:54 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 13:56:54,697 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 13:56:54,697 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 13:59:23,832 - root - ERROR - Failed to extract features for patient TCGA-02-0003: int() argument must be a string, a bytes-like object or a real number, not 'list' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:59:23,843 - root - ERROR - Failed to extract features for patient TCGA-02-0033: int() argument must be a string, a bytes-like object or a real number, not 'list' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:59:23,852 - root - ERROR - Failed to extract features for patient TCGA-02-0047: int() argument must be a string, a bytes-like object or a real number, not 'list' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:59:23,862 - root - ERROR - Failed to extract features for patient TCGA-02-0055: int() argument must be a string, a bytes-like object or a real number, not 'list' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:59:23,871 - root - ERROR - Failed to extract features for patient TCGA-02-2466: int() argument must be a string, a bytes-like object or a real number, not 'list' [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:205]
2024-11-11 13:59:23,902 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 0, Errors: 5 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-11 13:59:23,902 - root - INFO - Errors encountered for the following patients: TCGA-02-0003, TCGA-02-0033, TCGA-02-0047, TCGA-02-0055, TCGA-02-2466 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-11 13:59:23,909 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 14:04:42,269 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 14:04:42,276 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 14:04:42,277 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 14:04:42,277 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 14:04:42,278 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 14:04:42,278 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 14:04:42,346 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 14:04:42,517 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 14:04:47,722 - root - INFO - Feature extraction started at: 2024-11-11 14:04:47 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 14:04:47,722 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 14:04:47,722 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 14:07:19,741 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([805, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 14:07:20,321 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([618, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 14:07:21,282 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([832, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 14:07:22,356 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([703, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 14:07:24,173 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1208, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:218]
2024-11-11 14:07:24,173 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-11 14:07:24,178 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 14:22:51,624 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 14:22:51,633 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 14:22:51,633 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 14:22:51,633 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 14:22:51,634 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 14:22:51,635 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 14:22:51,840 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 14:22:52,013 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 14:22:57,331 - root - INFO - Feature extraction started at: 2024-11-11 14:22:57 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 14:22:57,331 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 14:22:57,331 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 14:25:27,474 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 14:25:28,267 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([605, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 14:25:29,290 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([815, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 14:25:30,134 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([689, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 14:25:31,588 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1184, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:218]
2024-11-11 14:25:31,588 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-11 14:25:31,604 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 14:34:33,505 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'cls_token', 'per_mut': True, 'stack_feature': True, 'batch_size': 12, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 14:34:33,510 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 14:34:33,510 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 14:34:33,510 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 14:34:33,511 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 14:34:33,511 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:76]
2024-11-11 14:34:33,560 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 14:34:33,726 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 14:34:39,221 - root - INFO - Feature extraction started at: 2024-11-11 14:34:39 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 14:34:39,222 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 14:34:39,222 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 14:37:11,221 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 14:37:12,002 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([605, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 14:37:13,006 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([815, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 14:37:13,843 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([689, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 14:37:15,290 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1184, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:218]
2024-11-11 14:37:15,290 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:221]
2024-11-11 14:37:15,295 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-11 16:18:34,630 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'cls_token', 'batch_size': 12, 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 16:18:34,635 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 16:18:34,635 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 16:18:34,635 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 16:18:34,635 - src.cli - INFO - Stack feature: True [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:60]
2024-11-11 16:18:34,636 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:77]
2024-11-11 16:19:42,661 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'cls_token', 'batch_size': 12, 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 16:19:42,664 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 16:19:42,664 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 16:19:42,664 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 16:19:42,664 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:74]
2024-11-11 16:19:48,864 - root - INFO - Feature extraction started at: 2024-11-11 16:19:48 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 16:19:48,865 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 16:19:48,865 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 16:23:03,356 - root - ERROR - Failed to extract features for patient TCGA-02-0003:  [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:210]
2024-11-11 16:23:03,363 - root - ERROR - Failed to extract features for patient TCGA-02-0033:  [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:210]
2024-11-11 16:23:03,594 - root - ERROR - Failed to extract features for patient TCGA-02-0047:  [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:210]
2024-11-11 16:23:03,598 - root - ERROR - Failed to extract features for patient TCGA-02-0055:  [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:210]
2024-11-11 16:23:03,603 - root - ERROR - Failed to extract features for patient TCGA-02-2466:  [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:210]
2024-11-11 16:23:03,618 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 0, Errors: 5 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-11 16:23:03,618 - root - INFO - Errors encountered for the following patients: TCGA-02-0003, TCGA-02-0033, TCGA-02-0047, TCGA-02-0055, TCGA-02-2466 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:228]
2024-11-11 16:23:03,620 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:90]
2024-11-11 16:29:13,001 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'cls_token', 'batch_size': 12, 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 16:29:13,005 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 16:29:13,006 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 16:29:13,006 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 16:29:13,007 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:74]
2024-11-11 16:29:17,123 - root - INFO - Feature extraction started at: 2024-11-11 16:29:17 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 16:29:17,123 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 16:29:17,123 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 16:37:29,206 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 16:37:29,211 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 16:37:29,211 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 16:37:29,211 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 16:37:29,211 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:74]
2024-11-11 16:37:33,307 - root - INFO - Feature extraction started at: 2024-11-11 16:37:33 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 16:37:33,307 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 16:37:33,307 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 16:50:57,459 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 16:50:57,464 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 16:50:57,464 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 16:50:57,464 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 16:50:57,464 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:74]
2024-11-11 16:51:02,209 - root - INFO - Feature extraction started at: 2024-11-11 16:51:02 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 16:51:02,209 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 16:51:02,209 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 16:53:51,609 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([16, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 16:53:52,077 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([13, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 16:53:52,776 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([17, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 16:53:53,155 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([14, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 16:53:54,141 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([24, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-11 16:53:54,141 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-11 16:53:54,143 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:90]
2024-11-11 17:14:02,496 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 17:14:02,501 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 17:14:02,501 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 17:14:02,501 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 17:14:02,501 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:74]
2024-11-11 17:14:06,762 - root - INFO - Feature extraction started at: 2024-11-11 17:14:06 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 17:14:06,762 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 17:14:06,762 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 17:33:14,934 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 17:33:14,938 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 17:33:14,938 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 17:33:14,938 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 17:33:14,939 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:74]
2024-11-11 17:33:17,321 - root - INFO - Feature extraction started at: 2024-11-11 17:33:17 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 17:33:17,321 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 17:33:17,321 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 17:36:04,180 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([16, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 17:36:04,584 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([13, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 17:36:05,101 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([17, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 17:36:05,515 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([14, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 17:36:06,564 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([24, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-11 17:36:06,564 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-11 17:36:06,566 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:90]
2024-11-11 18:06:50,247 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-11 18:06:50,252 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-11 18:06:50,252 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-11 18:06:50,252 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-11 18:06:50,252 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:74]
2024-11-11 18:06:50,300 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-11 18:06:50,465 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-11 18:06:55,922 - root - INFO - Feature extraction started at: 2024-11-11 18:06:55 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-11 18:06:55,922 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-11 18:06:55,923 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-11 18:09:59,888 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 18:10:00,659 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([605, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 18:10:01,669 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([815, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 18:10:02,510 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([689, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-11 18:10:03,957 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1184, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-11 18:10:03,957 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-11 18:10:03,961 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:90]
2024-11-14 09:42:48,035 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-14 09:42:48,069 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-14 09:42:48,070 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-14 09:42:48,070 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-14 09:42:48,070 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:74]
2024-11-14 09:42:48,132 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-14 09:42:48,301 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-14 09:42:49,077 - root - INFO - Feature extraction started at: 2024-11-14 09:42:49 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-14 09:42:49,077 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-14 09:42:49,077 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-14 09:44:02,310 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([605952]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 09:44:06,928 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([464640]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 09:44:13,167 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([625920]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 09:44:18,750 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([529152]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 09:44:27,188 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([909312]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-14 09:44:27,188 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-14 09:44:27,201 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:90]
2024-11-14 09:56:46,682 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-14 09:56:46,684 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-14 09:56:46,684 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-14 09:56:46,684 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-14 09:56:46,685 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:74]
2024-11-14 09:56:46,708 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-14 09:56:46,887 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-14 09:56:47,386 - root - INFO - Feature extraction started at: 2024-11-14 09:56:47 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-14 09:56:47,386 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-14 09:56:47,386 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-14 09:57:59,441 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 09:58:03,216 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([605, 1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 09:58:08,249 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([815, 1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 09:58:12,544 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([689, 1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 09:58:19,392 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1184, 1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-14 09:58:19,392 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-14 09:58:19,401 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:90]
2024-11-14 11:16:50,191 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-14 11:16:50,193 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-14 11:16:50,193 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-14 11:16:50,193 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-14 11:16:50,193 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:74]
2024-11-14 11:16:50,218 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-14 11:16:50,376 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-14 11:16:51,020 - root - INFO - Feature extraction started at: 2024-11-14 11:16:51 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-14 11:16:51,020 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-14 11:16:51,020 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-14 11:18:08,424 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 11:18:12,452 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([605, 1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 11:18:18,149 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([815, 1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 11:18:22,789 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([689, 1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 11:18:30,352 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1184, 1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-14 11:18:30,352 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-14 11:18:30,366 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:90]
2024-11-14 11:39:23,988 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-14 11:39:24,005 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-14 11:39:24,005 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-14 11:39:24,005 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-14 11:39:24,005 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:74]
2024-11-14 11:39:24,031 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-14 11:39:24,209 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-14 11:39:24,894 - root - INFO - Feature extraction started at: 2024-11-14 11:39:24 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-14 11:39:24,894 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-14 11:39:24,894 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-14 11:43:25,424 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-14 11:43:25,426 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-14 11:43:25,427 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-14 11:43:25,427 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-14 11:43:25,427 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:74]
2024-11-14 11:43:25,450 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-14 11:43:25,621 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-14 11:43:26,308 - root - INFO - Feature extraction started at: 2024-11-14 11:43:26 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-14 11:43:26,308 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-14 11:43:26,308 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-14 11:44:43,854 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 11:44:47,962 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([605, 1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 11:44:53,341 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([815, 1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 11:44:57,954 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([689, 1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 11:45:05,648 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1184, 1, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-14 11:45:05,648 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-14 11:45:05,660 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:90]
2024-11-14 11:58:11,001 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-14 11:58:11,018 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-14 11:58:11,019 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-14 11:58:11,019 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-14 11:58:11,019 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:74]
2024-11-14 11:58:11,052 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-14 11:58:11,253 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-14 11:58:11,922 - root - INFO - Feature extraction started at: 2024-11-14 11:58:11 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-14 11:58:11,922 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-14 11:58:11,922 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-14 11:59:28,082 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 11:59:33,437 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([605, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 11:59:40,089 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([815, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 11:59:45,677 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([689, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 11:59:54,749 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1184, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-14 11:59:54,749 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-14 11:59:54,759 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:90]
2024-11-14 12:03:00,031 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-14 12:03:00,033 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-14 12:03:00,033 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-14 12:03:00,033 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-14 12:03:00,033 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:74]
2024-11-14 12:03:00,057 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-14 12:03:00,234 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-14 12:03:00,868 - root - INFO - Feature extraction started at: 2024-11-14 12:03:00 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-14 12:03:00,868 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-14 12:03:00,868 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-14 12:04:18,427 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 12:04:22,495 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([605, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 12:04:28,077 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([815, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 12:04:32,682 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([689, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 12:04:40,364 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1184, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-14 12:04:40,364 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-14 12:04:40,376 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:90]
2024-11-14 12:59:35,673 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-14 12:59:35,688 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-14 12:59:35,688 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-14 12:59:35,688 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-14 12:59:35,688 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:74]
2024-11-14 12:59:37,919 - root - INFO - Feature extraction started at: 2024-11-14 12:59:37 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-14 12:59:37,919 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-14 12:59:37,919 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-14 13:00:53,601 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([16, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 13:00:55,543 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([13, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 13:00:58,209 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([17, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 13:01:00,455 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([14, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 13:01:04,129 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([24, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-14 13:01:04,130 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-14 13:01:04,132 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:90]
2024-11-14 13:07:19,527 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-14 13:07:19,529 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-14 13:07:19,529 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-14 13:07:19,529 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-14 13:07:19,529 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:74]
2024-11-14 13:07:19,938 - root - INFO - Feature extraction started at: 2024-11-14 13:07:19 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-14 13:07:19,938 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-14 13:07:19,938 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-14 13:08:32,210 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([16, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 13:08:34,297 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([13, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 13:08:36,781 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([17, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 13:08:38,786 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([14, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 13:08:42,642 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([24, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-14 13:08:42,642 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-14 13:08:42,645 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:90]
2024-11-14 15:10:01,818 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-14 15:10:01,837 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-14 15:10:01,837 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-14 15:10:01,837 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-14 15:10:01,837 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:74]
2024-11-14 15:10:02,256 - root - INFO - Feature extraction started at: 2024-11-14 15:10:02 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-14 15:10:02,256 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-14 15:10:02,256 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-14 15:11:12,109 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([16, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 15:11:14,039 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([13, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 15:11:16,615 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([17, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 15:11:18,692 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([14, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 15:11:22,358 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([24, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-14 15:11:22,358 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-14 15:11:22,361 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:90]
2024-11-14 15:19:33,786 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-14 15:19:33,788 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-14 15:19:33,788 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-14 15:19:33,788 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-14 15:19:33,788 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:74]
2024-11-14 15:19:34,292 - root - INFO - Feature extraction started at: 2024-11-14 15:19:34 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-14 15:19:34,293 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-14 15:19:34,293 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-14 15:20:47,046 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([16, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 15:20:49,111 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([13, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 15:20:51,830 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([17, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 15:20:54,171 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([14, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 15:20:57,876 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([24, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-14 15:20:57,877 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-14 15:20:57,880 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:90]
2024-11-14 16:25:38,669 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': ['SEP'], 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-14 16:25:38,683 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-14 16:25:38,684 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-14 16:25:38,684 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-14 16:25:38,684 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-14 16:25:39,056 - root - INFO - Feature extraction started at: 2024-11-14 16:25:39 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-14 16:25:39,056 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-14 16:25:39,056 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-14 16:59:23,860 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': ['SEP'], 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-14 16:59:23,869 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-14 16:59:23,869 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-14 16:59:23,869 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-14 16:59:23,869 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-14 16:59:24,221 - root - INFO - Feature extraction started at: 2024-11-14 16:59:24 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-14 16:59:24,221 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-14 16:59:24,221 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-14 17:10:25,514 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-14 17:10:25,516 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-14 17:10:25,516 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-14 17:10:25,516 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-14 17:10:25,516 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-14 17:10:25,896 - root - INFO - Feature extraction started at: 2024-11-14 17:10:25 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-14 17:10:25,896 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-14 17:10:25,896 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-14 17:11:37,767 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([16, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 17:11:39,810 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([13, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 17:11:42,478 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([17, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 17:11:44,781 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([14, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 17:11:48,628 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([24, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-14 17:11:48,628 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-14 17:11:48,631 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-14 17:13:15,891 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-14 17:13:15,893 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-14 17:13:15,894 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-14 17:13:15,894 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-14 17:13:15,894 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-14 17:13:16,238 - root - INFO - Feature extraction started at: 2024-11-14 17:13:16 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-14 17:13:16,238 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-14 17:13:16,238 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-14 17:14:28,191 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 17:14:30,251 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([605, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 17:14:33,036 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([815, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 17:14:35,532 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([689, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 17:14:39,501 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1184, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-14 17:14:39,501 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-14 17:14:39,504 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-14 17:25:03,589 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-14 17:25:03,591 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-14 17:25:03,592 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-14 17:25:03,592 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-14 17:25:03,592 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-14 17:25:03,972 - root - INFO - Feature extraction started at: 2024-11-14 17:25:03 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-14 17:25:03,972 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-14 17:25:03,972 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-14 17:26:15,661 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 17:26:17,729 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([605, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 17:26:21,239 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([815, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 17:26:23,820 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([689, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 17:26:28,630 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1184, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-14 17:26:28,630 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-14 17:26:28,632 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-14 17:44:43,864 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-14 17:44:43,866 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-14 17:44:43,866 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-14 17:44:43,867 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-14 17:44:43,867 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-14 17:44:44,228 - root - INFO - Feature extraction started at: 2024-11-14 17:44:44 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-14 17:44:44,229 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-14 17:44:44,229 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-14 17:45:56,984 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 17:45:59,051 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([605, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 17:46:01,421 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([815, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 17:46:03,448 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([689, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:175]
2024-11-14 17:46:07,027 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1184, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-14 17:46:07,027 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-14 17:46:07,030 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-15 11:03:38,999 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-15 11:03:39,001 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-15 11:03:39,001 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-15 11:03:39,001 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-15 11:03:39,001 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-15 11:03:39,398 - root - INFO - Feature extraction started at: 2024-11-15 11:03:39 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-15 11:03:39,398 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-15 11:03:39,399 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-15 11:04:53,622 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([805, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-15 11:04:53,622 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-15 11:04:53,626 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-15 11:46:35,868 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-15 11:46:35,870 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-15 11:46:35,870 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-15 11:46:35,870 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-15 11:46:35,870 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-15 11:46:36,204 - root - INFO - Feature extraction started at: 2024-11-15 11:46:36 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-15 11:46:36,204 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-15 11:46:36,204 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-15 11:47:46,646 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([805, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-15 11:47:46,646 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-15 11:47:46,648 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-18 11:25:44,611 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 11:25:44,613 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 11:25:44,613 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 11:25:44,613 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 11:25:44,613 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 11:25:45,042 - root - INFO - Feature extraction started at: 2024-11-18 11:25:45 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 11:25:45,042 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 11:25:45,042 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 11:26:56,039 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([805, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-18 11:26:56,040 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-18 11:26:56,044 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-18 11:30:51,014 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 11:30:51,015 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 11:30:51,016 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 11:30:51,016 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 11:30:51,016 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 11:30:51,041 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-18 11:30:51,203 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-18 11:30:51,806 - root - INFO - Feature extraction started at: 2024-11-18 11:30:51 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 11:30:51,806 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 11:30:51,806 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 11:32:04,577 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-18 11:32:04,578 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-18 11:32:04,588 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-18 11:34:09,011 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 11:34:09,013 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 11:34:09,013 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 11:34:09,013 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 11:34:09,013 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 11:34:09,036 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-18 11:34:09,223 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-18 11:34:09,692 - root - INFO - Feature extraction started at: 2024-11-18 11:34:09 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 11:34:09,692 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 11:34:09,692 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 11:35:24,278 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-18 11:35:24,279 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-18 11:35:24,292 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-18 11:50:26,745 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 11:50:26,746 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 11:50:26,747 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 11:50:26,747 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 11:50:26,747 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 11:50:26,770 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-18 11:50:26,937 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-18 11:50:27,496 - root - INFO - Feature extraction started at: 2024-11-18 11:50:27 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 11:50:27,496 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 11:50:27,496 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 11:51:40,861 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([805, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-18 11:51:40,862 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-18 11:51:40,876 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-18 11:59:28,656 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 11:59:28,658 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 11:59:28,658 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 11:59:28,658 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 11:59:28,658 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 11:59:28,681 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-18 11:59:28,857 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-18 11:59:29,453 - root - INFO - Feature extraction started at: 2024-11-18 11:59:29 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 11:59:29,453 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 11:59:29,453 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 12:00:39,006 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([805, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-18 12:00:39,006 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-18 12:00:39,015 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-18 12:11:43,447 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 12:11:43,449 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 12:11:43,449 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 12:11:43,449 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 12:11:43,449 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 12:11:43,472 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-18 12:11:43,675 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-18 12:11:44,318 - root - INFO - Feature extraction started at: 2024-11-18 12:11:44 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 12:11:44,318 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 12:11:44,318 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 13:55:23,869 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 13:55:23,871 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 13:55:23,871 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 13:55:23,871 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 13:55:23,871 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 13:55:23,897 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-18 13:55:24,059 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-18 13:55:24,643 - root - INFO - Feature extraction started at: 2024-11-18 13:55:24 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 13:55:24,643 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 13:55:24,643 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 14:00:23,841 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 14:00:23,843 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 14:00:23,843 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 14:00:23,843 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 14:00:23,843 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 14:00:23,867 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-18 14:00:24,028 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-18 14:00:24,504 - root - INFO - Feature extraction started at: 2024-11-18 14:00:24 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 14:00:24,504 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 14:00:24,504 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 14:24:49,795 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 14:24:49,797 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 14:24:49,797 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 14:24:49,797 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 14:24:49,797 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 14:24:49,823 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-18 14:24:49,994 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-18 14:24:50,555 - root - INFO - Feature extraction started at: 2024-11-18 14:24:50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 14:24:50,556 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 14:24:50,556 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 14:33:40,161 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 14:33:40,163 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 14:33:40,163 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 14:33:40,164 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 14:33:40,164 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 14:33:40,191 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-18 14:33:40,369 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-18 14:33:40,953 - root - INFO - Feature extraction started at: 2024-11-18 14:33:40 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 14:33:40,954 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 14:33:40,954 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 14:34:50,884 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([805, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-18 14:34:50,884 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-18 14:34:50,899 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-18 14:36:06,249 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 14:36:06,251 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 14:36:06,251 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 14:36:06,251 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 14:36:06,251 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 14:36:06,277 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-18 14:36:06,452 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-18 14:36:06,982 - root - INFO - Feature extraction started at: 2024-11-18 14:36:06 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 14:36:06,982 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 14:36:06,982 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 15:46:28,404 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 15:46:28,406 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 15:46:28,407 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 15:46:28,407 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 15:46:28,407 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 15:46:28,422 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-18 15:46:28,573 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-18 15:46:29,134 - root - INFO - Feature extraction started at: 2024-11-18 15:46:29 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 15:46:29,135 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 15:46:29,135 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 15:47:46,253 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([805, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-18 15:47:46,254 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-18 15:47:46,266 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-18 15:57:41,825 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 15:57:41,827 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 15:57:41,828 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 15:57:41,828 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 15:57:41,828 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 15:57:41,843 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-18 15:57:42,045 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-18 15:57:42,621 - root - INFO - Feature extraction started at: 2024-11-18 15:57:42 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 15:57:42,621 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 15:57:42,621 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 16:04:22,825 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([805, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-18 16:04:22,826 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-18 16:04:22,835 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-18 16:07:11,120 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 16:07:11,122 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 16:07:11,122 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 16:07:11,122 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 16:07:11,122 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 16:07:11,137 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-18 16:07:11,291 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-18 16:07:11,845 - root - INFO - Feature extraction started at: 2024-11-18 16:07:11 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 16:07:11,845 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 16:07:11,845 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 16:10:19,407 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([1578, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-18 16:10:19,407 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-18 16:10:19,417 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-18 16:13:38,838 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 16:13:38,840 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 16:13:38,840 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 16:13:38,840 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 16:13:38,840 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 16:13:38,859 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-18 16:13:39,025 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-18 16:13:39,579 - root - INFO - Feature extraction started at: 2024-11-18 16:13:39 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 16:13:39,579 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 16:13:39,579 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 16:15:23,678 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([1578, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-18 16:15:23,679 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-18 16:15:23,691 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-18 16:23:46,874 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 16:23:46,876 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 16:23:46,876 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 16:23:46,876 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 16:23:46,876 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 16:23:46,890 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-18 16:23:47,056 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-18 16:23:47,588 - root - INFO - Feature extraction started at: 2024-11-18 16:23:47 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 16:23:47,588 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 16:23:47,588 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 16:25:35,070 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([2367, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-18 16:25:35,070 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-18 16:25:35,078 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-18 16:34:22,329 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 16:34:22,331 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 16:34:22,331 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 16:34:22,331 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 16:34:22,331 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 16:34:22,350 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-18 16:34:22,526 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-18 16:34:23,065 - root - INFO - Feature extraction started at: 2024-11-18 16:34:23 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 16:34:23,065 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 16:34:23,065 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 16:36:07,876 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-18 16:36:07,876 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-18 16:36:07,884 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-18 16:49:39,638 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 16:49:39,641 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 16:49:39,641 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 16:49:39,641 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 16:49:39,641 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 16:49:39,656 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-18 16:49:39,808 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-18 16:49:40,349 - root - INFO - Feature extraction started at: 2024-11-18 16:49:40 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 16:49:40,349 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 16:49:40,349 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 16:51:17,374 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-18 16:51:17,374 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-18 16:51:17,381 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-18 17:02:43,485 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 17:02:43,487 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 17:02:43,487 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 17:02:43,487 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 17:02:43,488 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 17:02:43,505 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-18 17:02:43,713 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-18 17:02:44,281 - root - INFO - Feature extraction started at: 2024-11-18 17:02:44 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 17:02:44,281 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 17:02:44,281 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 17:04:28,658 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-18 17:04:28,658 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-18 17:04:28,669 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-18 17:07:42,762 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 17:07:42,764 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 17:07:42,764 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 17:07:42,764 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 17:07:42,764 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 17:07:42,788 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-18 17:07:42,946 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-18 17:07:43,501 - root - INFO - Feature extraction started at: 2024-11-18 17:07:43 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 17:07:43,501 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 17:07:43,501 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 17:10:22,052 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-18 17:10:22,052 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-18 17:10:22,062 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-18 17:19:06,016 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 17:19:06,017 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 17:19:06,017 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 17:19:06,018 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 17:19:06,018 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 17:19:06,380 - root - INFO - Feature extraction started at: 2024-11-18 17:19:06 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 17:19:06,380 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 17:19:06,380 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 17:20:31,156 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-18 17:20:31,156 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-18 17:20:31,159 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-18 17:23:39,173 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-18 17:23:39,175 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-18 17:23:39,175 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-18 17:23:39,175 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-18 17:23:39,175 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-18 17:23:39,500 - root - INFO - Feature extraction started at: 2024-11-18 17:23:39 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-18 17:23:39,501 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-18 17:23:39,501 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-18 17:25:02,082 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-18 17:25:02,083 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-18 17:25:02,085 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-19 10:03:58,092 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 10:03:58,094 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 10:03:58,094 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-19 10:03:58,094 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 10:03:58,094 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 10:03:58,513 - root - INFO - Feature extraction started at: 2024-11-19 10:03:58 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-19 10:03:58,513 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 10:03:58,513 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-19 10:05:05,980 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:164]
2024-11-19 10:05:05,997 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 1, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-19 10:05:06,000 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-19 10:05:22,734 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 10:05:22,736 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 10:05:22,736 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-19 10:05:22,736 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 10:05:22,736 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 10:05:23,064 - root - INFO - Feature extraction started at: 2024-11-19 10:05:23 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-19 10:05:23,064 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 10:05:23,064 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-19 10:06:39,485 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([1578, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-19 10:06:39,486 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-19 10:06:39,488 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-19 10:07:49,860 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 10:07:49,861 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 10:07:49,862 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-19 10:07:49,862 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 10:07:49,862 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 10:07:50,188 - root - INFO - Feature extraction started at: 2024-11-19 10:07:50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-19 10:07:50,188 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 10:07:50,188 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-19 10:09:05,237 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-19 10:09:05,238 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-19 10:09:05,240 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-19 10:11:18,457 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 10:11:18,459 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 10:11:18,459 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-19 10:11:18,459 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 10:11:18,459 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 10:11:18,833 - root - INFO - Feature extraction started at: 2024-11-19 10:11:18 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-19 10:11:18,833 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 10:11:18,833 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-19 10:12:35,904 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-19 10:12:35,904 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-19 10:12:35,907 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-19 10:18:41,961 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 10:18:41,963 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 10:18:41,963 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-19 10:18:41,963 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 10:18:41,963 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 10:18:42,311 - root - INFO - Feature extraction started at: 2024-11-19 10:18:42 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-19 10:18:42,311 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 10:18:42,311 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-19 10:20:00,135 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([1578, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-19 10:20:00,135 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-19 10:20:00,138 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-19 10:30:13,853 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 10:30:13,855 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 10:30:13,855 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-19 10:30:13,855 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 10:30:13,855 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 10:30:13,880 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-19 10:30:14,059 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 10:30:14,663 - root - INFO - Feature extraction started at: 2024-11-19 10:30:14 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-19 10:30:14,663 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 10:30:14,663 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-19 10:31:46,134 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([1578, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-19 10:31:46,134 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-19 10:31:46,141 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-19 10:33:50,672 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'dnabert2', 'tokenizer_type': 'dnabert2_bpe', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 10:33:50,674 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 10:33:50,674 - src.cli - INFO - Using tokenizer: dnabert2_bpe with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-19 10:33:50,674 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 10:33:50,674 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 10:33:50,696 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-19 10:33:50,873 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 10:33:51,414 - root - INFO - Feature extraction started at: 2024-11-19 10:33:51 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-19 10:33:51,414 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 10:33:51,414 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-19 10:35:09,766 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([1578, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-19 10:35:09,766 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-19 10:35:09,774 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-19 10:45:01,553 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 10:45:01,555 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 10:45:01,555 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-19 10:45:01,555 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 10:45:01,555 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 10:45:01,913 - root - INFO - Feature extraction started at: 2024-11-19 10:45:01 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-19 10:45:01,913 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 10:45:01,913 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-19 10:46:20,112 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([1578, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-19 10:46:20,112 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-19 10:46:20,115 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-19 10:49:43,533 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna', 'tokenizer_type': 'hd_char', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 10:49:43,535 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'hyenadna-medium-160k-seqlen', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 10:49:43,535 - src.cli - INFO - Using tokenizer: hd_char with params: {'characters': ['A', 'C', 'G', 'T', 'N'], 'model_max_length': 32770} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:56]
2024-11-19 10:49:43,535 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 10:49:43,535 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 10:49:43,865 - root - INFO - Feature extraction started at: 2024-11-19 10:49:43 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-19 10:49:43,866 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 10:49:43,866 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-19 10:50:59,376 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([1578, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-19 10:50:59,376 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-19 10:50:59,379 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-19 13:21:33,321 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'dnabert2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 13:21:33,322 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 13:21:33,322 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 13:21:33,322 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 13:22:09,326 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'dnabert2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 13:22:09,327 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 13:22:09,327 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 13:22:09,327 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 13:23:37,789 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'dnabert2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 13:23:37,791 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 13:23:37,791 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 13:23:37,791 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 13:29:57,841 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'dnabert2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 13:29:57,842 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': True} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 13:29:57,842 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 13:29:57,842 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 13:29:57,864 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-19 13:29:58,034 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 13:29:58,036 - filelock - DEBUG - Attempting to acquire lock 140155480111888 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/6623217350bd5b1eff2dd4830e6872699d3dc5cd.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 13:29:58,037 - filelock - DEBUG - Lock 140155480111888 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/6623217350bd5b1eff2dd4830e6872699d3dc5cd.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 13:29:58,174 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 158 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 13:29:58,181 - filelock - DEBUG - Attempting to release lock 140155480111888 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/6623217350bd5b1eff2dd4830e6872699d3dc5cd.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 13:29:58,181 - filelock - DEBUG - Lock 140155480111888 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/6623217350bd5b1eff2dd4830e6872699d3dc5cd.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 13:29:58,314 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 13:29:58,315 - filelock - DEBUG - Attempting to acquire lock 140155480402192 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/3b3ab6d7aaf96050dbb992924867043e98bc4332.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 13:29:58,316 - filelock - DEBUG - Lock 140155480402192 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/3b3ab6d7aaf96050dbb992924867043e98bc4332.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 13:29:58,447 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer.json HTTP/11" 200 167908 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 13:29:58,477 - filelock - DEBUG - Attempting to release lock 140155480402192 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/3b3ab6d7aaf96050dbb992924867043e98bc4332.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 13:29:58,477 - filelock - DEBUG - Lock 140155480402192 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/3b3ab6d7aaf96050dbb992924867043e98bc4332.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 13:29:58,601 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/added_tokens.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 13:29:58,732 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/special_tokens_map.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 13:29:58,745 - root - INFO - Loading model from pretrained model: zhihan1996/DNABERT-2-117M [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:96]
2024-11-19 13:29:58,876 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 13:29:58,877 - filelock - DEBUG - Attempting to acquire lock 140155480399504 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/8a18497de4d4a3f1cd183e90766f4a06fa25c8d4.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 13:29:58,877 - filelock - DEBUG - Lock 140155480399504 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/8a18497de4d4a3f1cd183e90766f4a06fa25c8d4.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 13:29:59,005 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /zhihan1996/DNABERT-2-117M/resolve/main/config.json HTTP/11" 200 904 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 13:29:59,007 - filelock - DEBUG - Attempting to release lock 140155480399504 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/8a18497de4d4a3f1cd183e90766f4a06fa25c8d4.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 13:29:59,008 - filelock - DEBUG - Lock 140155480399504 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/8a18497de4d4a3f1cd183e90766f4a06fa25c8d4.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 13:29:59,127 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/configuration_bert.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 13:29:59,128 - filelock - DEBUG - Attempting to acquire lock 140155480402960 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/b27bed3d8ae09cd13fe64f8805bc2aef24e1ffec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 13:29:59,129 - filelock - DEBUG - Lock 140155480402960 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/b27bed3d8ae09cd13fe64f8805bc2aef24e1ffec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 13:29:59,253 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /zhihan1996/DNABERT-2-117M/resolve/main/configuration_bert.py HTTP/11" 200 1011 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 13:29:59,256 - filelock - DEBUG - Attempting to release lock 140155480402960 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/b27bed3d8ae09cd13fe64f8805bc2aef24e1ffec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 13:29:59,256 - filelock - DEBUG - Lock 140155480402960 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/b27bed3d8ae09cd13fe64f8805bc2aef24e1ffec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 13:29:59,399 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 13:29:59,522 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/bert_layers.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 13:29:59,523 - filelock - DEBUG - Attempting to acquire lock 140155480402832 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/611b73d92807d1a22ad5790cda9e234db35827e8.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 13:29:59,524 - filelock - DEBUG - Lock 140155480402832 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/611b73d92807d1a22ad5790cda9e234db35827e8.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 13:29:59,653 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /zhihan1996/DNABERT-2-117M/resolve/main/bert_layers.py HTTP/11" 200 40690 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 13:29:59,743 - filelock - DEBUG - Attempting to release lock 140155480402832 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/611b73d92807d1a22ad5790cda9e234db35827e8.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 13:29:59,743 - filelock - DEBUG - Lock 140155480402832 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/611b73d92807d1a22ad5790cda9e234db35827e8.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 13:29:59,886 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/flash_attn_triton.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 13:29:59,888 - filelock - DEBUG - Attempting to acquire lock 140155480402896 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/b2b946c06f8430153de15227b232d070e0fd62c9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 13:29:59,888 - filelock - DEBUG - Lock 140155480402896 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/b2b946c06f8430153de15227b232d070e0fd62c9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 13:30:00,018 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /zhihan1996/DNABERT-2-117M/resolve/main/flash_attn_triton.py HTTP/11" 200 42737 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 13:30:00,021 - filelock - DEBUG - Attempting to release lock 140155480402896 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/b2b946c06f8430153de15227b232d070e0fd62c9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 13:30:00,021 - filelock - DEBUG - Lock 140155480402896 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/b2b946c06f8430153de15227b232d070e0fd62c9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 13:30:00,157 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/bert_padding.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 13:30:00,159 - filelock - DEBUG - Attempting to acquire lock 140155470001936 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/4da59be166036b2df98589a0e0b5d01a7044747d.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 13:30:00,159 - filelock - DEBUG - Lock 140155470001936 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/4da59be166036b2df98589a0e0b5d01a7044747d.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 13:30:00,288 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /zhihan1996/DNABERT-2-117M/resolve/main/bert_padding.py HTTP/11" 200 6099 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 13:30:00,291 - filelock - DEBUG - Attempting to release lock 140155470001936 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/4da59be166036b2df98589a0e0b5d01a7044747d.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 13:30:00,291 - filelock - DEBUG - Lock 140155470001936 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/4da59be166036b2df98589a0e0b5d01a7044747d.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 13:30:00,441 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/pytorch_model.bin HTTP/11" 302 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 13:30:00,444 - filelock - DEBUG - Attempting to acquire lock 140155469999632 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/7ff39ec77a484dd01070a41bfd6e95cdd7247bec80fe357ab43a4be33687aeba.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 13:30:00,444 - filelock - DEBUG - Lock 140155469999632 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/7ff39ec77a484dd01070a41bfd6e95cdd7247bec80fe357ab43a4be33687aeba.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 13:30:00,448 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): cdn-lfs.hf.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-19 13:30:00,651 - urllib3.connectionpool - DEBUG - https://cdn-lfs.hf.co:443 "GET /repos/c6/3a/c63ada858e8c084035483c507224ff1f5644acc4b4265d36d0be2cdb9dc5aee4/7ff39ec77a484dd01070a41bfd6e95cdd7247bec80fe357ab43a4be33687aeba?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1732278600&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjI3ODYwMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9jNi8zYS9jNjNhZGE4NThlOGMwODQwMzU0ODNjNTA3MjI0ZmYxZjU2NDRhY2M0YjQyNjVkMzZkMGJlMmNkYjlkYzVhZWU0LzdmZjM5ZWM3N2E0ODRkZDAxMDcwYTQxYmZkNmU5NWNkZDcyNDdiZWM4MGZlMzU3YWI0M2E0YmUzMzY4N2FlYmE~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=nyUVfMvWyDgasvzyK8oum~gH8rUjvSZM8nFShAMBoX-K-QEd5e0TUNHPmLxbHrF~AUxfd9Pifavc4tv2tH4b8o~yvL2EGozmzvwJdOfXE18~ZHdViYnG9xKHZPD8LFvxmv9UcoW5LnIwZrM5BuvlGSrofT9TuBDr7x53VMmbs8lPWRlmDnEDUDe-XhqKMpv4gjWGaQugHOCkkxNDz0e5kGdBWkWBChhGgykhBoBOeUjlr6qZK2CoUB4LtEI99duWMujgl0dB5mXXE5rM0sreDsUTfl7~a-MDDsc4HcMBudk-LE8AHSXkEVNjLQ3GgH~P5AY1yPYTxhXxwtlSfxK6HQ__&Key-Pair-Id=K3RPWS32NSSJCE HTTP/11" 200 468354983 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 13:30:05,569 - filelock - DEBUG - Attempting to release lock 140155469999632 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/7ff39ec77a484dd01070a41bfd6e95cdd7247bec80fe357ab43a4be33687aeba.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 13:30:05,570 - filelock - DEBUG - Lock 140155469999632 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/7ff39ec77a484dd01070a41bfd6e95cdd7247bec80fe357ab43a4be33687aeba.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 13:30:06,094 - root - INFO - Feature extraction started at: 2024-11-19 13:30:06 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-19 13:30:06,095 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 13:30:06,095 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-19 13:36:38,667 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'dnabert2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 13:36:38,669 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 13:36:38,669 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 13:36:38,669 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 13:36:38,693 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/models--zhihan1996--DNABERT-2-117M/snapshots/d064dece8a8b41d9fb8729fbe3435278786931f1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:102]
2024-11-19 13:36:39,166 - root - INFO - Feature extraction started at: 2024-11-19 13:36:39 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-19 13:36:39,166 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 13:36:39,166 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-19 13:46:48,671 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'dnabert2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 13:46:48,672 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 13:46:48,672 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 13:46:48,672 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 13:46:48,693 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/models--zhihan1996--DNABERT-2-117M/snapshots/d064dece8a8b41d9fb8729fbe3435278786931f1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:96]
2024-11-19 13:46:48,697 - root - ERROR - Tokenizer was not initialized. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:23]
2024-11-19 14:03:07,867 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'dnabert2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 14:03:07,869 - src.cli - INFO - Using encoder: dnabert2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 14:03:07,869 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 14:03:07,869 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 14:03:07,890 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/models--zhihan1996--DNABERT-2-117M/snapshots/d064dece8a8b41d9fb8729fbe3435278786931f1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:96]
2024-11-19 14:03:07,894 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/models--zhihan1996--DNABERT-2-117M/snapshots/d064dece8a8b41d9fb8729fbe3435278786931f1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:108]
2024-11-19 14:03:08,424 - root - INFO - Feature extraction started at: 2024-11-19 14:03:08 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-19 14:03:08,424 - root - INFO - Model: dnabert2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 14:03:08,424 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-19 14:04:29,317 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([1578, 768]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:223]
2024-11-19 14:04:29,318 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:226]
2024-11-19 14:04:29,325 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-19 14:59:01,325 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 14:59:01,326 - src.cli - INFO - Using encoder: hyenadna2 with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': True} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 14:59:01,327 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 14:59:01,327 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 14:59:01,346 - root - INFO - Downloading tokenizer from LongSafari/hyenadna-medium-160k-seqlen-hf... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:221]
2024-11-19 14:59:01,350 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-19 14:59:01,523 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 14:59:01,526 - filelock - DEBUG - Attempting to acquire lock 139854085848400 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/7ce74d254992d0a401cf518851477fac1bf722b9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 14:59:01,526 - filelock - DEBUG - Lock 139854085848400 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/7ce74d254992d0a401cf518851477fac1bf722b9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 14:59:01,659 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tokenizer_config.json HTTP/11" 200 1482 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 14:59:01,665 - filelock - DEBUG - Attempting to release lock 139854085848400 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/7ce74d254992d0a401cf518851477fac1bf722b9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 14:59:01,666 - filelock - DEBUG - Lock 139854085848400 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/7ce74d254992d0a401cf518851477fac1bf722b9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 15:01:30,580 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 15:01:30,581 - src.cli - INFO - Using encoder: hyenadna2 with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': True} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 15:01:30,581 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 15:01:30,581 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 15:01:30,601 - root - INFO - Downloading tokenizer from LongSafari/hyenadna-medium-160k-seqlen-hf... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:221]
2024-11-19 15:01:30,603 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-19 15:01:30,757 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:01:30,887 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tokenization_hyena.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:01:30,889 - filelock - DEBUG - Attempting to acquire lock 139805683850768 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d45662fcdc5cc05be3f2c952ebb82c512d42f5ec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 15:01:30,889 - filelock - DEBUG - Lock 139805683850768 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d45662fcdc5cc05be3f2c952ebb82c512d42f5ec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 15:01:31,024 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tokenization_hyena.py HTTP/11" 200 4057 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:01:31,030 - filelock - DEBUG - Attempting to release lock 139805683850768 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d45662fcdc5cc05be3f2c952ebb82c512d42f5ec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 15:01:31,030 - filelock - DEBUG - Lock 139805683850768 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d45662fcdc5cc05be3f2c952ebb82c512d42f5ec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 15:01:31,594 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/added_tokens.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:01:31,733 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/special_tokens_map.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:01:31,734 - filelock - DEBUG - Attempting to acquire lock 139805683856336 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/b7a451170f6fb07dc5d71f2e0241f262502eaf13.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 15:01:31,735 - filelock - DEBUG - Lock 139805683856336 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/b7a451170f6fb07dc5d71f2e0241f262502eaf13.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 15:01:31,871 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/special_tokens_map.json HTTP/11" 200 971 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:01:31,874 - filelock - DEBUG - Attempting to release lock 139805683856336 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/b7a451170f6fb07dc5d71f2e0241f262502eaf13.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 15:01:31,874 - filelock - DEBUG - Lock 139805683856336 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/b7a451170f6fb07dc5d71f2e0241f262502eaf13.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 15:01:31,876 - root - INFO - Loading model from pretrained model: LongSafari/hyenadna-medium-160k-seqlen-hf [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:232]
2024-11-19 15:01:32,005 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:01:32,006 - filelock - DEBUG - Attempting to acquire lock 139810433769232 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d061bc164157135bd7ddfa4cddb8ad47d2de8541.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 15:01:32,006 - filelock - DEBUG - Lock 139810433769232 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d061bc164157135bd7ddfa4cddb8ad47d2de8541.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 15:01:32,135 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/config.json HTTP/11" 200 984 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:01:32,138 - filelock - DEBUG - Attempting to release lock 139810433769232 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d061bc164157135bd7ddfa4cddb8ad47d2de8541.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 15:01:32,138 - filelock - DEBUG - Lock 139810433769232 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d061bc164157135bd7ddfa4cddb8ad47d2de8541.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 15:01:32,268 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/configuration_hyena.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:01:32,269 - filelock - DEBUG - Attempting to acquire lock 139810431918224 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d8ca5c2f084d69e729672a845d3d6469ed12f18a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 15:01:32,270 - filelock - DEBUG - Lock 139810431918224 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d8ca5c2f084d69e729672a845d3d6469ed12f18a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 15:01:32,397 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/configuration_hyena.py HTTP/11" 200 3093 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:01:32,400 - filelock - DEBUG - Attempting to release lock 139810431918224 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d8ca5c2f084d69e729672a845d3d6469ed12f18a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 15:01:32,400 - filelock - DEBUG - Lock 139810431918224 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d8ca5c2f084d69e729672a845d3d6469ed12f18a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 15:01:32,537 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:01:32,668 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/modeling_hyena.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:01:32,669 - filelock - DEBUG - Attempting to acquire lock 139810431917328 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/24f0890027c2d360c72e01f6bdbcf0e6109b15e7.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 15:01:32,670 - filelock - DEBUG - Lock 139810431917328 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/24f0890027c2d360c72e01f6bdbcf0e6109b15e7.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 15:01:32,801 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/modeling_hyena.py HTTP/11" 200 22584 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:01:32,804 - filelock - DEBUG - Attempting to release lock 139810431917328 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/24f0890027c2d360c72e01f6bdbcf0e6109b15e7.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 15:01:32,804 - filelock - DEBUG - Lock 139810431917328 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/24f0890027c2d360c72e01f6bdbcf0e6109b15e7.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 15:01:32,939 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/configuration_hyena.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:01:33,088 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/pytorch_model.bin HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:01:33,216 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/pytorch_model.bin.index.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:01:33,219 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-19 15:01:33,376 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tf_model.h5 HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:01:33,379 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-19 15:01:33,540 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/flax_model.msgpack HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:12:15,957 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 15:12:15,958 - src.cli - INFO - Using encoder: hyenadna2 with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 15:12:15,958 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 15:12:15,958 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 15:12:15,978 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:227]
2024-11-19 15:12:16,008 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:238]
2024-11-19 15:13:18,158 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 15:13:18,160 - src.cli - INFO - Using encoder: hyenadna2 with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 15:13:18,160 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 15:13:18,160 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 15:13:18,184 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/.no_exist/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:228]
2024-11-19 15:18:47,692 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 15:18:47,693 - src.cli - INFO - Using encoder: hyenadna2 with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': True} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 15:18:47,693 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 15:18:47,693 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 15:18:47,712 - root - INFO - Downloading tokenizer from LongSafari/hyenadna-medium-160k-seqlen-hf... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:222]
2024-11-19 15:18:47,715 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-19 15:18:47,876 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:18:47,879 - filelock - DEBUG - Attempting to acquire lock 140679824768400 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/7ce74d254992d0a401cf518851477fac1bf722b9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 15:18:47,879 - filelock - DEBUG - Lock 140679824768400 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/7ce74d254992d0a401cf518851477fac1bf722b9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 15:18:48,026 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tokenizer_config.json HTTP/11" 200 1482 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:18:48,031 - filelock - DEBUG - Attempting to release lock 140679824768400 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/7ce74d254992d0a401cf518851477fac1bf722b9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 15:18:48,032 - filelock - DEBUG - Lock 140679824768400 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/7ce74d254992d0a401cf518851477fac1bf722b9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 15:18:48,156 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tokenization_hyena.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:18:48,158 - filelock - DEBUG - Attempting to acquire lock 140679825059088 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d45662fcdc5cc05be3f2c952ebb82c512d42f5ec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 15:18:48,158 - filelock - DEBUG - Lock 140679825059088 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d45662fcdc5cc05be3f2c952ebb82c512d42f5ec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 15:18:48,283 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tokenization_hyena.py HTTP/11" 200 4057 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:18:48,286 - filelock - DEBUG - Attempting to release lock 140679825059088 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d45662fcdc5cc05be3f2c952ebb82c512d42f5ec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 15:18:48,286 - filelock - DEBUG - Lock 140679825059088 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d45662fcdc5cc05be3f2c952ebb82c512d42f5ec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 15:18:48,423 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/added_tokens.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:18:48,555 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/special_tokens_map.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:18:48,557 - filelock - DEBUG - Attempting to acquire lock 140679811502480 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/b7a451170f6fb07dc5d71f2e0241f262502eaf13.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 15:18:48,557 - filelock - DEBUG - Lock 140679811502480 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/b7a451170f6fb07dc5d71f2e0241f262502eaf13.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 15:18:48,701 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/special_tokens_map.json HTTP/11" 200 971 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:18:48,703 - filelock - DEBUG - Attempting to release lock 140679811502480 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/b7a451170f6fb07dc5d71f2e0241f262502eaf13.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 15:18:48,704 - filelock - DEBUG - Lock 140679811502480 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/b7a451170f6fb07dc5d71f2e0241f262502eaf13.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 15:18:48,705 - root - INFO - Loading model from pretrained model: LongSafari/hyenadna-medium-160k-seqlen-hf [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:233]
2024-11-19 15:18:48,834 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:18:48,835 - filelock - DEBUG - Attempting to acquire lock 140679825059856 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d061bc164157135bd7ddfa4cddb8ad47d2de8541.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 15:18:48,836 - filelock - DEBUG - Lock 140679825059856 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d061bc164157135bd7ddfa4cddb8ad47d2de8541.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 15:18:48,954 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/config.json HTTP/11" 200 984 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:18:48,956 - filelock - DEBUG - Attempting to release lock 140679825059856 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d061bc164157135bd7ddfa4cddb8ad47d2de8541.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 15:18:48,957 - filelock - DEBUG - Lock 140679825059856 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d061bc164157135bd7ddfa4cddb8ad47d2de8541.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 15:18:49,083 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/configuration_hyena.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:18:49,084 - filelock - DEBUG - Attempting to acquire lock 140679825058768 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d8ca5c2f084d69e729672a845d3d6469ed12f18a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 15:18:49,084 - filelock - DEBUG - Lock 140679825058768 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d8ca5c2f084d69e729672a845d3d6469ed12f18a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 15:18:49,208 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/configuration_hyena.py HTTP/11" 200 3093 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:18:49,211 - filelock - DEBUG - Attempting to release lock 140679825058768 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d8ca5c2f084d69e729672a845d3d6469ed12f18a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 15:18:49,211 - filelock - DEBUG - Lock 140679825058768 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d8ca5c2f084d69e729672a845d3d6469ed12f18a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 15:18:49,343 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:18:49,482 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/modeling_hyena.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:18:49,484 - filelock - DEBUG - Attempting to acquire lock 140679811505744 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/24f0890027c2d360c72e01f6bdbcf0e6109b15e7.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 15:18:49,484 - filelock - DEBUG - Lock 140679811505744 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/24f0890027c2d360c72e01f6bdbcf0e6109b15e7.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 15:18:49,613 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/modeling_hyena.py HTTP/11" 200 22584 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:18:49,615 - filelock - DEBUG - Attempting to release lock 140679811505744 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/24f0890027c2d360c72e01f6bdbcf0e6109b15e7.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 15:18:49,615 - filelock - DEBUG - Lock 140679811505744 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/24f0890027c2d360c72e01f6bdbcf0e6109b15e7.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 15:18:49,739 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/configuration_hyena.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:18:49,880 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/pytorch_model.bin HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:18:50,008 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/pytorch_model.bin.index.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:18:50,011 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-19 15:18:50,171 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tf_model.h5 HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:18:50,174 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-19 15:18:50,335 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/flax_model.msgpack HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:23:08,316 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 15:23:08,317 - src.cli - INFO - Using encoder: hyenadna2 with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': True} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 15:23:08,317 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 15:23:08,317 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 15:23:08,338 - root - INFO - Downloading tokenizer from LongSafari/hyenadna-medium-160k-seqlen-hf... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:222]
2024-11-19 15:23:08,340 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-19 15:23:28,886 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 15:23:28,887 - src.cli - INFO - Using encoder: hyenadna2 with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': True} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 15:23:28,887 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 15:23:28,887 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 15:23:28,907 - root - INFO - Downloading tokenizer from LongSafari/hyenadna-medium-160k-seqlen-hf... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:222]
2024-11-19 15:23:28,909 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-19 15:23:29,114 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:23:29,116 - filelock - DEBUG - Attempting to acquire lock 139844471537104 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/7ce74d254992d0a401cf518851477fac1bf722b9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 15:23:29,116 - filelock - DEBUG - Lock 139844471537104 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/7ce74d254992d0a401cf518851477fac1bf722b9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 15:23:29,241 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tokenizer_config.json HTTP/11" 200 1482 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:23:29,247 - filelock - DEBUG - Attempting to release lock 139844471537104 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/7ce74d254992d0a401cf518851477fac1bf722b9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 15:23:29,247 - filelock - DEBUG - Lock 139844471537104 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/7ce74d254992d0a401cf518851477fac1bf722b9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 15:23:29,366 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tokenization_hyena.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:23:29,368 - filelock - DEBUG - Attempting to acquire lock 139844402620432 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d45662fcdc5cc05be3f2c952ebb82c512d42f5ec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 15:23:29,368 - filelock - DEBUG - Lock 139844402620432 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d45662fcdc5cc05be3f2c952ebb82c512d42f5ec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 15:23:29,497 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tokenization_hyena.py HTTP/11" 200 4057 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:23:29,499 - filelock - DEBUG - Attempting to release lock 139844402620432 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d45662fcdc5cc05be3f2c952ebb82c512d42f5ec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 15:23:29,499 - filelock - DEBUG - Lock 139844402620432 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d45662fcdc5cc05be3f2c952ebb82c512d42f5ec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 15:23:29,638 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/added_tokens.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:23:29,769 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/special_tokens_map.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:23:29,770 - filelock - DEBUG - Attempting to acquire lock 139844402679312 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/b7a451170f6fb07dc5d71f2e0241f262502eaf13.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 15:23:29,771 - filelock - DEBUG - Lock 139844402679312 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/b7a451170f6fb07dc5d71f2e0241f262502eaf13.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 15:23:29,907 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/special_tokens_map.json HTTP/11" 200 971 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:23:29,910 - filelock - DEBUG - Attempting to release lock 139844402679312 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/b7a451170f6fb07dc5d71f2e0241f262502eaf13.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 15:23:29,910 - filelock - DEBUG - Lock 139844402679312 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/b7a451170f6fb07dc5d71f2e0241f262502eaf13.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 15:23:29,911 - root - INFO - Loading model from pretrained model: LongSafari/hyenadna-medium-160k-seqlen-hf [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:233]
2024-11-19 15:23:30,032 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:23:30,033 - filelock - DEBUG - Attempting to acquire lock 139844402618960 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d061bc164157135bd7ddfa4cddb8ad47d2de8541.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 15:23:30,034 - filelock - DEBUG - Lock 139844402618960 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d061bc164157135bd7ddfa4cddb8ad47d2de8541.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 15:23:30,156 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/config.json HTTP/11" 200 984 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:23:30,159 - filelock - DEBUG - Attempting to release lock 139844402618960 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d061bc164157135bd7ddfa4cddb8ad47d2de8541.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 15:23:30,159 - filelock - DEBUG - Lock 139844402618960 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d061bc164157135bd7ddfa4cddb8ad47d2de8541.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 15:23:30,279 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/configuration_hyena.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:23:30,281 - filelock - DEBUG - Attempting to acquire lock 139844402618960 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d8ca5c2f084d69e729672a845d3d6469ed12f18a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 15:23:30,281 - filelock - DEBUG - Lock 139844402618960 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d8ca5c2f084d69e729672a845d3d6469ed12f18a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 15:23:30,414 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/configuration_hyena.py HTTP/11" 200 3093 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:23:30,417 - filelock - DEBUG - Attempting to release lock 139844402618960 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d8ca5c2f084d69e729672a845d3d6469ed12f18a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 15:23:30,417 - filelock - DEBUG - Lock 139844402618960 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d8ca5c2f084d69e729672a845d3d6469ed12f18a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 15:23:30,541 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:23:30,672 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/modeling_hyena.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:23:30,674 - filelock - DEBUG - Attempting to acquire lock 139844402684816 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/24f0890027c2d360c72e01f6bdbcf0e6109b15e7.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-19 15:23:30,674 - filelock - DEBUG - Lock 139844402684816 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/24f0890027c2d360c72e01f6bdbcf0e6109b15e7.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-19 15:23:30,801 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/modeling_hyena.py HTTP/11" 200 22584 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:23:30,803 - filelock - DEBUG - Attempting to release lock 139844402684816 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/24f0890027c2d360c72e01f6bdbcf0e6109b15e7.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-19 15:23:30,803 - filelock - DEBUG - Lock 139844402684816 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/24f0890027c2d360c72e01f6bdbcf0e6109b15e7.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-19 15:23:30,937 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/configuration_hyena.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:23:31,148 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/pytorch_model.bin HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:23:31,273 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/pytorch_model.bin.index.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:23:31,276 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-19 15:23:31,430 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tf_model.h5 HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 15:23:31,433 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-19 15:23:31,610 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/flax_model.msgpack HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-19 16:45:13,486 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 16:45:13,487 - src.cli - INFO - Using encoder: hyenadna2 with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 16:45:13,487 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 16:45:13,487 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 16:45:13,508 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:227]
2024-11-19 16:45:13,519 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:239]
2024-11-19 16:46:45,123 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 16:46:45,124 - src.cli - INFO - Using encoder: hyenadna2 with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 16:46:45,124 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 16:46:45,124 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 16:46:45,145 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:227]
2024-11-19 16:46:45,156 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:239]
2024-11-19 16:48:47,813 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 16:48:47,814 - src.cli - INFO - Using encoder: hyenadna2 with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 16:48:47,814 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 16:48:47,814 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 16:48:47,836 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:227]
2024-11-19 16:48:47,847 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:239]
2024-11-19 16:49:31,394 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 16:49:31,395 - src.cli - INFO - Using encoder: hyenadna2 with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 16:49:31,396 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 16:49:31,396 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 16:49:31,415 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:227]
2024-11-19 16:49:31,420 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:239]
2024-11-19 16:49:46,197 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 16:49:46,199 - src.cli - INFO - Using encoder: hyenadna2 with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 16:49:46,199 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 16:49:46,199 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 16:49:46,219 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:227]
2024-11-19 16:49:46,224 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:239]
2024-11-19 16:50:27,121 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 16:50:27,123 - src.cli - INFO - Using encoder: hyenadna2 with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 16:50:27,123 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 16:50:27,123 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 16:50:27,144 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:227]
2024-11-19 16:50:27,150 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:239]
2024-11-19 17:15:55,443 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 17:15:55,444 - src.cli - INFO - Using encoder: hyenadna2 with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 17:15:55,444 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 17:15:55,444 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 17:15:55,471 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:227]
2024-11-19 17:15:55,480 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:240]
2024-11-19 17:18:43,782 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 17:18:43,783 - src.cli - INFO - Using encoder: hyenadna2 with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 17:18:43,783 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 17:18:43,784 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 17:18:43,810 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:227]
2024-11-19 17:18:43,817 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:240]
2024-11-19 17:18:44,296 - root - INFO - Feature extraction started at: 2024-11-19 17:18:44 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:97]
2024-11-19 17:18:44,296 - root - INFO - Model: hyenadna2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 17:18:44,297 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:101]
2024-11-19 17:33:17,585 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 17:33:17,587 - src.cli - INFO - Using encoder: hyenadna2 with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 17:33:17,587 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 17:33:17,587 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 17:33:17,608 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:227]
2024-11-19 17:33:17,616 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:240]
2024-11-19 17:33:17,909 - root - INFO - Feature extraction started at: 2024-11-19 17:33:17 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 17:33:17,909 - root - INFO - Model: hyenadna2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-19 17:33:17,909 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:102]
2024-11-19 17:34:25,218 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:165]
2024-11-19 17:34:25,242 - root - INFO - 
Feature extraction completed. Processed: 0, Skipped: 1, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:227]
2024-11-19 17:34:25,244 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-19 17:34:41,322 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 17:34:41,323 - src.cli - INFO - Using encoder: hyenadna2 with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 17:34:41,323 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 17:34:41,323 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 17:34:41,344 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:227]
2024-11-19 17:34:41,349 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:240]
2024-11-19 17:34:41,600 - root - INFO - Feature extraction started at: 2024-11-19 17:34:41 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 17:34:41,601 - root - INFO - Model: hyenadna2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-19 17:34:41,601 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:102]
2024-11-19 17:56:26,821 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 17:56:26,823 - src.cli - INFO - Using encoder: hyenadna2 with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 17:56:26,823 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 17:56:26,823 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 17:56:26,843 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:227]
2024-11-19 17:56:26,850 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:240]
2024-11-19 17:56:27,160 - root - INFO - Feature extraction started at: 2024-11-19 17:56:27 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 17:56:27,160 - root - INFO - Model: hyenadna2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-19 17:56:27,160 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:102]
2024-11-19 18:01:19,509 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 18:01:19,510 - src.cli - INFO - Using encoder: hyenadna2 with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 18:01:19,510 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 18:01:19,510 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 18:01:19,543 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:227]
2024-11-19 18:01:19,550 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:240]
2024-11-19 18:01:19,865 - root - INFO - Feature extraction started at: 2024-11-19 18:01:19 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 18:01:19,865 - root - INFO - Model: hyenadna2
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-19 18:01:19,865 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:102]
2024-11-19 18:02:38,918 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([1578, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:224]
2024-11-19 18:02:38,918 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:227]
2024-11-19 18:02:38,921 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-19 18:21:07,974 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 18:21:49,135 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 18:21:49,136 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 18:21:49,136 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 18:21:49,136 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 18:21:49,156 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:227]
2024-11-19 18:21:49,163 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:240]
2024-11-19 18:21:49,468 - root - INFO - Feature extraction started at: 2024-11-19 18:21:49 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 18:21:49,468 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-19 18:21:49,468 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:102]
2024-11-19 18:23:05,630 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([1578, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:224]
2024-11-19 18:23:05,630 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:227]
2024-11-19 18:23:05,632 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-19 18:29:40,988 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 18:29:40,989 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 18:29:40,989 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 18:29:40,989 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 18:29:41,008 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:227]
2024-11-19 18:29:41,017 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:240]
2024-11-19 18:29:41,296 - root - INFO - Feature extraction started at: 2024-11-19 18:29:41 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 18:29:41,297 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-19 18:29:41,297 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:102]
2024-11-19 18:35:15,749 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 1, 'encoder_name': 'hyenadna', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-19 18:35:15,750 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-19 18:35:15,750 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-19 18:35:15,750 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-19 18:35:15,769 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:227]
2024-11-19 18:35:15,778 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:238]
2024-11-19 18:35:16,078 - root - INFO - Feature extraction started at: 2024-11-19 18:35:16 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-19 18:35:16,078 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-19 18:35:16,078 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:102]
2024-11-19 18:36:29,172 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([1578, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:224]
2024-11-19 18:36:29,172 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:227]
2024-11-19 18:36:29,174 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-20 12:30:53,705 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-20 12:30:53,708 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-20 12:30:53,708 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-20 12:30:53,708 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-20 12:30:53,758 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:163]
2024-11-20 12:30:53,770 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:174]
2024-11-20 12:30:55,293 - root - INFO - Feature extraction started at: 2024-11-20 12:30:55 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-20 12:30:55,293 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-20 12:30:55,293 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:102]
2024-11-20 12:32:27,028 - root - INFO - Skipping patient TCGA-02-0003 (features already exist) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:165]
2024-11-20 12:34:26,150 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([605, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:176]
2024-11-20 13:31:42,945 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'hyenadna', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-20 13:31:42,949 - src.cli - INFO - Using encoder: hyenadna with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-20 13:31:42,949 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-20 13:31:42,949 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-20 13:31:42,983 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:163]
2024-11-20 13:31:42,999 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:174]
2024-11-20 13:31:45,552 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/accelerate/utils/modeling.py:1014]
2024-11-20 13:31:46,762 - root - INFO - Feature extraction started at: 2024-11-20 13:31:46 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-20 13:31:46,762 - root - INFO - Model: hyenadna
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-20 13:31:46,762 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:102]
2024-11-20 13:34:24,842 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:176]
2024-11-20 13:34:25,786 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([605, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:176]
2024-11-20 13:34:26,788 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([815, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:176]
2024-11-20 13:34:27,668 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([689, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:176]
2024-11-20 13:34:32,001 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1184, 256]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:224]
2024-11-20 13:34:32,001 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:227]
2024-11-20 13:34:32,007 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-20 13:53:46,113 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'nt', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-20 13:53:46,117 - src.cli - INFO - Using encoder: nt with params: {'pretrained_model_name': 'InstaDeepAI/nucleotide-transformer-v2-500m-multi-species', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer', 'download': True} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-20 13:53:46,118 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-20 13:53:46,118 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-20 13:53:46,148 - root - INFO - Downloading tokenizer from InstaDeepAI/nucleotide-transformer-v2-500m-multi-species... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:221]
2024-11-20 13:53:46,153 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-20 13:53:46,365 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 13:53:46,378 - filelock - DEBUG - Attempting to acquire lock 140113240863120 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/329c0d1008755f3b4a13c5c731c919a4968da554.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-20 13:53:46,382 - filelock - DEBUG - Lock 140113240863120 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/329c0d1008755f3b4a13c5c731c919a4968da554.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-20 13:53:46,512 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/tokenizer_config.json HTTP/11" 200 129 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 13:53:46,534 - filelock - DEBUG - Attempting to release lock 140113240863120 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/329c0d1008755f3b4a13c5c731c919a4968da554.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-20 13:53:46,535 - filelock - DEBUG - Lock 140113240863120 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/329c0d1008755f3b4a13c5c731c919a4968da554.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-20 13:53:46,757 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/vocab.txt HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 13:53:46,761 - filelock - DEBUG - Attempting to acquire lock 140113240914000 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/07d69f8c7001350597818d8853d85ef0c203bda2.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-20 13:53:46,764 - filelock - DEBUG - Lock 140113240914000 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/07d69f8c7001350597818d8853d85ef0c203bda2.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-20 13:53:46,900 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/vocab.txt HTTP/11" 200 28718 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 13:53:46,926 - filelock - DEBUG - Attempting to release lock 140113240914000 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/07d69f8c7001350597818d8853d85ef0c203bda2.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-20 13:53:46,928 - filelock - DEBUG - Lock 140113240914000 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/07d69f8c7001350597818d8853d85ef0c203bda2.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-20 13:53:47,065 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/added_tokens.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 13:53:47,219 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/special_tokens_map.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 13:53:47,223 - filelock - DEBUG - Attempting to acquire lock 140113240914320 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/ac47d8ff84d2793441964824395dba33d5146227.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-20 13:53:47,232 - filelock - DEBUG - Lock 140113240914320 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/ac47d8ff84d2793441964824395dba33d5146227.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-20 13:53:47,371 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/special_tokens_map.json HTTP/11" 200 101 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 13:53:47,395 - filelock - DEBUG - Attempting to release lock 140113240914320 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/ac47d8ff84d2793441964824395dba33d5146227.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-20 13:53:47,396 - filelock - DEBUG - Lock 140113240914320 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/ac47d8ff84d2793441964824395dba33d5146227.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-20 13:53:47,540 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/tokenizer.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 13:53:47,563 - root - INFO - Loading model from pretrained model: InstaDeepAI/nucleotide-transformer-v2-500m-multi-species [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:232]
2024-11-20 13:53:47,688 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 13:53:47,691 - filelock - DEBUG - Attempting to acquire lock 140113241015248 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/5de84a4d9f06eac63228d803da37dbfcd086b140.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-20 13:53:47,702 - filelock - DEBUG - Lock 140113241015248 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/5de84a4d9f06eac63228d803da37dbfcd086b140.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-20 13:53:47,833 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/config.json HTTP/11" 200 1065 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 13:53:47,844 - filelock - DEBUG - Attempting to release lock 140113241015248 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/5de84a4d9f06eac63228d803da37dbfcd086b140.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-20 13:53:47,845 - filelock - DEBUG - Lock 140113241015248 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/5de84a4d9f06eac63228d803da37dbfcd086b140.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-20 13:53:47,979 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/adapter_config.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 13:53:48,108 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/esm_config.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 13:53:48,110 - filelock - DEBUG - Attempting to acquire lock 140113241016208 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/23313afb28fe512badf134e9d1ce08e405e3656c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-20 13:53:48,114 - filelock - DEBUG - Lock 140113241016208 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/23313afb28fe512badf134e9d1ce08e405e3656c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-20 13:53:48,244 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/esm_config.py HTTP/11" 200 14876 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 13:53:48,252 - filelock - DEBUG - Attempting to release lock 140113241016208 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/23313afb28fe512badf134e9d1ce08e405e3656c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-20 13:53:48,253 - filelock - DEBUG - Lock 140113241016208 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/23313afb28fe512badf134e9d1ce08e405e3656c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-20 13:53:48,506 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/modeling_esm.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 13:53:48,509 - filelock - DEBUG - Attempting to acquire lock 140113192832656 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/967189e3be48c42bb5a6af4b8243b54590cbe929.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-20 13:53:48,513 - filelock - DEBUG - Lock 140113192832656 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/967189e3be48c42bb5a6af4b8243b54590cbe929.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-20 13:53:48,643 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/modeling_esm.py HTTP/11" 200 58184 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 13:53:48,744 - filelock - DEBUG - Attempting to release lock 140113192832656 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/967189e3be48c42bb5a6af4b8243b54590cbe929.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-20 13:53:48,745 - filelock - DEBUG - Lock 140113192832656 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/967189e3be48c42bb5a6af4b8243b54590cbe929.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-20 13:53:48,895 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/adapter_config.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 13:53:49,030 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/model.safetensors HTTP/11" 302 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 13:53:49,034 - filelock - DEBUG - Attempting to acquire lock 140113192836816 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/7a00ffaaf8f3ca627741a61e568d7e550b5c79aada70c76c8cb861192fbe7c59.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-20 13:53:49,038 - filelock - DEBUG - Lock 140113192836816 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/7a00ffaaf8f3ca627741a61e568d7e550b5c79aada70c76c8cb861192fbe7c59.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-20 13:53:49,042 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): cdn-lfs.hf.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-20 13:53:49,430 - urllib3.connectionpool - DEBUG - https://cdn-lfs.hf.co:443 "GET /repos/2e/ce/2ece3c9892edcfec41d0a4379b979570588b74988477fa7f4f9409873156d0dd/7a00ffaaf8f3ca627741a61e568d7e550b5c79aada70c76c8cb861192fbe7c59?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1732370028&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjM3MDAyOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8yZS9jZS8yZWNlM2M5ODkyZWRjZmVjNDFkMGE0Mzc5Yjk3OTU3MDU4OGI3NDk4ODQ3N2ZhN2Y0Zjk0MDk4NzMxNTZkMGRkLzdhMDBmZmFhZjhmM2NhNjI3NzQxYTYxZTU2OGQ3ZTU1MGI1Yzc5YWFkYTcwYzc2YzhjYjg2MTE5MmZiZTdjNTk~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=UBmrn89ziorDJN9JwciraSXbLJt2ose-yyp65Us~D0IXw7dpHWkykBBCovWE81aKRnfUR9rQZqhpcFefvDbcIz7XI63UvOKW6CGxK1n12~hXINYbnCSo155f3QS2JmOq-lExa3-LlJRpGTS7MTAd5qVcDbdw7aabLR1CMhMU-I75dNU3-v1GTVT9~fdN2Ly8ZSgwIrdsnDFtSV-mOIed1~KEWtSSuWSvi8L7EiPxZ7rizcN9idp6y961Zn1DCIhy1vd5KokxUuJr1WmIY4tm-2QeiHJ6k4cJNRhzmmvqdiITFCmp5-Qum3RYj-6kB9a6BqmNes5p~TxDpFDMIUlySg__&Key-Pair-Id=K3RPWS32NSSJCE HTTP/11" 200 1993438552 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 13:54:34,401 - filelock - DEBUG - Attempting to release lock 140113192836816 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/7a00ffaaf8f3ca627741a61e568d7e550b5c79aada70c76c8cb861192fbe7c59.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-20 13:54:34,402 - filelock - DEBUG - Lock 140113192836816 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/7a00ffaaf8f3ca627741a61e568d7e550b5c79aada70c76c8cb861192fbe7c59.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-20 13:54:35,588 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk). [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/accelerate/utils/modeling.py:1014]
2024-11-20 13:54:54,430 - root - INFO - Feature extraction started at: 2024-11-20 13:54:54 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-20 13:54:54,430 - root - INFO - Model: nt
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-20 13:54:54,430 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:102]
2024-11-20 14:43:32,692 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 50, 'encoder_name': 'nt', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-20 14:43:32,698 - src.cli - INFO - Using encoder: nt with params: {'pretrained_model_name': 'InstaDeepAI/nucleotide-transformer-v2-500m-multi-species', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-20 14:43:32,698 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-20 14:43:32,700 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-20 14:43:32,736 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/snapshots/f1fd7a1df5b19d31b88f11db1ce87caeb1ea4d2a [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:227]
2024-11-20 14:43:32,764 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/snapshots/f1fd7a1df5b19d31b88f11db1ce87caeb1ea4d2a [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:238]
2024-11-20 14:43:53,663 - root - INFO - Feature extraction started at: 2024-11-20 14:43:53 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-20 14:43:53,663 - root - INFO - Model: nt
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-20 14:43:53,663 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:102]
2024-11-20 14:46:44,081 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([866, 1024]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:176]
2024-11-20 14:46:46,773 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([671, 1024]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:176]
2024-11-20 14:46:50,160 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([883, 1024]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:176]
2024-11-20 14:46:53,080 - root - INFO - Saved features for patient TCGA-02-0055, final extracted features shape torch.Size([754, 1024]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:176]
2024-11-20 14:46:57,750 - root - INFO - Saved features for patient TCGA-02-2466, final extracted features shape torch.Size([1348, 1024]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:224]
2024-11-20 14:46:57,750 - root - INFO - 
Feature extraction completed. Processed: 5, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:227]
2024-11-20 14:46:57,761 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-20 15:13:58,863 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'nt', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-20 15:13:58,866 - src.cli - INFO - Using encoder: nt with params: {'pretrained_model_name': 'InstaDeepAI/nucleotide-transformer-v2-500m-multi-species', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-20 15:13:58,866 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-20 15:13:58,866 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-20 15:13:58,902 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/snapshots/f1fd7a1df5b19d31b88f11db1ce87caeb1ea4d2a [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:227]
2024-11-20 15:13:58,920 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/snapshots/f1fd7a1df5b19d31b88f11db1ce87caeb1ea4d2a [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:238]
2024-11-20 15:14:19,484 - root - INFO - Feature extraction started at: 2024-11-20 15:14:19 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-20 15:14:19,484 - root - INFO - Model: nt
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-20 15:14:19,484 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:102]
2024-11-20 15:58:58,864 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'ef', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-20 15:58:58,869 - src.cli - INFO - Using encoder: ef with params: {'pretrained_model_name': 'EleutherAI/enformer-official-rough', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer', 'download': True} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-20 15:58:58,869 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-20 15:58:58,870 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-20 15:59:56,200 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'ef', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-20 15:59:56,204 - src.cli - INFO - Using encoder: ef with params: {'pretrained_model_name': 'EleutherAI/enformer-official-rough', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer', 'download': True} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-20 15:59:56,204 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-20 15:59:56,204 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-20 15:59:56,237 - root - INFO - Loading model from pretrained model: EleutherAI/enformer-official-rough [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:327]
2024-11-20 15:59:56,242 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-20 15:59:56,468 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 15:59:56,484 - filelock - DEBUG - Attempting to acquire lock 140667265328720 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/e50a83cf5e2b127669849109f24c5edcc9361788.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-20 15:59:56,488 - filelock - DEBUG - Lock 140667265328720 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/e50a83cf5e2b127669849109f24c5edcc9361788.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-20 15:59:56,617 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /EleutherAI/enformer-official-rough/resolve/main/config.json HTTP/11" 200 439 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 15:59:56,639 - filelock - DEBUG - Attempting to release lock 140667265328720 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/e50a83cf5e2b127669849109f24c5edcc9361788.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-20 15:59:56,640 - filelock - DEBUG - Lock 140667265328720 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/e50a83cf5e2b127669849109f24c5edcc9361788.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-20 15:59:56,768 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/adapter_config.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 15:59:56,903 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 15:59:57,135 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/model.safetensors HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 15:59:57,268 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/model.safetensors.index.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 15:59:57,407 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/pytorch_model.bin HTTP/11" 302 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 15:59:57,411 - filelock - DEBUG - Attempting to acquire lock 140667265448208 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-20 15:59:57,415 - filelock - DEBUG - Lock 140667265448208 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-20 15:59:57,420 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): cdn-lfs.hf.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-20 15:59:57,654 - urllib3.connectionpool - DEBUG - https://cdn-lfs.hf.co:443 "GET /repos/66/eb/66eb21fc2fbae75237b909a4b84d41cb1dce65f654cb9640fdbb51e78b6c13d2/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1732377597&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjM3NzU5N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy82Ni9lYi82NmViMjFmYzJmYmFlNzUyMzdiOTA5YTRiODRkNDFjYjFkY2U2NWY2NTRjYjk2NDBmZGJiNTFlNzhiNmMxM2QyLzk5YjA5ZDYwMmUxOTVkODljN2Q0ZGViZTE0NGJiMmY0MzkwN2JhMGQ3NDAwNmU5NzA5OGU5OWQ5MTcxYzQzOWM~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=XFwJj0WW1gQeeMuXr2aPHj1jO517BnOeHlTsRQr4S8UNwnywWd1VFFd1YfBpaskZLgSFRoTCfED4UfvKbH3orvCB2GNJ81u0WP8YCFjij96OGVciH0yDrxxDzZwvp62omlJwOmmMnLDTETp9uiZBSZdxxmu5pA1JgvDazbtxpqaWBluL~ZV7trRmbLmgxA8-JuIRXcL8whlNvY3CAy9XGAScz0PRl5Dx8MMJWrnL5pvcNdULLfzLnF5dCKVs4nJffsBe721sNGTccmavzYSkIQwIONRPlrz66ZynjyMPAlY8DJU5TvpZHeFPuFn-iuBjBfT3CAgWghOTIU~lwsyVcg__&Key-Pair-Id=K3RPWS32NSSJCE HTTP/11" 200 1005149571 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:00:15,686 - filelock - DEBUG - Attempting to release lock 140667265448208 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-20 16:00:15,687 - filelock - DEBUG - Lock 140667265448208 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-20 16:00:15,833 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/model.safetensors HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:00:15,837 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-20 16:00:16,014 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/EleutherAI/enformer-official-rough HTTP/11" 200 783 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:00:16,181 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/EleutherAI/enformer-official-rough/commits/main HTTP/11" 200 1073 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:00:16,320 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/EleutherAI/enformer-official-rough/discussions?p=0 HTTP/11" 200 565 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:00:16,608 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/EleutherAI/enformer-official-rough/commits/refs%2Fpr%2F1 HTTP/11" 200 2038 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:00:16,610 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): safetensors-convert.hf.space:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-20 16:00:17,130 - urllib3.connectionpool - DEBUG - https://safetensors-convert.hf.space:443 "POST /call/run HTTP/11" 200 47 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:00:17,132 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): safetensors-convert.hf.space:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-20 16:00:17,611 - urllib3.connectionpool - DEBUG - https://safetensors-convert.hf.space:443 "GET /call/run/a813d104dc604da9a2f6734f9b4b2f1a HTTP/11" 200 None [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:00:19,148 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/EleutherAI/enformer-official-rough/commits/main HTTP/11" 200 1073 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:00:19,294 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/EleutherAI/enformer-official-rough/discussions?p=0 HTTP/11" 200 565 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:00:19,428 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/EleutherAI/enformer-official-rough/commits/refs%2Fpr%2F1 HTTP/11" 200 2038 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:00:19,616 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/refs%2Fpr%2F1/model.safetensors.index.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:00:19,750 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/refs%2Fpr%2F1/model.safetensors HTTP/11" 302 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:00:19,761 - filelock - DEBUG - Attempting to acquire lock 140667265966864 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/106d4b9e0b12a66e4ac32323705793ee450a15e882350bfdf58402b0e23972da.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-20 16:00:19,765 - filelock - DEBUG - Lock 140667265966864 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/106d4b9e0b12a66e4ac32323705793ee450a15e882350bfdf58402b0e23972da.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-20 16:00:19,771 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): cdn-lfs.hf.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-20 16:00:20,226 - urllib3.connectionpool - DEBUG - https://cdn-lfs.hf.co:443 "GET /repos/66/eb/66eb21fc2fbae75237b909a4b84d41cb1dce65f654cb9640fdbb51e78b6c13d2/106d4b9e0b12a66e4ac32323705793ee450a15e882350bfdf58402b0e23972da?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1732377619&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjM3NzYxOX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy82Ni9lYi82NmViMjFmYzJmYmFlNzUyMzdiOTA5YTRiODRkNDFjYjFkY2U2NWY2NTRjYjk2NDBmZGJiNTFlNzhiNmMxM2QyLzEwNmQ0YjllMGIxMmE2NmU0YWMzMjMyMzcwNTc5M2VlNDUwYTE1ZTg4MjM1MGJmZGY1ODQwMmIwZTIzOTcyZGE~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=PnG9uez9KgbVgONZfdg1GSbVbsXSL2fGWAmZLEcIkziZmcwi9KDxKx7v0O-Q0Y8c8tq2JrG~FE-kFt9xJsAWEZbcFKk8ea61te0P~R8SfBHRxP68tpH-vXy4X7mRgQq8EhE7J5nCzAj-uEXnnvCoFKsvKhgr-6lgCsyzTg7YyGbwk4qVCL393UeoXKrqgnUgTgYXEkYKo7xsDboZjL84~w0c7q87dYpsdpsmGtQLUUd069H6sXT5z3MDnofXbwbqII-dXpt1EnsVzAGN56zCMxWA7uAk3Pk3UjMF9qFE--W166slxgDWKk3YHFk8Fw5PpzHoG2Mr0rN~nGI62UvOtg__&Key-Pair-Id=K3RPWS32NSSJCE HTTP/11" 200 1005049584 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:00:47,952 - filelock - DEBUG - Attempting to release lock 140667265966864 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/106d4b9e0b12a66e4ac32323705793ee450a15e882350bfdf58402b0e23972da.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-20 16:00:47,953 - filelock - DEBUG - Lock 140667265966864 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/106d4b9e0b12a66e4ac32323705793ee450a15e882350bfdf58402b0e23972da.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-20 16:03:18,448 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'ef', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-20 16:03:18,451 - src.cli - INFO - Using encoder: ef with params: {'pretrained_model_name': 'EleutherAI/enformer-official-rough', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-20 16:03:18,451 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-20 16:03:18,451 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-20 16:03:18,476 - root - ERROR - Model checkpoint does not exist. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:331]
2024-11-20 16:06:23,930 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'ef', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-20 16:06:23,933 - src.cli - INFO - Using encoder: ef with params: {'pretrained_model_name': 'EleutherAI/enformer-official-rough', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer', 'download': True} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-20 16:06:23,933 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-20 16:06:23,934 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-20 16:06:24,024 - root - INFO - Loading model from pretrained model: EleutherAI/enformer-official-rough [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:327]
2024-11-20 16:06:24,027 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-20 16:06:24,259 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:06:24,273 - filelock - DEBUG - Attempting to acquire lock 140516724379856 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/e50a83cf5e2b127669849109f24c5edcc9361788.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-20 16:06:24,276 - filelock - DEBUG - Lock 140516724379856 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/e50a83cf5e2b127669849109f24c5edcc9361788.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-20 16:06:24,404 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /EleutherAI/enformer-official-rough/resolve/main/config.json HTTP/11" 200 439 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:06:24,440 - filelock - DEBUG - Attempting to release lock 140516724379856 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/e50a83cf5e2b127669849109f24c5edcc9361788.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-20 16:06:24,441 - filelock - DEBUG - Lock 140516724379856 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/e50a83cf5e2b127669849109f24c5edcc9361788.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-20 16:06:24,563 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/adapter_config.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:06:24,690 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:06:24,819 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/model.safetensors HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:06:24,955 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/model.safetensors.index.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:06:25,083 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/pytorch_model.bin HTTP/11" 302 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:06:25,086 - filelock - DEBUG - Attempting to acquire lock 140516724376336 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-20 16:06:25,091 - filelock - DEBUG - Lock 140516724376336 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-20 16:06:25,095 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): cdn-lfs.hf.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-20 16:06:25,237 - urllib3.connectionpool - DEBUG - https://cdn-lfs.hf.co:443 "GET /repos/66/eb/66eb21fc2fbae75237b909a4b84d41cb1dce65f654cb9640fdbb51e78b6c13d2/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1732377985&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjM3Nzk4NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy82Ni9lYi82NmViMjFmYzJmYmFlNzUyMzdiOTA5YTRiODRkNDFjYjFkY2U2NWY2NTRjYjk2NDBmZGJiNTFlNzhiNmMxM2QyLzk5YjA5ZDYwMmUxOTVkODljN2Q0ZGViZTE0NGJiMmY0MzkwN2JhMGQ3NDAwNmU5NzA5OGU5OWQ5MTcxYzQzOWM~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=tWB1HtKBBGkwe1hlXn2eG73HEI3kpXUB9bOdmUOW54gLb0iSTiO8RgbaQZ5hnLbZjenZh7lxjwgI4tht0uVURvbGdBumtHMhi6xmwgo7OdGQXuds8nxXnUWToU~-J-1hEGG~dFyh12N7vtXUWMC4-u6cxHsZ6S5kLb70gAz0Dwcj7Kabwcd71K27oKA6rG1U705BAGX5ctIO7SAhUuGmLRNe6NKXKuvEhdwq-B1kbIM6213ex4yfdI7ur-Tp3-icGrZm3T5FNzm9I9WmXvs7Gt~kiZP~0vJjt1fPk87AlNNDI8e1dnnXGqNUMk-~UHr2FqhD9P0WFNOOz62~JR2iHg__&Key-Pair-Id=K3RPWS32NSSJCE HTTP/11" 200 1005149571 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:06:46,030 - filelock - DEBUG - Attempting to release lock 140516724376336 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-20 16:06:46,031 - filelock - DEBUG - Lock 140516724376336 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-20 16:06:46,159 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/model.safetensors HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:06:46,162 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-20 16:06:46,338 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/EleutherAI/enformer-official-rough HTTP/11" 200 783 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:06:46,474 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/EleutherAI/enformer-official-rough/commits/main HTTP/11" 200 1073 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:06:46,601 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/EleutherAI/enformer-official-rough/discussions?p=0 HTTP/11" 200 565 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:06:46,742 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/EleutherAI/enformer-official-rough/commits/refs%2Fpr%2F1 HTTP/11" 200 2038 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-20 16:06:46,744 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): safetensors-convert.hf.space:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-20 16:06:47,314 - urllib3.connectionpool - DEBUG - https://safetensors-convert.hf.space:443 "POST /call/run HTTP/11" 503 58 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-21 09:04:15,157 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'ef', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-21 09:04:15,158 - src.cli - INFO - Using encoder: ef with params: {'pretrained_model_name': 'EleutherAI/enformer-official-rough', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer', 'download': True} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-21 09:04:15,159 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-21 09:04:15,159 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-21 09:04:15,178 - root - INFO - Loading model from pretrained model: EleutherAI/enformer-official-rough [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:327]
2024-11-21 09:04:15,182 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-21 09:04:15,392 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-21 09:04:15,395 - filelock - DEBUG - Attempting to acquire lock 140341965534096 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/e50a83cf5e2b127669849109f24c5edcc9361788.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-21 09:04:15,395 - filelock - DEBUG - Lock 140341965534096 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/e50a83cf5e2b127669849109f24c5edcc9361788.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-21 09:04:15,528 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /EleutherAI/enformer-official-rough/resolve/main/config.json HTTP/11" 200 439 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-21 09:04:15,534 - filelock - DEBUG - Attempting to release lock 140341965534096 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/e50a83cf5e2b127669849109f24c5edcc9361788.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-21 09:04:15,534 - filelock - DEBUG - Lock 140341965534096 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/e50a83cf5e2b127669849109f24c5edcc9361788.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-21 09:04:15,675 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/adapter_config.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-21 09:04:15,799 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-21 09:04:15,929 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/model.safetensors HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-21 09:04:16,061 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/model.safetensors.index.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-21 09:04:16,195 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/pytorch_model.bin HTTP/11" 302 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-21 09:04:16,198 - filelock - DEBUG - Attempting to acquire lock 140341965611472 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-21 09:04:16,198 - filelock - DEBUG - Lock 140341965611472 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-21 09:04:16,203 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): cdn-lfs.hf.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-21 09:04:16,434 - urllib3.connectionpool - DEBUG - https://cdn-lfs.hf.co:443 "GET /repos/66/eb/66eb21fc2fbae75237b909a4b84d41cb1dce65f654cb9640fdbb51e78b6c13d2/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1732435456&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjQzNTQ1Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy82Ni9lYi82NmViMjFmYzJmYmFlNzUyMzdiOTA5YTRiODRkNDFjYjFkY2U2NWY2NTRjYjk2NDBmZGJiNTFlNzhiNmMxM2QyLzk5YjA5ZDYwMmUxOTVkODljN2Q0ZGViZTE0NGJiMmY0MzkwN2JhMGQ3NDAwNmU5NzA5OGU5OWQ5MTcxYzQzOWM~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=tKUGqUyfVj2V67hHfD3-JGQWhb11tMreUqzBCGlEkt6P23e-ayEZ7c~DbM8PvjqcJ4du45ORfwcJsL7LMrEflZPF2dalTrN5Oa45qOPOetTHfkH69ph5-7APO9KzjFPn7zmEDOYsVarmoHpYwVUj8dgy-a2tZ1uJ043m3cG7stw5vK3pEbDj4mQ21WkM3h-EU3OHy6X0LzNCDRfbUBQwGPiimKN60OzFNL8Emifn4MnpjzAUol0Ox8pj24N4MHVG2rsHOWVSnBiT5B6d3z~r1gL~JtkaBNC5TawQxMQRGIWBEMmsJcxpSPbZA2KbV3lwTun-LmQLxOEBAnR~xBahLQ__&Key-Pair-Id=K3RPWS32NSSJCE HTTP/11" 200 1005149571 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-21 09:04:26,478 - filelock - DEBUG - Attempting to release lock 140341965611472 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-21 09:04:26,478 - filelock - DEBUG - Lock 140341965611472 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-21 09:04:26,604 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/model.safetensors HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-21 09:04:26,607 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-21 09:04:26,783 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/EleutherAI/enformer-official-rough HTTP/11" 200 783 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-21 09:04:26,904 - root - INFO - Feature extraction started at: 2024-11-21 09:04:26 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-21 09:04:26,904 - root - INFO - Model: ef
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-21 09:04:26,904 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:102]
2024-11-21 09:04:26,968 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/EleutherAI/enformer-official-rough/commits/main HTTP/11" 200 1073 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-21 09:04:27,100 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/EleutherAI/enformer-official-rough/discussions?p=0 HTTP/11" 200 565 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-21 09:04:27,290 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/EleutherAI/enformer-official-rough/commits/refs%2Fpr%2F1 HTTP/11" 200 2038 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-21 09:04:27,362 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): safetensors-convert.hf.space:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-21 09:04:30,093 - urllib3.connectionpool - DEBUG - https://safetensors-convert.hf.space:443 "POST /call/run HTTP/11" 503 58 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:29:52,268 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 50, 'encoder_name': 'gv', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-27 11:29:52,289 - src.cli - INFO - Using encoder: gv with params: {'pretrained_model_name': 'PoetschLab/GROVER', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover', 'download': True} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-27 11:29:52,289 - src.cli - INFO - Using sequence chunk size: 50 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-27 11:29:52,289 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-27 11:29:52,326 - root - INFO - Downloading tokenizer from PoetschLab/GROVER... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:421]
2024-11-27 11:29:52,342 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 11:29:52,572 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:29:52,574 - filelock - DEBUG - Attempting to acquire lock 139645136611856 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/3a66e59228bcac90d6ea31f7a7b568ce7452c176.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 11:29:52,575 - filelock - DEBUG - Lock 139645136611856 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/3a66e59228bcac90d6ea31f7a7b568ce7452c176.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 11:29:52,709 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /PoetschLab/GROVER/resolve/main/tokenizer_config.json HTTP/11" 200 314 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:29:52,724 - filelock - DEBUG - Attempting to release lock 139645136611856 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/3a66e59228bcac90d6ea31f7a7b568ce7452c176.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 11:29:52,724 - filelock - DEBUG - Lock 139645136611856 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/3a66e59228bcac90d6ea31f7a7b568ce7452c176.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 11:29:52,855 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/tokenizer.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:29:52,856 - filelock - DEBUG - Attempting to acquire lock 139645136713936 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/532b827ad133bc7263840f5c17ecd49d77993fa1.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 11:29:52,856 - filelock - DEBUG - Lock 139645136713936 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/532b827ad133bc7263840f5c17ecd49d77993fa1.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 11:29:52,997 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /PoetschLab/GROVER/resolve/main/tokenizer.json HTTP/11" 200 24637 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:29:53,001 - filelock - DEBUG - Attempting to release lock 139645136713936 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/532b827ad133bc7263840f5c17ecd49d77993fa1.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 11:29:53,001 - filelock - DEBUG - Lock 139645136713936 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/532b827ad133bc7263840f5c17ecd49d77993fa1.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 11:29:53,135 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/tokenizer.model HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:29:53,263 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/added_tokens.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:29:53,401 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/special_tokens_map.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:29:53,403 - filelock - DEBUG - Attempting to acquire lock 139645136609040 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/ecf09bb92a7a4fae4e7ef876320c628ae2ce126e.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 11:29:53,403 - filelock - DEBUG - Lock 139645136609040 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/ecf09bb92a7a4fae4e7ef876320c628ae2ce126e.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 11:29:53,534 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /PoetschLab/GROVER/resolve/main/special_tokens_map.json HTTP/11" 200 77 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:29:53,537 - filelock - DEBUG - Attempting to release lock 139645136609040 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/ecf09bb92a7a4fae4e7ef876320c628ae2ce126e.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 11:29:53,537 - filelock - DEBUG - Lock 139645136609040 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/ecf09bb92a7a4fae4e7ef876320c628ae2ce126e.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 11:29:53,588 - root - INFO - Loading model from pretrained model: PoetschLab/GROVER [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:432]
2024-11-27 11:29:53,718 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:29:53,719 - filelock - DEBUG - Attempting to acquire lock 139645136808144 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/dc89517c5b01a77f5423953bbe32258b369acb53.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 11:29:53,720 - filelock - DEBUG - Lock 139645136808144 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/dc89517c5b01a77f5423953bbe32258b369acb53.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 11:29:53,847 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /PoetschLab/GROVER/resolve/main/config.json HTTP/11" 200 1109 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:29:53,849 - filelock - DEBUG - Attempting to release lock 139645136808144 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/dc89517c5b01a77f5423953bbe32258b369acb53.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 11:29:53,849 - filelock - DEBUG - Lock 139645136808144 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/dc89517c5b01a77f5423953bbe32258b369acb53.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 11:29:53,981 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/adapter_config.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:29:54,318 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/adapter_config.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:29:54,447 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/model.safetensors HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:29:54,583 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/model.safetensors.index.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:29:54,723 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/pytorch_model.bin HTTP/11" 302 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:29:54,725 - filelock - DEBUG - Attempting to acquire lock 139645118787664 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/81fa4ee056e65ff1c06c32512589f3ba3bcb9d054960f35f634b9cf6da7aadda.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 11:29:54,726 - filelock - DEBUG - Lock 139645118787664 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/81fa4ee056e65ff1c06c32512589f3ba3bcb9d054960f35f634b9cf6da7aadda.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 11:29:54,730 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): cdn-lfs-us-1.hf.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 11:29:54,944 - urllib3.connectionpool - DEBUG - https://cdn-lfs-us-1.hf.co:443 "GET /repos/ec/89/ec89555b6bae1e89f06aea92e20141af026ca5e5be53bf7afb3cf5e6ccc02ca4/81fa4ee056e65ff1c06c32512589f3ba3bcb9d054960f35f634b9cf6da7aadda?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1732962594&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjk2MjU5NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2VjLzg5L2VjODk1NTViNmJhZTFlODlmMDZhZWE5MmUyMDE0MWFmMDI2Y2E1ZTViZTUzYmY3YWZiM2NmNWU2Y2NjMDJjYTQvODFmYTRlZTA1NmU2NWZmMWMwNmMzMjUxMjU4OWYzYmEzYmNiOWQwNTQ5NjBmMzVmNjM0YjljZjZkYTdhYWRkYT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=k79Anx1ZN6F5R7ScPCfKUirEcvLHm50fcI5TeJWyn14Spoqp9fqX3HM0qNOZRRLeyDoSsAAvVkaskKoq0jCkNwkStgoS2xyrdP36VnjTWErChoqDZnOInsEuLFb3uu07rvcYUGJWGptg5-9rnCKAHJY-38Odnsz9rPAryYXj5C-iCIoxVEkvF-DVV6~v8Vt9KfZsbUZ3oolLav0D0IDiamV1U0~OAEq-uOZuBeAjYFkxJj3LWKueHz0WaQw9dVS0pbZvm9L2FrnSfWvrFC9UPklDpkvnMVFylrGARST8rdtEAntXOjHKoqaSYpe2cBwlBX9ZJjCj84Br4s-YfCY9PA__&Key-Pair-Id=K24J24Z295AEI9 HTTP/11" 200 348488361 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:30:03,142 - filelock - DEBUG - Attempting to release lock 139645118787664 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/81fa4ee056e65ff1c06c32512589f3ba3bcb9d054960f35f634b9cf6da7aadda.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 11:30:03,142 - filelock - DEBUG - Lock 139645118787664 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/81fa4ee056e65ff1c06c32512589f3ba3bcb9d054960f35f634b9cf6da7aadda.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 11:30:03,269 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/model.safetensors HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:30:03,272 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 11:30:03,443 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/PoetschLab/GROVER HTTP/11" 200 3649 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:30:03,546 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/generation_config.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:30:03,576 - root - INFO - Feature extraction started at: 2024-11-27 11:30:03 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-27 11:30:03,576 - root - INFO - Model: gv
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-27 11:30:03,576 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:102]
2024-11-27 11:30:03,640 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/PoetschLab/GROVER/commits/main HTTP/11" 200 2000 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:30:03,795 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/PoetschLab/GROVER/discussions?p=0 HTTP/11" 200 1676 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:30:04,065 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/PoetschLab/GROVER/commits/refs%2Fpr%2F4 HTTP/11" 200 2965 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:30:04,162 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): safetensors-convert.hf.space:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 11:30:04,692 - urllib3.connectionpool - DEBUG - https://safetensors-convert.hf.space:443 "POST /call/run HTTP/11" 503 30 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 11:35:15,343 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 30, 'encoder_name': 'gv', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-27 11:35:15,345 - src.cli - INFO - Using encoder: gv with params: {'pretrained_model_name': 'PoetschLab/GROVER', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-27 11:35:15,345 - src.cli - INFO - Using sequence chunk size: 30 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-27 11:35:15,345 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-27 11:35:15,368 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/models--PoetschLab--GROVER/snapshots/f6ed259a321aacb629cf638a1568c2a40b381cfe [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:427]
2024-11-27 11:35:15,370 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/models--PoetschLab--GROVER/snapshots/f6ed259a321aacb629cf638a1568c2a40b381cfe [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:438]
2024-11-27 11:35:15,444 - root - INFO - Feature extraction started at: 2024-11-27 11:35:15 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-27 11:35:15,444 - root - INFO - Model: gv
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-27 11:35:15,444 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:102]
2024-11-27 11:37:17,025 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 20, 'encoder_name': 'gv', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-27 11:37:17,027 - src.cli - INFO - Using encoder: gv with params: {'pretrained_model_name': 'PoetschLab/GROVER', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-27 11:37:17,027 - src.cli - INFO - Using sequence chunk size: 20 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-27 11:37:17,027 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-27 11:37:17,050 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/models--PoetschLab--GROVER/snapshots/f6ed259a321aacb629cf638a1568c2a40b381cfe [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:427]
2024-11-27 11:37:17,052 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/models--PoetschLab--GROVER/snapshots/f6ed259a321aacb629cf638a1568c2a40b381cfe [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:438]
2024-11-27 11:37:17,124 - root - INFO - Feature extraction started at: 2024-11-27 11:37:17 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-27 11:37:17,124 - root - INFO - Model: gv
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-27 11:37:17,124 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:102]
2024-11-27 11:38:27,292 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 609]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:224]
2024-11-27 11:38:27,292 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:227]
2024-11-27 11:38:27,312 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-27 11:41:07,592 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 20, 'encoder_name': 'gv', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-27 11:41:07,593 - src.cli - INFO - Using encoder: gv with params: {'pretrained_model_name': 'PoetschLab/GROVER', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-27 11:41:07,593 - src.cli - INFO - Using sequence chunk size: 20 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-27 11:41:07,593 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-27 11:41:07,620 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/models--PoetschLab--GROVER/snapshots/f6ed259a321aacb629cf638a1568c2a40b381cfe [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:427]
2024-11-27 11:41:07,621 - root - INFO - Loading model from cache directory: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/models--PoetschLab--GROVER/snapshots/f6ed259a321aacb629cf638a1568c2a40b381cfe [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:438]
2024-11-27 11:41:07,691 - root - INFO - Feature extraction started at: 2024-11-27 11:41:07 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:98]
2024-11-27 11:41:07,691 - root - INFO - Model: gv
 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:99]
2024-11-27 11:41:07,691 - root - INFO - Scanning for existing features... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:102]
2024-11-27 11:42:18,254 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 609]) [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:224]
2024-11-27 11:42:18,255 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/feats_extract.py:227]
2024-11-27 11:42:18,280 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:92]
2024-11-27 13:18:40,509 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 20, 'encoder_name': 'cd', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-27 13:18:40,511 - src.cli - INFO - Using encoder: cd with params: {'pretrained_model_name': 'kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus', 'download': False} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-27 13:18:40,511 - src.cli - INFO - Using sequence chunk size: 20 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-27 13:18:40,511 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-27 13:18:40,532 - root - ERROR - Tokenizer checkpoint does not exist: /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/models--PoetschLab--GROVER/snapshots/f6ed259a321aacb629cf638a1568c2a40b381cfe [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:489]
2024-11-27 13:19:06,524 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'chunk_size': 20, 'encoder_name': 'cd', 'device': 'cuda', 'pooling_type': 'ema', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:46]
2024-11-27 13:19:06,526 - src.cli - INFO - Using encoder: cd with params: {'pretrained_model_name': 'kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16', 'cache_dir': '/mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus', 'download': True} [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:55]
2024-11-27 13:19:06,526 - src.cli - INFO - Using sequence chunk size: 20 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:57]
2024-11-27 13:19:06,526 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/cli.py:75]
2024-11-27 13:19:06,545 - root - INFO - Downloading tokenizer from kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16... [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:485]
2024-11-27 13:19:06,548 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 13:19:06,729 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 13:19:06,731 - filelock - DEBUG - Attempting to acquire lock 139765214144016 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/26a76102ebe3e6115abfd7fdfd4de5ee4a30f8d0.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 13:19:06,732 - filelock - DEBUG - Lock 139765214144016 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/26a76102ebe3e6115abfd7fdfd4de5ee4a30f8d0.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 13:19:06,870 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16/resolve/main/tokenizer_config.json HTTP/11" 200 1485 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 13:19:06,876 - filelock - DEBUG - Attempting to release lock 139765214144016 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/26a76102ebe3e6115abfd7fdfd4de5ee4a30f8d0.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 13:19:06,876 - filelock - DEBUG - Lock 139765214144016 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/26a76102ebe3e6115abfd7fdfd4de5ee4a30f8d0.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 13:19:12,601 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16/resolve/main/tokenization_caduceus.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 13:19:12,603 - filelock - DEBUG - Attempting to acquire lock 139765214270736 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/7ceca077334f318882ac62c7ee047a12a36fe750.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 13:19:12,603 - filelock - DEBUG - Lock 139765214270736 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/7ceca077334f318882ac62c7ee047a12a36fe750.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 13:19:12,734 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16/resolve/main/tokenization_caduceus.py HTTP/11" 200 4966 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 13:19:12,737 - filelock - DEBUG - Attempting to release lock 139765214270736 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/7ceca077334f318882ac62c7ee047a12a36fe750.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 13:19:12,737 - filelock - DEBUG - Lock 139765214270736 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/7ceca077334f318882ac62c7ee047a12a36fe750.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 13:19:12,897 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16/resolve/main/added_tokens.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 13:19:13,038 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16/resolve/main/special_tokens_map.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 13:19:13,039 - filelock - DEBUG - Attempting to acquire lock 139765214393040 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/cb07cd4618f0653064315668f403b091f8287734.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 13:19:13,040 - filelock - DEBUG - Lock 139765214393040 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/cb07cd4618f0653064315668f403b091f8287734.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 13:19:13,202 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16/resolve/main/special_tokens_map.json HTTP/11" 200 173 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 13:19:13,205 - filelock - DEBUG - Attempting to release lock 139765214393040 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/cb07cd4618f0653064315668f403b091f8287734.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 13:19:13,205 - filelock - DEBUG - Lock 139765214393040 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/cb07cd4618f0653064315668f403b091f8287734.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 13:19:13,336 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16/resolve/main/tokenizer.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 13:19:13,338 - root - INFO - Loading model from pretrained model: kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/repos/genml/src/feature_extraction/helpers/encoders.py:496]
2024-11-27 13:19:13,474 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 13:19:13,475 - filelock - DEBUG - Attempting to acquire lock 139765214383952 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/aa2cae6bbf5667a71e7eab78fa8d5bd422b125dc.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 13:19:13,476 - filelock - DEBUG - Lock 139765214383952 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/aa2cae6bbf5667a71e7eab78fa8d5bd422b125dc.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 13:19:13,616 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16/resolve/main/config.json HTTP/11" 200 1375 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 13:19:13,619 - filelock - DEBUG - Attempting to release lock 139765214383952 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/aa2cae6bbf5667a71e7eab78fa8d5bd422b125dc.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 13:19:13,620 - filelock - DEBUG - Lock 139765214383952 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/aa2cae6bbf5667a71e7eab78fa8d5bd422b125dc.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 13:19:13,753 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16/resolve/main/adapter_config.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 13:19:13,891 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16/resolve/main/configuration_caduceus.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 13:19:13,892 - filelock - DEBUG - Attempting to acquire lock 139765214458896 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/dfccd5b37e630fdbf024f1e96d12713d97b67fb3.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 13:19:13,893 - filelock - DEBUG - Lock 139765214458896 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/dfccd5b37e630fdbf024f1e96d12713d97b67fb3.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 13:19:14,024 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16/resolve/main/configuration_caduceus.py HTTP/11" 200 1964 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 13:19:14,027 - filelock - DEBUG - Attempting to release lock 139765214458896 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/dfccd5b37e630fdbf024f1e96d12713d97b67fb3.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 13:19:14,027 - filelock - DEBUG - Lock 139765214458896 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/dfccd5b37e630fdbf024f1e96d12713d97b67fb3.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 13:19:14,205 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16/resolve/main/modeling_caduceus.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 13:19:14,207 - filelock - DEBUG - Attempting to acquire lock 139765214981072 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/a74e61e6409f240a99b2a0ad80312dbb24950e16.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 13:19:14,207 - filelock - DEBUG - Lock 139765214981072 acquired on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/a74e61e6409f240a99b2a0ad80312dbb24950e16.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 13:19:14,351 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /kuleshov-group/caduceus-ps_seqlen-131k_d_model-256_n_layer-16/resolve/main/modeling_caduceus.py HTTP/11" 200 28617 [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 13:19:14,353 - filelock - DEBUG - Attempting to release lock 139765214981072 on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/a74e61e6409f240a99b2a0ad80312dbb24950e16.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 13:19:14,354 - filelock - DEBUG - Lock 139765214981072 released on /mnt/bulk-io/lizhang/LiWorkSpace/genomics/data/06_checkpoints/caduceus/.locks/models--kuleshov-group--caduceus-ps_seqlen-131k_d_model-256_n_layer-16/a74e61e6409f240a99b2a0ad80312dbb24950e16.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/genomics/.venv/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 16:08:28,444 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 1, 'encoder_name': 'db2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:46]
2024-11-27 16:08:28,446 - src.cli - INFO - Using encoder: db2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': True} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:55]
2024-11-27 16:08:28,446 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:57]
2024-11-27 16:08:28,446 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:75]
2024-11-27 16:08:28,489 - root - INFO - Downloading tokenizer from zhihan1996/DNABERT-2-117M... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:73]
2024-11-27 16:08:28,496 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 16:08:28,667 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 16:08:28,669 - filelock - DEBUG - Attempting to acquire lock 140341188662032 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/6623217350bd5b1eff2dd4830e6872699d3dc5cd.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 16:08:28,669 - filelock - DEBUG - Lock 140341188662032 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/6623217350bd5b1eff2dd4830e6872699d3dc5cd.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 16:08:28,794 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer_config.json HTTP/11" 200 158 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 16:08:28,814 - filelock - DEBUG - Attempting to release lock 140341188662032 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/6623217350bd5b1eff2dd4830e6872699d3dc5cd.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 16:08:28,814 - filelock - DEBUG - Lock 140341188662032 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/6623217350bd5b1eff2dd4830e6872699d3dc5cd.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 16:08:28,982 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 16:08:28,983 - filelock - DEBUG - Attempting to acquire lock 140340954764176 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/3b3ab6d7aaf96050dbb992924867043e98bc4332.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 16:08:28,983 - filelock - DEBUG - Lock 140340954764176 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/3b3ab6d7aaf96050dbb992924867043e98bc4332.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 16:08:29,114 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /zhihan1996/DNABERT-2-117M/resolve/main/tokenizer.json HTTP/11" 200 167908 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 16:08:29,143 - filelock - DEBUG - Attempting to release lock 140340954764176 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/3b3ab6d7aaf96050dbb992924867043e98bc4332.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 16:08:29,143 - filelock - DEBUG - Lock 140340954764176 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/3b3ab6d7aaf96050dbb992924867043e98bc4332.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 16:08:29,276 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/added_tokens.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 16:08:29,418 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/special_tokens_map.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 16:08:29,460 - root - INFO - Loading model from pretrained model: zhihan1996/DNABERT-2-117M [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:84]
2024-11-27 16:08:29,583 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 16:08:29,584 - filelock - DEBUG - Attempting to acquire lock 140340968555216 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/8a18497de4d4a3f1cd183e90766f4a06fa25c8d4.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 16:08:29,585 - filelock - DEBUG - Lock 140340968555216 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/8a18497de4d4a3f1cd183e90766f4a06fa25c8d4.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 16:08:29,718 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /zhihan1996/DNABERT-2-117M/resolve/main/config.json HTTP/11" 200 904 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 16:08:29,720 - filelock - DEBUG - Attempting to release lock 140340968555216 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/8a18497de4d4a3f1cd183e90766f4a06fa25c8d4.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 16:08:29,720 - filelock - DEBUG - Lock 140340968555216 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/8a18497de4d4a3f1cd183e90766f4a06fa25c8d4.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 16:08:29,850 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/configuration_bert.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 16:08:29,851 - filelock - DEBUG - Attempting to acquire lock 140340965061264 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/b27bed3d8ae09cd13fe64f8805bc2aef24e1ffec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 16:08:29,851 - filelock - DEBUG - Lock 140340965061264 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/b27bed3d8ae09cd13fe64f8805bc2aef24e1ffec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 16:08:29,976 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /zhihan1996/DNABERT-2-117M/resolve/main/configuration_bert.py HTTP/11" 200 1011 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 16:08:29,979 - filelock - DEBUG - Attempting to release lock 140340965061264 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/b27bed3d8ae09cd13fe64f8805bc2aef24e1ffec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 16:08:29,979 - filelock - DEBUG - Lock 140340965061264 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/b27bed3d8ae09cd13fe64f8805bc2aef24e1ffec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 16:08:30,114 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 16:08:30,236 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/bert_layers.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 16:08:30,237 - filelock - DEBUG - Attempting to acquire lock 140340968555088 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/611b73d92807d1a22ad5790cda9e234db35827e8.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 16:08:30,237 - filelock - DEBUG - Lock 140340968555088 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/611b73d92807d1a22ad5790cda9e234db35827e8.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 16:08:30,360 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /zhihan1996/DNABERT-2-117M/resolve/main/bert_layers.py HTTP/11" 200 40690 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 16:08:30,362 - filelock - DEBUG - Attempting to release lock 140340968555088 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/611b73d92807d1a22ad5790cda9e234db35827e8.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 16:08:30,363 - filelock - DEBUG - Lock 140340968555088 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/611b73d92807d1a22ad5790cda9e234db35827e8.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 16:08:30,497 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/flash_attn_triton.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 16:08:30,498 - filelock - DEBUG - Attempting to acquire lock 140340954774032 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/b2b946c06f8430153de15227b232d070e0fd62c9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 16:08:30,499 - filelock - DEBUG - Lock 140340954774032 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/b2b946c06f8430153de15227b232d070e0fd62c9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 16:08:30,632 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /zhihan1996/DNABERT-2-117M/resolve/main/flash_attn_triton.py HTTP/11" 200 42737 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 16:08:30,635 - filelock - DEBUG - Attempting to release lock 140340954774032 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/b2b946c06f8430153de15227b232d070e0fd62c9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 16:08:30,635 - filelock - DEBUG - Lock 140340954774032 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/b2b946c06f8430153de15227b232d070e0fd62c9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 16:08:30,768 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/bert_padding.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 16:08:30,769 - filelock - DEBUG - Attempting to acquire lock 140340954774032 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/4da59be166036b2df98589a0e0b5d01a7044747d.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 16:08:30,770 - filelock - DEBUG - Lock 140340954774032 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/4da59be166036b2df98589a0e0b5d01a7044747d.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 16:08:30,896 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /zhihan1996/DNABERT-2-117M/resolve/main/bert_padding.py HTTP/11" 200 6099 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 16:08:30,898 - filelock - DEBUG - Attempting to release lock 140340954774032 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/4da59be166036b2df98589a0e0b5d01a7044747d.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 16:08:30,898 - filelock - DEBUG - Lock 140340954774032 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/4da59be166036b2df98589a0e0b5d01a7044747d.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 16:08:32,438 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /zhihan1996/DNABERT-2-117M/resolve/main/pytorch_model.bin HTTP/11" 302 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 16:08:32,440 - filelock - DEBUG - Attempting to acquire lock 140340840243088 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/7ff39ec77a484dd01070a41bfd6e95cdd7247bec80fe357ab43a4be33687aeba.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 16:08:32,440 - filelock - DEBUG - Lock 140340840243088 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/7ff39ec77a484dd01070a41bfd6e95cdd7247bec80fe357ab43a4be33687aeba.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 16:08:32,442 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): cdn-lfs.hf.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 16:08:32,706 - urllib3.connectionpool - DEBUG - https://cdn-lfs.hf.co:443 "GET /repos/c6/3a/c63ada858e8c084035483c507224ff1f5644acc4b4265d36d0be2cdb9dc5aee4/7ff39ec77a484dd01070a41bfd6e95cdd7247bec80fe357ab43a4be33687aeba?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1732979312&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjk3OTMxMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9jNi8zYS9jNjNhZGE4NThlOGMwODQwMzU0ODNjNTA3MjI0ZmYxZjU2NDRhY2M0YjQyNjVkMzZkMGJlMmNkYjlkYzVhZWU0LzdmZjM5ZWM3N2E0ODRkZDAxMDcwYTQxYmZkNmU5NWNkZDcyNDdiZWM4MGZlMzU3YWI0M2E0YmUzMzY4N2FlYmE~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=j19tn4~FbWHO9GwR3BGXBUiIY4KI4NfxmmhTZFTZ2ss6ETVp2seH34An05Y2yv0JyWsFC285sZfc0XiZLZaWcmqQ-Gsbemyps9qZ1k0zW3tmdJqeSvivGqGQs2DSkR4APBg4HXSgkBANVD~uHZcQBhnjKQodeD0tq9Bl2pv4S~sNTyhLgai5ZT5W5PiciNJvyeYBzYEXk9rb7Z0zGONKAUPIHTwWDcyW5zDUQXlp1hHrp67zejHTm0fTwdpOpkJ9NTsc4qVQYU4lrz-MUoiivT~0sKzdt4y2x56rBCK1-bZpZ-OjQxnTZ9mps0IoMw8hNR85b2gMWwE-x3Fb~xqqgA__&Key-Pair-Id=K3RPWS32NSSJCE HTTP/11" 200 468354983 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 16:08:37,546 - filelock - DEBUG - Attempting to release lock 140340840243088 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/7ff39ec77a484dd01070a41bfd6e95cdd7247bec80fe357ab43a4be33687aeba.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 16:08:37,547 - filelock - DEBUG - Lock 140340840243088 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/.locks/models--zhihan1996--DNABERT-2-117M/7ff39ec77a484dd01070a41bfd6e95cdd7247bec80fe357ab43a4be33687aeba.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml_db2/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 16:08:38,610 - root - INFO - Feature extraction started at: 2024-11-27 16:08:38 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:72]
2024-11-27 16:08:38,610 - root - INFO - Model: db2
 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:73]
2024-11-27 16:08:38,610 - root - INFO - Scanning for existing features... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:76]
2024-11-27 16:11:04,562 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 1, 'encoder_name': 'db2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'padding': False, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:46]
2024-11-27 16:11:04,563 - src.cli - INFO - Using encoder: db2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:55]
2024-11-27 16:11:04,563 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:57]
2024-11-27 16:11:04,564 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:75]
2024-11-27 16:11:04,605 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/models--zhihan1996--DNABERT-2-117M/snapshots/d064dece8a8b41d9fb8729fbe3435278786931f1 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:79]
2024-11-27 16:11:04,610 - root - INFO - Loading model from cache directory: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/models--zhihan1996--DNABERT-2-117M/snapshots/d064dece8a8b41d9fb8729fbe3435278786931f1 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:90]
2024-11-27 16:11:05,734 - root - INFO - Feature extraction started at: 2024-11-27 16:11:05 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:72]
2024-11-27 16:11:05,734 - root - INFO - Model: db2
 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:73]
2024-11-27 16:11:05,734 - root - INFO - Scanning for existing features... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:76]
2024-11-27 16:29:20,759 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 1, 'encoder_name': 'db2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:46]
2024-11-27 16:29:20,762 - src.cli - INFO - Using encoder: db2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:55]
2024-11-27 16:29:20,763 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:57]
2024-11-27 16:30:16,840 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 1, 'encoder_name': 'db2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:46]
2024-11-27 16:30:16,841 - src.cli - INFO - Using encoder: db2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:53]
2024-11-27 16:30:16,841 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:54]
2024-11-27 16:30:16,841 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:71]
2024-11-27 16:30:16,881 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/models--zhihan1996--DNABERT-2-117M/snapshots/d064dece8a8b41d9fb8729fbe3435278786931f1 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:37]
2024-11-27 16:30:16,886 - root - INFO - Loading model from cache directory: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/models--zhihan1996--DNABERT-2-117M/snapshots/d064dece8a8b41d9fb8729fbe3435278786931f1 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:48]
2024-11-27 16:30:17,966 - root - INFO - Feature extraction started at: 2024-11-27 16:30:17 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:68]
2024-11-27 16:30:17,966 - root - INFO - Model: db2
 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:69]
2024-11-27 16:30:17,967 - root - INFO - Scanning for existing features... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:72]
2024-11-27 16:36:42,139 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 1, 'encoder_name': 'db2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:46]
2024-11-27 16:36:42,140 - src.cli - INFO - Using encoder: db2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:53]
2024-11-27 16:36:42,140 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:54]
2024-11-27 16:36:42,140 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:71]
2024-11-27 16:36:42,182 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/models--zhihan1996--DNABERT-2-117M/snapshots/d064dece8a8b41d9fb8729fbe3435278786931f1 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:37]
2024-11-27 16:36:42,187 - root - INFO - Loading model from cache directory: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/models--zhihan1996--DNABERT-2-117M/snapshots/d064dece8a8b41d9fb8729fbe3435278786931f1 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:48]
2024-11-27 16:36:43,309 - root - INFO - Feature extraction started at: 2024-11-27 16:36:43 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:68]
2024-11-27 16:36:43,309 - root - INFO - Model: db2
 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:69]
2024-11-27 16:36:43,309 - root - INFO - Scanning for existing features... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:72]
2024-11-27 16:39:31,950 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 5, 'chunk_size': 1, 'encoder_name': 'db2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 12, 'sep_token': '[SEP]', 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:46]
2024-11-27 16:39:31,952 - src.cli - INFO - Using encoder: db2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:53]
2024-11-27 16:39:31,952 - src.cli - INFO - Using sequence chunk size: 1 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:54]
2024-11-27 16:39:31,952 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:71]
2024-11-27 16:39:31,993 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/models--zhihan1996--DNABERT-2-117M/snapshots/d064dece8a8b41d9fb8729fbe3435278786931f1 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:37]
2024-11-27 16:39:31,999 - root - INFO - Loading model from cache directory: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/models--zhihan1996--DNABERT-2-117M/snapshots/d064dece8a8b41d9fb8729fbe3435278786931f1 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:48]
2024-11-27 16:39:33,079 - root - INFO - Feature extraction started at: 2024-11-27 16:39:33 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:68]
2024-11-27 16:39:33,079 - root - INFO - Model: db2
 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:69]
2024-11-27 16:39:33,079 - root - INFO - Scanning for existing features... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:72]
2024-11-27 16:41:33,167 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 768]) [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:115]
2024-11-27 16:41:55,640 - root - INFO - Saved features for patient TCGA-02-0033, final extracted features shape torch.Size([605, 768]) [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:115]
2024-11-27 16:42:25,900 - root - INFO - Saved features for patient TCGA-02-0047, final extracted features shape torch.Size([815, 768]) [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:115]
2024-11-27 17:05:15,805 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'encoder_name': 'hd', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:44]
2024-11-27 17:05:15,806 - src.cli - INFO - Using encoder: hd with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:49]
2024-11-27 17:05:15,806 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:65]
2024-11-27 17:06:08,933 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'encoder_name': 'hd', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:44]
2024-11-27 17:06:08,935 - src.cli - INFO - Using encoder: hd with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:49]
2024-11-27 17:06:08,935 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:65]
2024-11-27 17:06:08,976 - root - ERROR - Tokenizer checkpoint does not exist: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:35]
2024-11-27 17:06:51,302 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'encoder_name': 'hd', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:44]
2024-11-27 17:06:51,303 - src.cli - INFO - Using encoder: hd with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': True} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:49]
2024-11-27 17:06:51,303 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:65]
2024-11-27 17:06:51,345 - root - INFO - Downloading tokenizer from LongSafari/hyenadna-medium-160k-seqlen-hf... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:31]
2024-11-27 17:06:51,350 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 17:06:51,713 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 17:06:51,714 - filelock - DEBUG - Attempting to acquire lock 140082304445520 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/7ce74d254992d0a401cf518851477fac1bf722b9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 17:06:51,714 - filelock - DEBUG - Lock 140082304445520 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/7ce74d254992d0a401cf518851477fac1bf722b9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 17:06:51,845 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tokenizer_config.json HTTP/11" 200 1482 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 17:06:51,852 - filelock - DEBUG - Attempting to release lock 140082304445520 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/7ce74d254992d0a401cf518851477fac1bf722b9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 17:06:51,852 - filelock - DEBUG - Lock 140082304445520 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/7ce74d254992d0a401cf518851477fac1bf722b9.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 17:06:51,979 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tokenization_hyena.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 17:06:51,980 - filelock - DEBUG - Attempting to acquire lock 140082304445584 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d45662fcdc5cc05be3f2c952ebb82c512d42f5ec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 17:06:51,981 - filelock - DEBUG - Lock 140082304445584 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d45662fcdc5cc05be3f2c952ebb82c512d42f5ec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 17:06:52,110 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tokenization_hyena.py HTTP/11" 200 4057 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 17:06:52,113 - filelock - DEBUG - Attempting to release lock 140082304445584 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d45662fcdc5cc05be3f2c952ebb82c512d42f5ec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 17:06:52,113 - filelock - DEBUG - Lock 140082304445584 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d45662fcdc5cc05be3f2c952ebb82c512d42f5ec.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 17:06:52,260 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/added_tokens.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 17:06:52,388 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/special_tokens_map.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 17:06:52,389 - filelock - DEBUG - Attempting to acquire lock 140082299336656 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/b7a451170f6fb07dc5d71f2e0241f262502eaf13.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 17:06:52,389 - filelock - DEBUG - Lock 140082299336656 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/b7a451170f6fb07dc5d71f2e0241f262502eaf13.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 17:06:52,519 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/special_tokens_map.json HTTP/11" 200 971 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 17:06:52,522 - filelock - DEBUG - Attempting to release lock 140082299336656 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/b7a451170f6fb07dc5d71f2e0241f262502eaf13.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 17:06:52,522 - filelock - DEBUG - Lock 140082299336656 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/b7a451170f6fb07dc5d71f2e0241f262502eaf13.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 17:06:52,652 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/tokenizer.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 17:06:52,656 - root - INFO - Loading model from pretrained model: LongSafari/hyenadna-medium-160k-seqlen-hf [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:106]
2024-11-27 17:06:52,802 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 17:06:52,803 - filelock - DEBUG - Attempting to acquire lock 140082299280720 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d061bc164157135bd7ddfa4cddb8ad47d2de8541.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 17:06:52,804 - filelock - DEBUG - Lock 140082299280720 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d061bc164157135bd7ddfa4cddb8ad47d2de8541.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 17:06:52,956 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/config.json HTTP/11" 200 984 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 17:06:52,959 - filelock - DEBUG - Attempting to release lock 140082299280720 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d061bc164157135bd7ddfa4cddb8ad47d2de8541.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 17:06:52,959 - filelock - DEBUG - Lock 140082299280720 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d061bc164157135bd7ddfa4cddb8ad47d2de8541.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 17:06:53,105 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/adapter_config.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 17:06:53,242 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/configuration_hyena.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 17:06:53,244 - filelock - DEBUG - Attempting to acquire lock 140082299288592 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d8ca5c2f084d69e729672a845d3d6469ed12f18a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 17:06:53,244 - filelock - DEBUG - Lock 140082299288592 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d8ca5c2f084d69e729672a845d3d6469ed12f18a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 17:06:53,373 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/configuration_hyena.py HTTP/11" 200 3093 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 17:06:53,376 - filelock - DEBUG - Attempting to release lock 140082299288592 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d8ca5c2f084d69e729672a845d3d6469ed12f18a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 17:06:53,376 - filelock - DEBUG - Lock 140082299288592 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/d8ca5c2f084d69e729672a845d3d6469ed12f18a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 17:06:54,115 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/modeling_hyena.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 17:06:54,117 - filelock - DEBUG - Attempting to acquire lock 140082247418256 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/24f0890027c2d360c72e01f6bdbcf0e6109b15e7.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 17:06:54,117 - filelock - DEBUG - Lock 140082247418256 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/24f0890027c2d360c72e01f6bdbcf0e6109b15e7.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 17:06:54,252 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/modeling_hyena.py HTTP/11" 200 22584 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 17:06:54,254 - filelock - DEBUG - Attempting to release lock 140082247418256 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/24f0890027c2d360c72e01f6bdbcf0e6109b15e7.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 17:06:54,255 - filelock - DEBUG - Lock 140082247418256 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/24f0890027c2d360c72e01f6bdbcf0e6109b15e7.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 17:06:54,429 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/adapter_config.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 17:06:54,567 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /LongSafari/hyenadna-medium-160k-seqlen-hf/resolve/main/model.safetensors HTTP/11" 302 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 17:06:54,570 - filelock - DEBUG - Attempting to acquire lock 140082247426896 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/16685b36caf5d144da391f1b540ed47e89d79b3efd38899325492f174b8e852a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 17:06:54,571 - filelock - DEBUG - Lock 140082247426896 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/16685b36caf5d144da391f1b540ed47e89d79b3efd38899325492f174b8e852a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 17:06:54,574 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): cdn-lfs-us-1.hf.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 17:06:54,807 - urllib3.connectionpool - DEBUG - https://cdn-lfs-us-1.hf.co:443 "GET /repos/57/c9/57c99b55a221cbab1741ace9eecc90c9f11056fa4bec40e8d0a6fe41433ffe56/16685b36caf5d144da391f1b540ed47e89d79b3efd38899325492f174b8e852a?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1732982814&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjk4MjgxNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzU3L2M5LzU3Yzk5YjU1YTIyMWNiYWIxNzQxYWNlOWVlY2M5MGM5ZjExMDU2ZmE0YmVjNDBlOGQwYTZmZTQxNDMzZmZlNTYvMTY2ODViMzZjYWY1ZDE0NGRhMzkxZjFiNTQwZWQ0N2U4OWQ3OWIzZWZkMzg4OTkzMjU0OTJmMTc0YjhlODUyYT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=oQ2lDMOKNJAtI7XV~Rqcu6yIM1zF8bxTl7hFk2B2ac9uPQPbrgih4pqJsuJwzfwkS5u~zS05Fn6xtPYDYEtFEOMgRK~~RIJyIuC0bwMEEXb0CZ4EREP7S8NsU-Hl2tMHM1syngh95IP8PKmfXnWzWmCZ51DufrLyVgX00B0sPU~oNp86Fn0vBYM~sJ6L5gKJaAAjmZzlkp-uE4xFfBJPBsv31bkFamPRGdWu9fZSRHGpGROETVtQDMXY830TQae2HXaKwoYSDB--lJASxZAOpSgycKWFxnpgG2ZEARu7sYiUJXjfwWdXOGfRZ9pjoEFwQOK0VUxCFzq3nBNEl1OIpQ__&Key-Pair-Id=K24J24Z295AEI9 HTTP/11" 200 56971992 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 17:06:56,271 - filelock - DEBUG - Attempting to release lock 140082247426896 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/16685b36caf5d144da391f1b540ed47e89d79b3efd38899325492f174b8e852a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 17:06:56,271 - filelock - DEBUG - Lock 140082247426896 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/.locks/models--LongSafari--hyenadna-medium-160k-seqlen-hf/16685b36caf5d144da391f1b540ed47e89d79b3efd38899325492f174b8e852a.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 17:06:57,240 - accelerate.big_modeling - WARNING - You shouldn't move a model that is dispatched using accelerate hooks. [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/accelerate/big_modeling.py:451]
2024-11-27 17:06:57,252 - root - INFO - Feature extraction started at: 2024-11-27 17:06:57 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:66]
2024-11-27 17:06:57,252 - root - INFO - Model: hd
 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:67]
2024-11-27 17:06:57,253 - root - INFO - Scanning for existing features... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:70]
2024-11-27 17:13:23,771 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'encoder_name': 'hd', 'device': 'cuda:0', 'pooling_type': 'mean_pooling', 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:44]
2024-11-27 17:13:23,773 - src.cli - INFO - Using encoder: hd with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:49]
2024-11-27 17:13:23,773 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:65]
2024-11-27 17:13:23,817 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:37]
2024-11-27 17:13:23,823 - root - INFO - Loading model from cache directory: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:112]
2024-11-27 17:13:25,118 - accelerate.big_modeling - WARNING - You shouldn't move a model that is dispatched using accelerate hooks. [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/accelerate/big_modeling.py:451]
2024-11-27 17:13:25,126 - root - INFO - Feature extraction started at: 2024-11-27 17:13:25 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:66]
2024-11-27 17:13:25,126 - root - INFO - Model: hd
 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:67]
2024-11-27 17:13:25,126 - root - INFO - Scanning for existing features... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:70]
2024-11-27 17:21:18,694 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'encoder_name': 'db2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:44]
2024-11-27 17:21:18,696 - src.cli - INFO - Using encoder: db2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:49]
2024-11-27 17:21:18,696 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:65]
2024-11-27 17:21:18,749 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/models--zhihan1996--DNABERT-2-117M/snapshots/d064dece8a8b41d9fb8729fbe3435278786931f1 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:37]
2024-11-27 17:21:18,778 - root - INFO - Loading model from cache directory: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/models--zhihan1996--DNABERT-2-117M/snapshots/d064dece8a8b41d9fb8729fbe3435278786931f1 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:48]
2024-11-27 17:21:20,025 - root - INFO - Feature extraction started at: 2024-11-27 17:21:20 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:66]
2024-11-27 17:21:20,025 - root - INFO - Model: db2
 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:67]
2024-11-27 17:21:20,025 - root - INFO - Scanning for existing features... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:70]
2024-11-27 17:21:38,092 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'encoder_name': 'db2', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:44]
2024-11-27 17:21:38,093 - src.cli - INFO - Using encoder: db2 with params: {'pretrained_model_name': 'zhihan1996/DNABERT-2-117M', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2', 'download': False} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:49]
2024-11-27 17:21:38,093 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:65]
2024-11-27 17:21:38,136 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/models--zhihan1996--DNABERT-2-117M/snapshots/d064dece8a8b41d9fb8729fbe3435278786931f1 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:37]
2024-11-27 17:21:38,141 - root - INFO - Loading model from cache directory: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/dnabert2/models--zhihan1996--DNABERT-2-117M/snapshots/d064dece8a8b41d9fb8729fbe3435278786931f1 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:48]
2024-11-27 17:21:39,168 - root - INFO - Feature extraction started at: 2024-11-27 17:21:39 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:66]
2024-11-27 17:21:39,168 - root - INFO - Model: db2
 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:67]
2024-11-27 17:21:39,168 - root - INFO - Scanning for existing features... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:70]
2024-11-27 17:23:51,236 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 768]) [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:153]
2024-11-27 17:23:51,236 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:156]
2024-11-27 17:23:51,240 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:77]
2024-11-27 17:24:49,929 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'encoder_name': 'hd', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:44]
2024-11-27 17:24:49,932 - src.cli - INFO - Using encoder: hd with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:49]
2024-11-27 17:24:49,932 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:65]
2024-11-27 17:24:49,983 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:37]
2024-11-27 17:24:49,989 - root - INFO - Loading model from cache directory: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:112]
2024-11-27 17:24:51,237 - accelerate.big_modeling - WARNING - You shouldn't move a model that is dispatched using accelerate hooks. [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/accelerate/big_modeling.py:451]
2024-11-27 17:24:51,246 - root - INFO - Feature extraction started at: 2024-11-27 17:24:51 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:66]
2024-11-27 17:24:51,246 - root - INFO - Model: hd
 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:67]
2024-11-27 17:24:51,246 - root - INFO - Scanning for existing features... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:70]
2024-11-27 17:28:42,569 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'encoder_name': 'hd', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:44]
2024-11-27 17:28:42,572 - src.cli - INFO - Using encoder: hd with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:49]
2024-11-27 17:28:42,572 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:65]
2024-11-27 17:28:42,621 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:37]
2024-11-27 17:28:42,626 - root - INFO - Loading model from cache directory: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:112]
2024-11-27 17:28:43,916 - accelerate.big_modeling - WARNING - You shouldn't move a model that is dispatched using accelerate hooks. [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/accelerate/big_modeling.py:451]
2024-11-27 17:28:43,925 - root - INFO - Feature extraction started at: 2024-11-27 17:28:43 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:66]
2024-11-27 17:28:43,925 - root - INFO - Model: hd
 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:67]
2024-11-27 17:28:43,925 - root - INFO - Scanning for existing features... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:70]
2024-11-27 19:35:01,501 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'encoder_name': 'hd', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:44]
2024-11-27 19:35:01,505 - src.cli - INFO - Using encoder: hd with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:49]
2024-11-27 19:35:01,544 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:65]
2024-11-27 19:35:01,579 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:37]
2024-11-27 19:35:01,595 - root - INFO - Loading model from cache directory: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:112]
2024-11-27 19:35:02,822 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk). [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/accelerate/utils/modeling.py:1014]
2024-11-27 19:35:03,084 - root - INFO - Feature extraction started at: 2024-11-27 19:35:03 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:66]
2024-11-27 19:35:03,084 - root - INFO - Model: hd
 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:67]
2024-11-27 19:35:03,084 - root - INFO - Scanning for existing features... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:70]
2024-11-27 19:36:52,022 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 256]) [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:153]
2024-11-27 19:36:52,023 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:156]
2024-11-27 19:36:52,028 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:77]
2024-11-27 19:38:28,632 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'encoder_name': 'hd', 'device': 'cuda:0', 'pooling_type': 'mean_pooling', 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:44]
2024-11-27 19:38:28,634 - src.cli - INFO - Using encoder: hd with params: {'pretrained_model_name': 'LongSafari/hyenadna-medium-160k-seqlen-hf', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna', 'download': False} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:49]
2024-11-27 19:38:28,648 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:65]
2024-11-27 19:38:28,682 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:37]
2024-11-27 19:38:28,688 - root - INFO - Loading model from cache directory: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/hyenadna/models--LongSafari--hyenadna-medium-160k-seqlen-hf/snapshots/7ebf71773d22c0ede2cc55cb2be15ee8c289e1ce [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:112]
2024-11-27 19:38:29,415 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk). [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/accelerate/utils/modeling.py:1014]
2024-11-27 19:38:29,680 - root - INFO - Feature extraction started at: 2024-11-27 19:38:29 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:66]
2024-11-27 19:38:29,680 - root - INFO - Model: hd
 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:67]
2024-11-27 19:38:29,680 - root - INFO - Scanning for existing features... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:70]
2024-11-27 19:40:12,490 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 256]) [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:153]
2024-11-27 19:40:12,490 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:156]
2024-11-27 19:40:12,496 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:77]
2024-11-27 19:47:22,196 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'encoder_name': 'nt', 'device': 'cuda:0', 'pooling_type': 'mean_pooling', 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:44]
2024-11-27 19:47:22,198 - src.cli - INFO - Using encoder: nt with params: {'pretrained_model_name': 'InstaDeepAI/nucleotide-transformer-v2-500m-multi-species', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer', 'download': True} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:49]
2024-11-27 19:47:22,212 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:65]
2024-11-27 19:47:22,225 - root - INFO - Downloading tokenizer from InstaDeepAI/nucleotide-transformer-v2-500m-multi-species... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:31]
2024-11-27 19:47:22,234 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 19:47:22,546 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 19:47:22,953 - filelock - DEBUG - Attempting to acquire lock 140178079152336 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/329c0d1008755f3b4a13c5c731c919a4968da554.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 19:47:22,971 - filelock - DEBUG - Lock 140178079152336 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/329c0d1008755f3b4a13c5c731c919a4968da554.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 19:47:23,111 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/tokenizer_config.json HTTP/11" 200 129 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 19:47:23,251 - filelock - DEBUG - Attempting to release lock 140178079152336 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/329c0d1008755f3b4a13c5c731c919a4968da554.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 19:47:23,252 - filelock - DEBUG - Lock 140178079152336 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/329c0d1008755f3b4a13c5c731c919a4968da554.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 19:47:23,408 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/vocab.txt HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 19:47:23,411 - filelock - DEBUG - Attempting to acquire lock 140178079251664 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/07d69f8c7001350597818d8853d85ef0c203bda2.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 19:47:23,440 - filelock - DEBUG - Lock 140178079251664 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/07d69f8c7001350597818d8853d85ef0c203bda2.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 19:47:23,584 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/vocab.txt HTTP/11" 200 28718 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 19:47:23,637 - filelock - DEBUG - Attempting to release lock 140178079251664 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/07d69f8c7001350597818d8853d85ef0c203bda2.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 19:47:23,638 - filelock - DEBUG - Lock 140178079251664 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/07d69f8c7001350597818d8853d85ef0c203bda2.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 19:47:23,783 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/added_tokens.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 19:47:23,960 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/special_tokens_map.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 19:47:23,962 - filelock - DEBUG - Attempting to acquire lock 140178079252048 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/ac47d8ff84d2793441964824395dba33d5146227.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 19:47:24,001 - filelock - DEBUG - Lock 140178079252048 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/ac47d8ff84d2793441964824395dba33d5146227.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 19:47:24,143 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/special_tokens_map.json HTTP/11" 200 101 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 19:47:24,487 - filelock - DEBUG - Attempting to release lock 140178079252048 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/ac47d8ff84d2793441964824395dba33d5146227.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 19:47:24,488 - filelock - DEBUG - Lock 140178079252048 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/ac47d8ff84d2793441964824395dba33d5146227.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 19:47:24,690 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/tokenizer.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 19:47:24,854 - root - INFO - Loading model from pretrained model: InstaDeepAI/nucleotide-transformer-v2-500m-multi-species [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:143]
2024-11-27 19:47:24,993 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 19:47:24,995 - filelock - DEBUG - Attempting to acquire lock 140178079335312 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/5de84a4d9f06eac63228d803da37dbfcd086b140.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 19:47:25,138 - filelock - DEBUG - Lock 140178079335312 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/5de84a4d9f06eac63228d803da37dbfcd086b140.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 19:47:25,404 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/config.json HTTP/11" 200 1065 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 19:47:25,603 - filelock - DEBUG - Attempting to release lock 140178079335312 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/5de84a4d9f06eac63228d803da37dbfcd086b140.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 19:47:25,604 - filelock - DEBUG - Lock 140178079335312 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/5de84a4d9f06eac63228d803da37dbfcd086b140.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 19:47:25,859 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/esm_config.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 19:47:25,861 - filelock - DEBUG - Attempting to acquire lock 140177974853456 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/23313afb28fe512badf134e9d1ce08e405e3656c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 19:47:26,002 - filelock - DEBUG - Lock 140177974853456 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/23313afb28fe512badf134e9d1ce08e405e3656c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 19:47:26,228 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/esm_config.py HTTP/11" 200 14876 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 19:47:26,301 - filelock - DEBUG - Attempting to release lock 140177974853456 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/23313afb28fe512badf134e9d1ce08e405e3656c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 19:47:26,302 - filelock - DEBUG - Lock 140177974853456 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/23313afb28fe512badf134e9d1ce08e405e3656c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 19:47:26,694 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/modeling_esm.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 19:47:26,696 - filelock - DEBUG - Attempting to acquire lock 140177973420112 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/967189e3be48c42bb5a6af4b8243b54590cbe929.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 19:47:26,750 - filelock - DEBUG - Lock 140177973420112 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/967189e3be48c42bb5a6af4b8243b54590cbe929.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 19:47:26,895 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/modeling_esm.py HTTP/11" 200 58184 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 19:47:26,980 - filelock - DEBUG - Attempting to release lock 140177973420112 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/967189e3be48c42bb5a6af4b8243b54590cbe929.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 19:47:26,981 - filelock - DEBUG - Lock 140177973420112 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/967189e3be48c42bb5a6af4b8243b54590cbe929.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 19:47:27,157 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/adapter_config.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 19:47:27,363 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/model.safetensors HTTP/11" 302 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 19:47:27,366 - filelock - DEBUG - Attempting to acquire lock 140177973507792 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/7a00ffaaf8f3ca627741a61e568d7e550b5c79aada70c76c8cb861192fbe7c59.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 19:47:27,396 - filelock - DEBUG - Lock 140177973507792 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/7a00ffaaf8f3ca627741a61e568d7e550b5c79aada70c76c8cb861192fbe7c59.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 19:47:27,409 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): cdn-lfs.hf.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 19:47:27,650 - urllib3.connectionpool - DEBUG - https://cdn-lfs.hf.co:443 "GET /repos/2e/ce/2ece3c9892edcfec41d0a4379b979570588b74988477fa7f4f9409873156d0dd/7a00ffaaf8f3ca627741a61e568d7e550b5c79aada70c76c8cb861192fbe7c59?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1732996047&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjk5NjA0N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8yZS9jZS8yZWNlM2M5ODkyZWRjZmVjNDFkMGE0Mzc5Yjk3OTU3MDU4OGI3NDk4ODQ3N2ZhN2Y0Zjk0MDk4NzMxNTZkMGRkLzdhMDBmZmFhZjhmM2NhNjI3NzQxYTYxZTU2OGQ3ZTU1MGI1Yzc5YWFkYTcwYzc2YzhjYjg2MTE5MmZiZTdjNTk~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=KgK4Wo3ZvZeQ8kHpvExomTuJTX2s1gETijpskWuqc09EXLpxnlfHFEgdBafosxKdqnIKSj0bWiJE2tnyYKZwH7up87FGtGaWOeub8RTh9UynyPt36RkcJesNkuqqENBdL29ugfg5LJdzKBAcaqhGET-AmUR2HG8KCO0FEsSD-sVxJcGpJVnrAvdKV60i8tDQqGh-QS6digExqFCfkuCJ2S~PAAdZf5A7V2WFEtYWpzUg7yz2CnE5RkUhNMiADw~qBagibXABDPFZY68wNYd1E3XmPxUwJWcFI6HxOc9DNcrLo2VzvkK7UTs1~QZaBKCPSTuv37cyEgshRskb5FFfSA__&Key-Pair-Id=K3RPWS32NSSJCE HTTP/11" 200 1993438552 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 19:47:49,232 - filelock - DEBUG - Attempting to release lock 140177973507792 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/7a00ffaaf8f3ca627741a61e568d7e550b5c79aada70c76c8cb861192fbe7c59.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 19:47:49,232 - filelock - DEBUG - Lock 140177973507792 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/7a00ffaaf8f3ca627741a61e568d7e550b5c79aada70c76c8cb861192fbe7c59.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 19:47:49,767 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk). [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/accelerate/utils/modeling.py:1014]
2024-11-27 19:47:52,527 - root - INFO - Feature extraction started at: 2024-11-27 19:47:52 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:66]
2024-11-27 19:47:52,527 - root - INFO - Model: nt
 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:67]
2024-11-27 19:47:52,527 - root - INFO - Scanning for existing features... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:70]
2024-11-27 20:03:07,036 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'encoder_name': 'nt', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:44]
2024-11-27 20:03:07,039 - src.cli - INFO - Using encoder: nt with params: {'pretrained_model_name': 'InstaDeepAI/nucleotide-transformer-v2-500m-multi-species', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer', 'download': False} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:49]
2024-11-27 20:03:07,052 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:65]
2024-11-27 20:03:07,260 - root - ERROR - Tokenizer checkpoint does not exist: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/snapshots/f1fd7a1df5b19d31b88f11db1ce87caeb1ea4d2a [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:35]
2024-11-27 20:03:26,391 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'encoder_name': 'nt', 'device': 'cuda', 'pooling_type': 'mean_pooling', 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:44]
2024-11-27 20:03:26,393 - src.cli - INFO - Using encoder: nt with params: {'pretrained_model_name': 'InstaDeepAI/nucleotide-transformer-v2-500m-multi-species', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer', 'download': True} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:49]
2024-11-27 20:03:26,404 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:65]
2024-11-27 20:03:26,480 - root - INFO - Downloading tokenizer from InstaDeepAI/nucleotide-transformer-v2-500m-multi-species... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:31]
2024-11-27 20:03:26,485 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 20:03:26,704 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:03:26,775 - filelock - DEBUG - Attempting to acquire lock 139877501713808 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/329c0d1008755f3b4a13c5c731c919a4968da554.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 20:03:26,791 - filelock - DEBUG - Lock 139877501713808 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/329c0d1008755f3b4a13c5c731c919a4968da554.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 20:03:26,929 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/tokenizer_config.json HTTP/11" 200 129 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:03:27,284 - filelock - DEBUG - Attempting to release lock 139877501713808 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/329c0d1008755f3b4a13c5c731c919a4968da554.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 20:03:27,284 - filelock - DEBUG - Lock 139877501713808 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/329c0d1008755f3b4a13c5c731c919a4968da554.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 20:03:27,423 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/vocab.txt HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:03:27,425 - filelock - DEBUG - Attempting to acquire lock 139877501827344 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/07d69f8c7001350597818d8853d85ef0c203bda2.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 20:03:27,467 - filelock - DEBUG - Lock 139877501827344 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/07d69f8c7001350597818d8853d85ef0c203bda2.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 20:03:27,601 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/vocab.txt HTTP/11" 200 28718 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:03:27,688 - filelock - DEBUG - Attempting to release lock 139877501827344 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/07d69f8c7001350597818d8853d85ef0c203bda2.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 20:03:27,689 - filelock - DEBUG - Lock 139877501827344 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/07d69f8c7001350597818d8853d85ef0c203bda2.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 20:03:27,823 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/added_tokens.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:03:27,983 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/special_tokens_map.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:03:27,984 - filelock - DEBUG - Attempting to acquire lock 139877501827728 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/ac47d8ff84d2793441964824395dba33d5146227.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 20:03:28,025 - filelock - DEBUG - Lock 139877501827728 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/ac47d8ff84d2793441964824395dba33d5146227.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 20:03:28,157 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/special_tokens_map.json HTTP/11" 200 101 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:03:28,209 - filelock - DEBUG - Attempting to release lock 139877501827728 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/ac47d8ff84d2793441964824395dba33d5146227.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 20:03:28,209 - filelock - DEBUG - Lock 139877501827728 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/ac47d8ff84d2793441964824395dba33d5146227.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 20:03:28,347 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/tokenizer.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:03:28,385 - root - INFO - Loading model from pretrained model: InstaDeepAI/nucleotide-transformer-v2-500m-multi-species [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:143]
2024-11-27 20:03:28,508 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:03:28,510 - filelock - DEBUG - Attempting to acquire lock 139877491441808 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/5de84a4d9f06eac63228d803da37dbfcd086b140.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 20:03:28,539 - filelock - DEBUG - Lock 139877491441808 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/5de84a4d9f06eac63228d803da37dbfcd086b140.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 20:03:28,751 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/config.json HTTP/11" 200 1065 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:03:28,810 - filelock - DEBUG - Attempting to release lock 139877491441808 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/5de84a4d9f06eac63228d803da37dbfcd086b140.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 20:03:28,810 - filelock - DEBUG - Lock 139877491441808 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/5de84a4d9f06eac63228d803da37dbfcd086b140.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 20:03:28,951 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/esm_config.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:03:28,952 - filelock - DEBUG - Attempting to acquire lock 139877491442768 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/23313afb28fe512badf134e9d1ce08e405e3656c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 20:03:28,984 - filelock - DEBUG - Lock 139877491442768 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/23313afb28fe512badf134e9d1ce08e405e3656c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 20:03:29,122 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/esm_config.py HTTP/11" 200 14876 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:03:29,176 - filelock - DEBUG - Attempting to release lock 139877491442768 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/23313afb28fe512badf134e9d1ce08e405e3656c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 20:03:29,176 - filelock - DEBUG - Lock 139877491442768 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/23313afb28fe512badf134e9d1ce08e405e3656c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 20:03:29,462 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/modeling_esm.py HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:03:29,464 - filelock - DEBUG - Attempting to acquire lock 139877489466192 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/967189e3be48c42bb5a6af4b8243b54590cbe929.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 20:03:29,506 - filelock - DEBUG - Lock 139877489466192 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/967189e3be48c42bb5a6af4b8243b54590cbe929.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 20:03:29,658 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/modeling_esm.py HTTP/11" 200 58184 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:03:29,734 - filelock - DEBUG - Attempting to release lock 139877489466192 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/967189e3be48c42bb5a6af4b8243b54590cbe929.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 20:03:29,735 - filelock - DEBUG - Lock 139877489466192 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/967189e3be48c42bb5a6af4b8243b54590cbe929.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 20:03:29,891 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/adapter_config.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:03:30,064 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /InstaDeepAI/nucleotide-transformer-v2-500m-multi-species/resolve/main/model.safetensors HTTP/11" 302 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:03:30,066 - filelock - DEBUG - Attempting to acquire lock 139877489468752 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/7a00ffaaf8f3ca627741a61e568d7e550b5c79aada70c76c8cb861192fbe7c59.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 20:03:30,093 - filelock - DEBUG - Lock 139877489468752 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/7a00ffaaf8f3ca627741a61e568d7e550b5c79aada70c76c8cb861192fbe7c59.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 20:03:30,100 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): cdn-lfs.hf.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 20:03:30,230 - urllib3.connectionpool - DEBUG - https://cdn-lfs.hf.co:443 "GET /repos/2e/ce/2ece3c9892edcfec41d0a4379b979570588b74988477fa7f4f9409873156d0dd/7a00ffaaf8f3ca627741a61e568d7e550b5c79aada70c76c8cb861192fbe7c59?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1732997010&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjk5NzAxMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8yZS9jZS8yZWNlM2M5ODkyZWRjZmVjNDFkMGE0Mzc5Yjk3OTU3MDU4OGI3NDk4ODQ3N2ZhN2Y0Zjk0MDk4NzMxNTZkMGRkLzdhMDBmZmFhZjhmM2NhNjI3NzQxYTYxZTU2OGQ3ZTU1MGI1Yzc5YWFkYTcwYzc2YzhjYjg2MTE5MmZiZTdjNTk~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=Ub3HA3us6ot~WnaGavrwkyFZnF5YckjVM~FqpgTJ2AMwOBvVNVwyuCijOX2IqrcyTbh5ShSxnVNVwFbtznId8cHkaieE3THXFMnfoj6uzpmm75EeskbKri1FZ89x92ZjdtWirScTRT1WSbymO2j9M3v2XlqIwauyDTYAFERWg2T-EEsXXGVvYpxCwXw-bR1ORunjHZ5LPPut0kyi0~iB71NZRpCjHb2Oa6hq45EpGrDA1khwiKw~2lD4s882bZjtM84C9L-R9tke1FiMrNfM4pVapzygdStBgQlmYsIpZcvaYQzURKTG2YGf2xxTR3YwFRJeNs1wq4oJTuh8AyEpKQ__&Key-Pair-Id=K3RPWS32NSSJCE HTTP/11" 200 1993438552 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:03:51,197 - filelock - DEBUG - Attempting to release lock 139877489468752 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/7a00ffaaf8f3ca627741a61e568d7e550b5c79aada70c76c8cb861192fbe7c59.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 20:03:51,198 - filelock - DEBUG - Lock 139877489468752 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/nt_transformer/.locks/models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species/7a00ffaaf8f3ca627741a61e568d7e550b5c79aada70c76c8cb861192fbe7c59.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 20:03:54,728 - root - INFO - Feature extraction started at: 2024-11-27 20:03:54 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:66]
2024-11-27 20:03:54,728 - root - INFO - Model: nt
 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:67]
2024-11-27 20:03:54,728 - root - INFO - Scanning for existing features... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:70]
2024-11-27 20:05:28,048 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 1024]) [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:153]
2024-11-27 20:05:28,049 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:156]
2024-11-27 20:05:28,055 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:77]
2024-11-27 20:11:46,992 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'encoder_name': 'ef', 'device': 'cuda:0', 'pooling_type': 'mean_pooling', 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:44]
2024-11-27 20:11:46,996 - src.cli - INFO - Using encoder: ef with params: {'pretrained_model_name': 'EleutherAI/enformer-official-rough', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer', 'download': True} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:49]
2024-11-27 20:11:47,006 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:65]
2024-11-27 20:11:47,030 - root - INFO - Loading model from pretrained model: EleutherAI/enformer-official-rough [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:206]
2024-11-27 20:11:47,037 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 20:11:47,251 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:11:47,323 - filelock - DEBUG - Attempting to acquire lock 140619821252176 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/e50a83cf5e2b127669849109f24c5edcc9361788.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 20:11:47,339 - filelock - DEBUG - Lock 140619821252176 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/e50a83cf5e2b127669849109f24c5edcc9361788.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 20:11:47,484 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /EleutherAI/enformer-official-rough/resolve/main/config.json HTTP/11" 200 439 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:11:47,573 - filelock - DEBUG - Attempting to release lock 140619821252176 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/e50a83cf5e2b127669849109f24c5edcc9361788.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 20:11:47,573 - filelock - DEBUG - Lock 140619821252176 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/e50a83cf5e2b127669849109f24c5edcc9361788.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 20:11:47,721 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/adapter_config.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:11:47,890 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:11:48,024 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/model.safetensors HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:11:48,170 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/model.safetensors.index.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:11:48,334 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/pytorch_model.bin HTTP/11" 302 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:11:48,337 - filelock - DEBUG - Attempting to acquire lock 140619821248016 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 20:11:48,369 - filelock - DEBUG - Lock 140619821248016 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 20:11:48,381 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): cdn-lfs.hf.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 20:11:48,636 - urllib3.connectionpool - DEBUG - https://cdn-lfs.hf.co:443 "GET /repos/66/eb/66eb21fc2fbae75237b909a4b84d41cb1dce65f654cb9640fdbb51e78b6c13d2/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1732997508&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjk5NzUwOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy82Ni9lYi82NmViMjFmYzJmYmFlNzUyMzdiOTA5YTRiODRkNDFjYjFkY2U2NWY2NTRjYjk2NDBmZGJiNTFlNzhiNmMxM2QyLzk5YjA5ZDYwMmUxOTVkODljN2Q0ZGViZTE0NGJiMmY0MzkwN2JhMGQ3NDAwNmU5NzA5OGU5OWQ5MTcxYzQzOWM~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=mtlIfBm2EJ8R-3GNRYl4LiPlqSY9iryS2mNaSvB1otD3OBK6ZkUBRTvVrJzXNYOdHOaxxmeot4-6fb3YrwD853ZU2AnB8LIbx3bFN~hqDYpSe8lsNGQ3aQZWtfNtsQ6cduOyrctAnSc5OJ6yp79epVfAp3pKRfuVUgz17W4vCTsBP-UK9ytYt8KfFY49mgpheoawGY2xfJ0vvmy13yDqEeHaUyPhGB1UiRXtfnQe7CELPEQ~ryXFQAl0kxkqw8IehK7pmijcTN5~LFkk8YkgITIRIEdYepF4Ee~~TLl67NxvYm31r3M5nHbVB~SSuJZu45UxAn5enmMpmazjrXKHRw__&Key-Pair-Id=K3RPWS32NSSJCE HTTP/11" 200 1005149571 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:12:06,464 - filelock - DEBUG - Attempting to release lock 140619821248016 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 20:12:06,465 - filelock - DEBUG - Lock 140619821248016 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/.locks/models--EleutherAI--enformer-official-rough/99b09d602e195d89c7d4debe144bb2f43907ba0d74006e97098e99d9171c439c.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 20:12:06,614 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /EleutherAI/enformer-official-rough/resolve/main/model.safetensors HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:12:06,617 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 20:12:06,844 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/EleutherAI/enformer-official-rough HTTP/11" 200 783 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:12:06,995 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/EleutherAI/enformer-official-rough/commits/main HTTP/11" 200 1073 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:12:07,137 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/EleutherAI/enformer-official-rough/discussions?p=0 HTTP/11" 200 565 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:12:07,396 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/EleutherAI/enformer-official-rough/commits/refs%2Fpr%2F1 HTTP/11" 200 2038 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:12:07,398 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): safetensors-convert.hf.space:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 20:12:07,709 - urllib3.connectionpool - DEBUG - https://safetensors-convert.hf.space:443 "POST /call/run HTTP/11" 503 30 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:12:09,053 - root - INFO - Feature extraction started at: 2024-11-27 20:12:09 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:66]
2024-11-27 20:12:09,054 - root - INFO - Model: ef
 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:67]
2024-11-27 20:12:09,054 - root - INFO - Scanning for existing features... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:70]
2024-11-27 20:27:57,049 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'encoder_name': 'ef', 'device': 'cuda:0', 'pooling_type': 'mean_pooling', 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:44]
2024-11-27 20:27:57,051 - src.cli - INFO - Using encoder: ef with params: {'pretrained_model_name': 'EleutherAI/enformer-official-rough', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer', 'download': False} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:49]
2024-11-27 20:27:57,062 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:65]
2024-11-27 20:27:57,090 - root - INFO - Loading model from cache directory: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/enformer/models--EleutherAI--enformer-official-rough/snapshots/affe5713ae9017460706a44108289b13c5fee16c [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:212]
2024-11-27 20:27:57,867 - root - INFO - Feature extraction started at: 2024-11-27 20:27:57 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:66]
2024-11-27 20:27:57,867 - root - INFO - Model: ef
 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:67]
2024-11-27 20:27:57,867 - root - INFO - Scanning for existing features... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:70]
2024-11-27 20:35:34,706 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'encoder_name': 'gv', 'device': 'cuda:0', 'pooling_type': 'mean_pooling', 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:44]
2024-11-27 20:35:34,709 - src.cli - INFO - Using encoder: gv with params: {'pretrained_model_name': 'PoetschLab/GROVER', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover', 'download': True} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:49]
2024-11-27 20:35:34,721 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:65]
2024-11-27 20:36:27,079 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'encoder_name': 'gv', 'device': 'cuda:0', 'pooling_type': 'mean_pooling', 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:44]
2024-11-27 20:36:27,080 - src.cli - INFO - Using encoder: gv with params: {'pretrained_model_name': 'PoetschLab/GROVER', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover', 'download': True} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:49]
2024-11-27 20:36:27,095 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:65]
2024-11-27 20:36:27,122 - root - INFO - Downloading tokenizer from PoetschLab/GROVER... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:29]
2024-11-27 20:36:27,126 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 20:36:27,287 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/tokenizer_config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:27,349 - filelock - DEBUG - Attempting to acquire lock 140051684102288 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/3a66e59228bcac90d6ea31f7a7b568ce7452c176.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 20:36:27,366 - filelock - DEBUG - Lock 140051684102288 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/3a66e59228bcac90d6ea31f7a7b568ce7452c176.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 20:36:27,536 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /PoetschLab/GROVER/resolve/main/tokenizer_config.json HTTP/11" 200 314 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:27,621 - filelock - DEBUG - Attempting to release lock 140051684102288 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/3a66e59228bcac90d6ea31f7a7b568ce7452c176.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 20:36:27,622 - filelock - DEBUG - Lock 140051684102288 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/3a66e59228bcac90d6ea31f7a7b568ce7452c176.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 20:36:27,822 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/tokenizer.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:27,824 - filelock - DEBUG - Attempting to acquire lock 140051684101648 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/532b827ad133bc7263840f5c17ecd49d77993fa1.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 20:36:27,942 - filelock - DEBUG - Lock 140051684101648 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/532b827ad133bc7263840f5c17ecd49d77993fa1.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 20:36:28,158 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /PoetschLab/GROVER/resolve/main/tokenizer.json HTTP/11" 200 24637 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:28,255 - filelock - DEBUG - Attempting to release lock 140051684101648 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/532b827ad133bc7263840f5c17ecd49d77993fa1.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 20:36:28,255 - filelock - DEBUG - Lock 140051684101648 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/532b827ad133bc7263840f5c17ecd49d77993fa1.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 20:36:28,405 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/tokenizer.model HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:28,574 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/added_tokens.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:28,723 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/special_tokens_map.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:28,725 - filelock - DEBUG - Attempting to acquire lock 140051684100496 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/ecf09bb92a7a4fae4e7ef876320c628ae2ce126e.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 20:36:28,754 - filelock - DEBUG - Lock 140051684100496 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/ecf09bb92a7a4fae4e7ef876320c628ae2ce126e.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 20:36:28,894 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /PoetschLab/GROVER/resolve/main/special_tokens_map.json HTTP/11" 200 77 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:28,947 - filelock - DEBUG - Attempting to release lock 140051684100496 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/ecf09bb92a7a4fae4e7ef876320c628ae2ce126e.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 20:36:28,947 - filelock - DEBUG - Lock 140051684100496 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/ecf09bb92a7a4fae4e7ef876320c628ae2ce126e.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 20:36:29,004 - root - INFO - Loading model from pretrained model: PoetschLab/GROVER [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:198]
2024-11-27 20:36:29,131 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/config.json HTTP/11" 200 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:29,133 - filelock - DEBUG - Attempting to acquire lock 140051684146384 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/dc89517c5b01a77f5423953bbe32258b369acb53.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 20:36:29,169 - filelock - DEBUG - Lock 140051684146384 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/dc89517c5b01a77f5423953bbe32258b369acb53.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 20:36:29,305 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /PoetschLab/GROVER/resolve/main/config.json HTTP/11" 200 1109 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:29,350 - filelock - DEBUG - Attempting to release lock 140051684146384 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/dc89517c5b01a77f5423953bbe32258b369acb53.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 20:36:29,351 - filelock - DEBUG - Lock 140051684146384 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/dc89517c5b01a77f5423953bbe32258b369acb53.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 20:36:31,749 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/adapter_config.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:31,927 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/model.safetensors HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:32,073 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/model.safetensors.index.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:32,224 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/pytorch_model.bin HTTP/11" 302 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:32,227 - filelock - DEBUG - Attempting to acquire lock 140051684145680 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/81fa4ee056e65ff1c06c32512589f3ba3bcb9d054960f35f634b9cf6da7aadda.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:331]
2024-11-27 20:36:32,262 - filelock - DEBUG - Lock 140051684145680 acquired on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/81fa4ee056e65ff1c06c32512589f3ba3bcb9d054960f35f634b9cf6da7aadda.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:334]
2024-11-27 20:36:32,274 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): cdn-lfs-us-1.hf.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 20:36:32,484 - urllib3.connectionpool - DEBUG - https://cdn-lfs-us-1.hf.co:443 "GET /repos/ec/89/ec89555b6bae1e89f06aea92e20141af026ca5e5be53bf7afb3cf5e6ccc02ca4/81fa4ee056e65ff1c06c32512589f3ba3bcb9d054960f35f634b9cf6da7aadda?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1732998992&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjk5ODk5Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2VjLzg5L2VjODk1NTViNmJhZTFlODlmMDZhZWE5MmUyMDE0MWFmMDI2Y2E1ZTViZTUzYmY3YWZiM2NmNWU2Y2NjMDJjYTQvODFmYTRlZTA1NmU2NWZmMWMwNmMzMjUxMjU4OWYzYmEzYmNiOWQwNTQ5NjBmMzVmNjM0YjljZjZkYTdhYWRkYT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=KdSlvNla-AUnEIOZV3HM3pndP7xYDHmDCQpUWaAWtG6YpCarOvNm8lM2msn6CzUio2u4jDEAyHU3KKIozWVwg-ASOrAybzd8BJYGmiy3JEbdUot94SgHNo-cZkTeCcM42TAX03x-pRTW0Ig-~eSR6GT-dytihIe9cf-pk04twSwg0Kh~SNPvG4gQEhuJQS1uXKrh~PBB6-AUN9uzkf-SN9c8z71yCl3gUcvSLGq2S19U78NvdT7qLULNokYUEyctAJDBfoOmP8NZouvQXysKr3UNuIo3lHdbxzyzcNfUZ5VFRL-n3EpTUQg9qrcdf2guSEL88V10WP-NZ7s3wjN-DA__&Key-Pair-Id=K24J24Z295AEI9 HTTP/11" 200 348488361 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:40,935 - filelock - DEBUG - Attempting to release lock 140051684145680 on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/81fa4ee056e65ff1c06c32512589f3ba3bcb9d054960f35f634b9cf6da7aadda.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:364]
2024-11-27 20:36:40,936 - filelock - DEBUG - Lock 140051684145680 released on /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/.locks/models--PoetschLab--GROVER/81fa4ee056e65ff1c06c32512589f3ba3bcb9d054960f35f634b9cf6da7aadda.lock [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/filelock/_api.py:367]
2024-11-27 20:36:41,088 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/model.safetensors HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:41,090 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 20:36:41,270 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/PoetschLab/GROVER HTTP/11" 200 3649 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:41,531 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/PoetschLab/GROVER/commits/main HTTP/11" 200 2000 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:41,612 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /PoetschLab/GROVER/resolve/main/generation_config.json HTTP/11" 404 0 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:41,665 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/PoetschLab/GROVER/discussions?p=0 HTTP/11" 200 1676 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:41,858 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/PoetschLab/GROVER/commits/refs%2Fpr%2F4 HTTP/11" 200 2965 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:36:41,860 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): safetensors-convert.hf.space:443 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:1051]
2024-11-27 20:36:42,132 - root - INFO - Feature extraction started at: 2024-11-27 20:36:42 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:66]
2024-11-27 20:36:42,132 - root - INFO - Model: gv
 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:67]
2024-11-27 20:36:42,132 - root - INFO - Scanning for existing features... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:70]
2024-11-27 20:36:42,174 - urllib3.connectionpool - DEBUG - https://safetensors-convert.hf.space:443 "POST /call/run HTTP/11" 503 30 [in /mnt/bulk-io/lizhang/LiWorkSpace/leopard/new_conda/envs/genml/lib/python3.11/site-packages/urllib3/connectionpool.py:546]
2024-11-27 20:37:57,229 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 609]) [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:153]
2024-11-27 20:37:57,229 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:156]
2024-11-27 20:37:57,232 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:77]
2024-11-28 12:24:26,298 - src.cli - INFO - Config loaded: {'filepath': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/01_raw/tcga_mutations_controlled.csv', 'pat_column': 'Patient_ID', 'mut_column': 'Alt_Sequence', 'num_patients': 1, 'encoder_name': 'gv', 'device': 'cuda:0', 'pooling_type': 'mean_pooling', 'batch_size': 64, 'num_workers': 4, 'output_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/04_feature'} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:44]
2024-11-28 12:24:26,301 - src.cli - INFO - Using encoder: gv with params: {'pretrained_model_name': 'PoetschLab/GROVER', 'cache_dir': '/mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover', 'download': False} [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:49]
2024-11-28 12:24:26,313 - src.cli - INFO - Start feature extraction. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:65]
2024-11-28 12:24:26,340 - root - INFO - Loading tokenizer from checkpoint: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/models--PoetschLab--GROVER/snapshots/f6ed259a321aacb629cf638a1568c2a40b381cfe [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:35]
2024-11-28 12:24:26,380 - root - INFO - Loading model from cache directory: /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/data/06_checkpoints/grover/models--PoetschLab--GROVER/snapshots/f6ed259a321aacb629cf638a1568c2a40b381cfe [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/helpers/encoders.py:204]
2024-11-28 12:24:30,789 - root - INFO - Feature extraction started at: 2024-11-28 12:24:30 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:66]
2024-11-28 12:24:30,789 - root - INFO - Model: gv
 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:67]
2024-11-28 12:24:30,789 - root - INFO - Scanning for existing features... [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:70]
2024-11-28 12:26:14,859 - root - INFO - Saved features for patient TCGA-02-0003, final extracted features shape torch.Size([789, 609]) [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:153]
2024-11-28 12:26:14,859 - root - INFO - 
Feature extraction completed. Processed: 1, Skipped: 0, Errors: 0 [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/feature_extraction/feats_extract.py:156]
2024-11-28 12:26:14,865 - src.cli - INFO - Feature extraction and saving completed successfully. [in /mnt/bulk-uranus/lizhang/LiWorkSpace/genomics/genml/src/cli.py:77]
